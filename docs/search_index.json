[["index.html", "Adventures in Data Science Overview", " Adventures in Data Science Dr. Carl G. Stahmer Dr. Pamela L. Reynolds Dr. Tyler Shoemaker Carrie Alexander Arthur Koehl Nick Ulle 2021-02-22 Overview This is the course reader for IST008, Adventures in Data Science: Social Science Edition. The course is designed to provide students with a basic understanding of computing and network architecture, basic programming skills, and an introduction to common methods in Data Science and Digital Humanities. This coure reader provides background information that will help you to better understand the concepts that we will discuss in class and to better participate in the hands-on portion of the course. "],["working-with-the-command-line.html", "1 Working with the Command Line 1.1 Interacting with the Command Line 1.2 Common Command Line Commands 1.3 Command Line Text Editors 1.4 Basic Vim Commands", " 1 Working with the Command Line Most users interact with their computer through a Graphical User Interface (GUI) that allows them to use a mouse, keyboard, and graphical elements on screen (such as file menus, pictures of folders and files, etc.) to perform their work. Users tend to conflate their Operating System and their GUI because computer hardware and software manufacturers tightly pack these two concerns as a convenience to users. But the Windows 10 or Mac Big Sur operating system that makes your computer work and the Windows 10 or Mac Big Sur GUI that you interact with are, in fact completely different and separable software packages and it is possible to use different methods/software to interact with your computer than the stock, tightly coupled GUI that launches automatically when you turn on your computer. Because computer manufacturers like Windows and Mac devote so many resources to the development of their system GUIs, there are few viable (at present, none, commercially available) competing GUIs for these platforms. This is not the case in the Linux world, however, where users have several system GUI packages from which to choose and can seamlessly switch between them as desired. Despite the lack of competition/choice on the GUI front when it comes to interacting with your computer, there are other, non-graphical ways of communicating directly with your operating system that exist for all operating systems. We call these “Command Line” interfaces. The Command Line offers a text-only, non graphical means of interacting with your computer. In the early days of computing, all user interaction with the computer happened at the command line. In the current days of graphical user interfaces, using the Command Line requires you to launch a special program that provides Command Line access. Mac users will use an application called “Terminal” which ships by default with the Mac operating system. To launch the Terminal application, go to: Applications -&gt; Utilities -&gt; Terminal When you launch the application, you will see something like this: Windows users will use an application called Git Bash, which was installed on your system when you installed Git. To launch Git Bash, go to: Click on the Windows Start Menu and search for “Git Bash” Alternatively, Click on the Windows Start Menu, select Programs, and browse to Git Bash When you launch the application, you will see something like this: 1.1 Interacting with the Command Line While it can look intimidating to those raised on the GUI, working with the Command Line is actually quite simple. Instead of pointing and clicking on things to make them happen, you type written commands. The figure below shows a new, empty Command Line Interface in the Mac Terminal application The Command Line prompt contains a lot of valuable information. The beginning of the line, “(base) MacPro-F5KWP01GF694” tells us exactly which computer we are communication with. This may seem redundant, but it is actually possible to interact with computers other than the one you are typing on by connecting to them via the Command Line over the network. The bit of information after the colon, in this example the “~” character tells us where in the computer’s filesystem we are. We’ll learn more about this later, for now you need to undersant that the “~” character means that you are in your home directory. The next piece of information we are given is the username under which we are logged into the computer, in this case, my local username, “cstahmer”. After the username, we see the “$” character. This is known as the Command Prompt. It is an indicator that the Command Line application is waiting for you to enter something. The Command Prompt character is used througout these materials when giving command examples. When working through materials, DO NOT ENTER the Command Prompt. It will already be there telling you that the computer is ready to receive your command. Depending on your system and/or Command Line interface, you may or may not also see a solid or flashing box that appears after the Command Prompt. This is a Cursor Position Indicator, which tells you where the current cursor is in the terminal. This is useful if you need to go gack and correct an error. Generally speaking, you can’t click a mouse in a terminal app to edit text. You need to use your computer’s right and left arrows to move the cursor to the correct location and then make your edit. As noted earlier, we interact with the Command Line by typing commands. The figure below shows an example of a simple command, “echo” being entered into the Command Line. The “echo” command prints back to screen any text that you supply to the command It literally echoes your text. To execute, this or any command, you simply hit the “return” or “enter” key on your keyboard. You’ll see that when you execute a Command Line command the sytem performs the indicated operation, prints any output from the operation to screen and then delivers a new Command Line prompt. Note that depending on your particular system and/or Command Line interface, things might look slightly different on your computer. However, the basic presentation and function as described above will be the same. 1.2 Common Command Line Commands During our hands-on, in-class session we will practice using the following Command Line commands. Be prepared to have this page ready as a reference during class to make things easier. Table 1.1: Command Name Function ls List Lists all files in the current directory. ls -l List with Long flag Lists additional information about each file. ls -a List with All flag Lists all files, including hidden files. pwd Print Working Directory Prints the current working directory. mkdir Make Directory Creates a new file directory. cd Change Directory Navigates to another directory on the file system. mv Move Moves files. cp Copy Copies files. rm Remove/delete Deletes files. For a more complete list of Unix Commands, see the Unix Cheat Sheet. 1.3 Command Line Text Editors The Command Line also features a variety of different text editors, similar in nature to Microsoft Word or Mac Pages but much more stripped down. These editors are only accessible from the Command Line; we won’t spend very much time with them, but it is important to know how to use them so that you can open, read, and write directly in the Command Line window. Macs and Git Bash both ship with a text editor called Vim (other common editors include Emacs and Nano). To open a file with vim, type vi in a Command Line window, followed by the filename. If you want to create a new file, simply type the filename you’d like to use for that file after vi. Vim works a bit differently than other text editors and word processors. It has a number of ‘modes,’ which provide different forms of interaction with a file’s data. We will focus on two modes, Normal mode and Insert. When you open a file with Vim, the program starts in Normal mode. This mode is command-based and, somewhat strangely, it doesn’t let you insert text directly in the document (the reasons for this have to do with Vim’s underlying design philosophy: we edit text more than we write it on the Command Line). To insert text in your document, switch to Insert mode by pressing i. You can check whether you’re in Insert mode by looking at the bottom left hand portion of the window, which should read -- INSERT --. Once you are done inserting text, pressing ESC (the Escape key) will bring you back to Normal mode. From here, you can save and quit your file, though these actions differ from other text editors and word processors: saving and quitting with Vim works through a sequence of key commands (or chords), which you enter from Normal mode. To save a file in Vim, make sure you are in Normal mode and then enter :w. Note the colon, which must be included. After you’ve entered this key sequence, in the bottom left hand corner of your window you should see “[filename] XL, XC written” (L stands for “lines” and C stands for “characters”). To quit Vim, enter :q. This should take you back to your Command Line and, if you have created a new file, you will now see that file in your window. If you don’t want to save the changes you’ve made in a file, you can toss them out by typing :q! in place of :w and then :q. Also, in Vim key sequences for save, quit, and hundreds of other commands can be chained together. For example, instead of separately inputting :w and :q to save and quite a file, you can use :wq, which will produce the same effect. There are dozens of base commands like this in Vim, and the program can be customized far beyond what we need for our class. More information about this text editor can be found here. 1.4 Basic Vim Commands Table 1.2: Command Function esc Enter Normal mode. i Enter Insert mdoe. :w Save. :q Quit. :q! Quit without saving. For a more complete list of Vim commands, see this Cheat Sheet. "],["introduction-to-version-control.html", "2 Introduction to Version Control 2.1 What is Version Control? 2.2 Software Assisted Version Control 2.3 Local vs Server Based Version Control 2.4 Central Version Control Systems 2.5 Distributed Version Control Systems 2.6 The Best of Both Worlds 2.7 VCS and the Computer File System 2.8 How Computers Store and Access Information 2.9 How VCS Manage Your Files 2.10 Graph-Based Data Management 2.11 Additional Resources", " 2 Introduction to Version Control This section covers the basics of using Version Control Software (VCS) to track and record changes to files on your local computer. It provides background information that will help you to better understand what VCS is, why we use it, and how it does its work. 2.1 What is Version Control? Version control describes a process of storing and organizing multiple versions (or copies) of documents that you create. Approaches to version control range from simple to complex and can involve the use of various human workflows and/or software applications to accomplish the overall goal of storing and managing multiple versions of the same document(s). Most people have a folder/directory somewhere on their computer that looks something like this: Or perhaps, this: This is a rudimentary form of version control that relies completely on the human workflow of saving multiple versions of a file. This system works minimally well, in that it does provide you with a history of file versions theoretically organized by their time sequence. But this filesystem method provides no information about how the file has changed from version to version, why you might have saved a particular version, or specifically how the various versions are related. This human-managed filesystem approach is more subject to error than software-assisted version control systems. It is not uncommon for users to make mistakes when naming file versions, or to go back and eit files out of sequence. Software-assisted version control systems (VCS) such as Git were designed to solve this problem. 2.2 Software Assisted Version Control Version control software has its roots in the software development community, where it is common for many coders to work on the same file, sometimes synchronously, amplifying the need to track and understand revisions. But nearly all types of computer files, not just code, can be tracked using modern version control systems. IBM’s OS/360 IEBUPDTE software update tool is widely regarded as the earliest and most widely adopted precursor to modern, version control systems. Its release in 1972 of the Source Code Control System (SCCS) package marked the first, fully fledged system designed specifically for software version control. Today’s marketplace offers many options when it comes to choosing a version control software system. They include systems such as Git, Visual Source Safe, Subversion, Mercurial, CVS, and Plastic SCM, to name a few. Each of these systems offers its twist on version control, differing sometimes in the area of user functionality, sometimes in how it handles things on the back-end, and sometimes both. This tutorial focuses on the Git VCS, but in the sections that follow we offer some general information about classes of version control systems to help you better understand how Git does what it does and help you make more informed decisions about how to deploy it for you own work. 2.3 Local vs Server Based Version Control There are two general types of version control systems: Local and Server (sometimes called Cloud) based systems. When working with a Local version control system, all files, metadata, and everything associated with the version control system live on your local drive in a universe unto itself. Working locally is a perfectly reasonable option for those who work independently (not as part of a team), have no need to regularly share their files or file versions, and who have robust back-up practices for their local storage drive(s). Working locally is also sometimes the only option for projects involving protected data and/or proprietary code that cannot be shared. Server based VCS utilize software running on your local computer that communicates with a remote server (or servers) that store your files and data. Depending on the system being deployed, files and data may reside exclusively on the server and are downloaded to temporary local storage only when a file is being actively edited. Or, the system may maintain continuous local and remote versions of your files. Server based systems facilitate team science because they allow multiple users to have access to the same files, and all their respective versions, via the server. They can also provide an important, non-local back-up of your files, protecting you from loss of data should your local storage fail. Git is a free Server based version control system that can store files both locally and on a remote server. While the sections that follow offer a broader description of Server based version control, in this workshop we will focus only on using Git locally and will not configure the software to communicate with, store files on, or otherwise interact with a remote server. DataLab’s companion “Git for Teams” workshop focuses on using Git with the GitHub cloud service to capitalize on Git’s distributed version control capabilities. Server based version control systems can generally be segmented into two distinct categories: 1) Centralized Version Control Systems (Centralized VCS) and 2) Distributed Version Control Systems (Distributed VCS). 2.4 Central Version Control Systems Centralized VCS is the oldest and, surprisingly to many, still the dominant form of version control architecture worldwide. Centralized VCS implement a “spoke and wheel” architecture to provided server based version control. With the spoke and wheel architecture, the server maintains a centralized collection of file versions. Users utilize version control clients to “check-out” a file of interest to their local file storage, where they are free to make changes to the file. Centralized VCS typically restrict other users from checking out editable versions of a file if another user currently has the file checked out. Once the user who has checked out the file has finished making changes, they “check-in” their new version, which is then stored on the server from where it can be retrieved and “checked-out” by another user. As can be seen, Centralized VCS provide a very controlled and ordered universe that ensures file integrity and tracking of changes. However, this regulation comes at a cost. Namely, it reduces the ease with which multiple users can work simultaneously on the same file. 2.5 Distributed Version Control Systems Distributed VCS are not dependent on a central repository as a means of sharing files or tracking versions. Distributed VCS implement a network architecture (as opposed to the spoke and wheel of the Centralized VCS as pictured above) to allow each user to communicate directly with every other user. In Distributed VCS, each user maintains their own version history of the files being tracked, and the VCS software communicates between users to keep the various local file systems in sync with each other. With this type of system, the local versions of two different users will diverge from each other if both users make changes to the file. This divergence will remain in place until the local repositories are synced, at which time the VCS stitches (or merges) the two different versions of the file into a single version that reflects the changes made by each individual, and then saves the stitched version of the file onto both systems as the current version. Various mechanisms can then be used to resolve the conflicts that may arise during this merge process. Distributed VCS offer greater flexibility and facilitate collaborative work, but a lack of understanding of the sync/merge workflow can cause problems. It is not uncommon for a user to forget to synch their local repository with the repositories of other team members and, as a result, work for extended periods of time on outdated files that don’t reflect their teammates and result in work inefficiencies and merge challenges. 2.6 The Best of Both Worlds An important feature of Distributed VCS is that many users and organizations choose to include a central server as a node in the distributed network. This creates an hybrid universe in which some users will sync directly to each other while other users will sync through a central server. Syncing with a cloud-based server provides an extra level of backup for your files and also facilitates communication between users. But treating the server as just another node on the network (as opposed to a centralized point of control) puts the control and flexibility back in the hands of the individual developer. For example, in a true Centralized CVS, if the server goes down then nobody can check files in and out of the server, which means that nobody can work. But in a Distributed CVS this is not an issue. Users can continue to work on local versions and the system will sync any changes when the server becomes available. Git, which is the focus of this tutorial, is a Distributed VCS. You can use Git to share and sync repositories directly with other users or through a central Git server such as, for example, GitHub or GitLab. 2.7 VCS and the Computer File System When we think about Version Control, we typically think about managing changes to individual files. From the user perspective, the File is typically the minimum accessible unit of information. Whether working with images, tabular data, or written text, we typically use software to open a File that contains the information we want to view or edit. As such, it comes as a surprise to most users that the concept of Files, and their organizing containers (Folders or Directories), are not intrinsic to how computers themselves store and interact with data. In this section of the tutorial we will learn about how computers store and access information and how VCS interact with this process to track and manage files. 2.8 How Computers Store and Access Information For all of their computing power and seeming intelligence, computers still only know two things: 0 and 1. In computer speak, we call this a binary system, and the unit of memory on a hard-disk, flash drive, or computer chip that stores each 1 or 0 is called a bit. You can think of your computer’s storage device (regardless of what kind it is) as a presenting a large grid, where each box is a bit: In the above example, as with most computer storage, the bits in our storage grid are addressable, meaning that we can designate a particular bit using a row and column number such as, for example, A7, or E12. Also, remember, that each bit can only contain one of two values: 0 or 1. So, in practice, our storage grid would actually look something like this: All of the complex information that we store in the computer is translated to this binary language prior to storage using a system called Unicode. You can think of Unicode as a codebook that assigns a unique combination of 8, 16, 32, 64, etc. (depending on how old your computer is) ones and zeros to each letter, numeral, or symbol. For example, the 8-bit Unicode for the upper case letter “A” is “01000001”, and the 8-bit Unicode character for the digit “3” is “00110011”. The above grid actually spells out the phrase, “Call me Ishmael”, the opening line of Herman Melville’s novel Moby Dick. An important aspect of how computers story information in binary form is that, unlike most human readable forms of data storage, there is no right to left, up or down, or any other regularized organization of bits on a storage medium. When you save a file on your computer, the computer simply looks for any open bits and starts recording information. The net result is that the contents of single file are frequently randomly interleaved with data from other files. This mode of storage is used because it maximizes the use of open bits on the storage device. But it presents the singular problem of not making data readable in a regularized, linear fashion. To solve this problem, all computers reserve a particular part of their internal memory for a “Directory” which stores a sector map of all chunks of data. For example, if you create a file called README.txt with the word “hello” in it, the computer would randomly store the Unicode for the five characters in the word “hello” on the storage device and make a directory entry something like the following: Understanding the Directory concept and how computers store information is crucial to understanding how VCS mange your Files. 2.9 How VCS Manage Your Files Most users think about version control as a process of managing files. For example, if I might have a directory called “My Project” that holds several files related to this project as follows: One approach to managing changes to the above project files would be to store multiple versions of each file as in the figure below for the file analysis.r: In fact, many VCS do exactly this. They treat each file as the minimum unit of data and simply save various versions of each file along with some additional information about the version. This approach can work reasonably well. However, it has limitations. First, this approach can unnecessarily consume space on the local storage device, especially if you are saving many versions of a very large file. It also has difficulty dealing with changes in filenames, typically treating the same file with a new name as a completely new file, thereby breaking the chain of version history. To combat these issues, good VCS don’t actually manage files at all. They manage Directories. Distributed VCS like Git take this alternate approach to data storage that is Directory, rather than file, based. 2.10 Graph-Based Data Management Git (and many other Distributed VCS) manage your files as collections of data rather than collections of files. Git’s primary unit of management is the “Repository,” or “Repo” for short, which is aligned with your computer’s Directory/Folder structure. Consider, for example, the following file structure: Here we see a user, Tom’s, home directory, which contains three sub directories (Data, Thesis, and Tools) and one file (Notes.txt). Both the Data and Tools directories contain sub files and/or directories. If Tom wanted to track changes to the two files in the Data directory, he would first create a Git repository by placing the Data directory “under version control.” When a repository is created, the Git system writes a collection of hidden files into the Data Directory that it uses to store information about all of the data that lives under that directory. This includes information about the addition, renaming, and deletion of both files and folders as well as information about changes to the data contained in the files themselves. Additions, deletions and versions of files are tracked and stored not as copies of files, but rather as a set of instructions that describes changes made to the underling data and the directory structure that describes them. 2.11 Additional Resources The Git Book is the defintive Git resource and provides an excellent reference for everythign that we will cover in the Interactive session. There is no need to read the book prior to the session, but it’s a good reference resource to have avaialable as you begin to work with Git after the workshop. "],["introduction-to-git.html", "3 Introduction to Git 3.1 Save, Stage, Commit 3.2 Creating Your First Repo 3.3 Checking the Status of a Repo 3.4 Version of a File 3.5 View a History of Your Commits 3.6 Comparing Commits 3.7 Comparing Files 3.8 To View an Earlier Commit 3.9 Undoing Things 3.10 When Things go Wrong!", " 3 Introduction to Git Put some intro text here 3.1 Save, Stage, Commit Git does not automatically preserve versions of every “saved” file. When working with Git, you save files as you always do, but this has no impact on the versions that are preserved in the repository. To create a “versions”, you must first add saved files to a Staging area and then “Commit” your staged files to the repository. The Commits that you make constituted the versions of files that are preserved in the repository. 3.2 Creating Your First Repo Move to your Home directory $ cd ~ note: The $ character represents your command promt. DO NOT type it into your terminal Create a new directory for this workshop $ mkdir introtogit Change to the new directory $ cd introtogit Put the new directory under version control $ git init 3.3 Checking the Status of a Repo To check the status of a repository use the followign command $ git status 3.4 Version of a File In Gitspeak, we ‘commit’ if version of a file to the repository to save a copy of the current working version of a file as a version. This is a multi-step process in which we first ‘stage’ the file to be committed and then ‘commit’ the file. STEP 1: Place the file you want to version into the Staging Area $ git add &lt;filename&gt; Replace in the command above with the actual name of the file you want to version. STEP 2: Commit Staged Files $ git commit -m &#39;A detailed comment explaining the nature of the versio being committed. Do not include any apostrophe&#39;s in your comment.&#39; 3.5 View a History of Your Commits To get a history of commits $ git log To see commit history with patch data (insertions and deletions) for a specified number of commits $ git log -p -2 To see abbreviated stats for the commit history $ git log --stat You can save a copy of your Git log to a text file with the following command: $ git --no-pager log &gt; log.txt 3.6 Comparing Commits $ git diff &lt;commit&gt; &lt;commit&gt; 3.7 Comparing Files $ git diff &lt;commit&gt; &lt;file&gt; or $ git diff &lt;commit&gt;:&lt;file&gt; &lt;commit&gt;:&lt;file&gt; 3.8 To View an Earlier Commit $ git checkout &lt;commit&gt; To solve Detached Head problem either RESET HEAD as described below or just chekout another branch git checkout &lt;branch&gt; To save this older version as a parallel branch execute $ git checkout -b &lt;new_branch_name This will save the older commit as a new branch running parallel to master. 3.9 Undoing Things One of the common undos takes place when you commit too early and possibly forget to add some files, or you mess up your commit message. If you want to redo that commit, make the additional changes you forgot, stage them, and commit again using the –amend option $ git commit --amend To unstage a file for commit use $ git reset HEAD &lt;file&gt; Throwing away changes you’ve made to a file $ git checkout -- &lt;file&gt; Rolling everything back to the last commit $ git reset --hard HEAD Rolling everything back to the next to last commit (The commit before the HEAD commit) $ git reset --hard HEAD^ Rolling everything back tp two commits before the head $ git reset --hard HEAD^2 Rolling everything back to an identified commit using HASH/ID from log $ git reset --hard &lt;commit&gt; 3.10 When Things go Wrong! To reset everything back to an earlier commit and make sure that the HEAD pointer is pointing to the newly reset HEAD, do the following $ git reset --hard &lt;commit&gt; $ git reset --soft HEAD@{1} "],["git-branching.html", "4 Git Branching 4.1 Merging Branches 4.2 Branching Workflows", " 4 Git Branching Branching provides a simple way to maintain multiple, side-by-side versions of the files in a repository. Conceptually, branching a repository creates a copy of the codebase in its current state that you can work on without affecting the primary version from which it was copied. This alows you to work down multiple paths without affecting the main (or other) codebase. To see a list of branches in your repository $ git branch To create a new branch $ git checkout -b hotfix New branches are created of the current working branch. To change branches use $ git checkout &lt;branch name&gt; 4.1 Merging Branches When you merge a branch, git folds any changes that you made to files in an identified branch into the current working branch. It also adds any new files. When you perform a merge, a new commit will be automatically created to track the merge. To merge branches, commit any changes to the branch you want to merge (in this example, the ‘hotfix’ branch) then checkout the branch into which you want to merge (for example, master), and then execute a merge command. $ git commit -m &#39;commiting staged files in hotfix branch&#39; $ git checkout master $ git merge hotfix 4.2 Branching Workflows "],["introduction-to-r.html", "5 Introduction to R 5.1 Learning objectives 5.2 Before We Start 5.3 Mathematical Operations 5.4 HELP! 5.5 Calls 5.6 Variables 5.7 Data Types and Classes 5.8 Vectors 5.9 Matrices, Arrays &amp; Lists 5.10 Data Frames 5.11 Subsetting", " 5 Introduction to R 5.1 Learning objectives After this lecture, you should be able to: define reproducible research and the role of programming languages explain what R and RStudio are, how they relate to eachother, and identify the purpose of the different RStudio panes create and save a script file for later use; use comments to annotate solve simple mathematical operations in R create variables and dataframes inspect the contents of vectors in R and manipulate their content subset and extract values from vectors use the help function 5.2 Before We Start What is R and RStudio? “R” is both a free and open source programming language designed for statistical computing and graphics, and the software for interpreting the code written in the R language. RStudio is an integrative development environment (IDE) within which you can write and execute code, and interact with the R software. It’s an interface for working with the R software that allows you to see your code, plots, variables, etc. all on one screen. This functionality can help you work with R, connect it with other tools, and manage your workspace and projects. You cannot run RStudio without having R installed. While RStudio is a commercial product, the free version is sufficient for most researchers. Why learn R? There are many advantages to working with R. Scientific integrity. Working with a scripting language like R facilitates reproducible research. Having the commands for an analysis captured in code promotes transparency and reproducibility. Someone using your code and data should be able to exactly reproduce your analyses. An increasing number of research journals not only encourage, but are beginning to require, submission of code along with a manuscript. Many data types and sizes. R was designed for statistical computing and thus incorporates many data structures and types to facilitate analyses. It can also connect to local and cloud databases. Graphics. R has buit-in plotting functionalities that allow you to adjust any aspect of your graph to effectively tell the story of your data. Open and cross-platform. Because R is free, open-source software that works across many different operating systems, anyone can inspect the source code, and report and fix bugs. It is supported by a large community of users and developers. Interdisciplinary and extensible. Because anyone can write and share R packages, it provides a framework for integrating approaches across domains, encouraging innovation. Navigating the interface Source is your script. You can save this as a .R file and re-run to reproduce your results. Console - this is where you run the code. You can type directly here, but it won’t save anything entered here when you exit RStudio. Environment/history lists all the objects you have created and the commands you have run. Files/plots/packages/help/viewer pane is useful for locating files on your machine to read into R, inspecting any graphics you create, seeing a list of available packages, and getting help. To interact with R, compose your code in the script and use the commands execute (or run) to send them to the console. (Shortcuts: You can use the shortcut Ctrl + Enter, or Cmd + Return, to run a line of code). Create a script file for today’s lecture and save it to your lecture_4 folder under ist008_2021 in your home directory. (It’s good practice to keep your projects organized., Some suggested sub-folders for a research project might be: data, documents, scripts, and, depending on your needs, other relevant outputs or products such as figures. 5.3 Mathematical Operations R works by the process of “REPL”: Read-Eval-Print Loop: R waits for you to type an expression (a single piece of code) and press Enter. R then reads in your commands and parses them. It reads whether the command is syntactically correct. If so, it will then evaluate the code to compute a result. R then prints the result in the console and loops back around to wait for your next command. You can use R like a calculator to see how it processes commands. Arithmetic in R follows an order of operations (aka PEMDAS): parenthesis, exponents, multiplication and division, addition and subtraction. 7 + 2 7 - 2 244/12 2 * 12 To see the complete order of operations, use the help command: ?Syntax 5.4 HELP! This is just the beginning, and there are lots of resources to help you learn more. R has built-in help files that can be accessed with the ? and help() commands (to get help with arithmetic commands, you must put the symbol in single or double quotes). You can search within the help documentation using the ?? commands. You can view the package documentation using packageDescription(\"Name\"). And, you can always ask the community: Google, Stack Overflow [r], topic-specific mailing lists, and the R-help mailing list. On CRAN, check out the Intro to R Manual and R FAQ. When asking for help, clearly state the problem and provide a reproducible example. R also has a posting guide to help you write questions that are more likely to get a helpful reply. It’s also a good idea to save your sessionInfo() so you can show others how your machine and session was configured. 5.5 Calls R has many functions (reusable commands) built-in that allow you to compute mathematical operations, statistics, and other computing tasks. Code that uses a function is said to call that function. When you call a function, the values that you assign as input are called arguments. Some functions have multiple parameters and can accept multiple arguments. log(10) sqrt(9) sum(5, 4, 1) 5.6 Variables A variable is a name for a stored value. Variables allow you to reuse the result of a computation, write general expressions (such as a*x + b), and break up your code into smaller steps so it’s easier to test and understand. Variable names can contain letters or numbers, but they cannot begin with a number. In general, variable names should be descriptive but concise, and should not use the same name as common (base R) functions, like mean, T, median, sum, etc. x &lt;- 10 y &lt;- 24 fantastic.variable2 = x x&lt;-y/2 In R, variables are copy-on-write. When we change a variable (a “write”), R automatically copies the original value so dependent variables are unchanged until they are re-run. x = 13 y = x x = 16 y 5.7 Data Types and Classes R categorizes data into different types that specify how the object is stored in memory. Some common types are: character (\"marie curie\", \"grace hooper\") complex (3i) double (2, 3, 5.7) integer (2L, 4L) logical (TRUE, FALSE) Types higher in the list are more general than types lower in the list. For instance, we can represent a logical value as a character string (\"TRUE\", \"FALSE\"), but can’t represent an arbitrary character string as a logical value. R will automatically convert objects to more general types as needed (but not to less general types!). Perhaps more useful than types for day-to-day programming is an object’s class, which specifies how it behaves in R. There are classes that correspond to each of the data types above, with the same name (exception: the class for type double is called numeric). Other classes also exist, and an object can have multiple classes. You can check the class of an object with class(): x &lt;- 2 class(x) y &lt;- &quot;two&quot; class(y) class(TRUE) class(mean) R’s types and classes differ from how we categorize data in statistics: continuous (real numbers) discrete (integers, or finite number of values) logical (1 or 0, T or F) nominal (unordered categorical values) ordinal (ordered categorical values) graph (network data) character (text data) 5.8 Vectors A vector is an ordered collection of values. The elements in the vector must have the same data type. (While class and type are independent, for vectors they are typically the same and thus you can expect that they typically should have the same class.) You can combine or concatenate values to create a vector using c(). v&lt;-c(16, 3, 4, 2, 3, 1, 4, 2, 0, 7, 7, 8, 8, 2, 25) class(v) place &lt;- c(&quot;Mandro&quot;, &quot;Cruess&quot;, &quot;ARC&quot;, &quot;CoHo&quot;, &quot;PES&quot;, &quot;Walker&quot;, &quot;ARC&quot;, &quot;Tennis Courts&quot;, &quot;Library&quot;, &quot;Arboretum&quot;, &quot;Arboretum&quot;, &quot;Disneyland&quot;, &quot;West Village&quot;, &quot;iTea&quot;, &quot;MU&quot;) class(place) What happens if you make a typo or try to combine different data types in the same vector? R resolves this for you and automatically converts elements within the vector to be the same data type. It does so through implicit coercion where it conserves the most information possible (logical -&gt; integer -&gt; numeric -&gt; complex -&gt; character). Sometimes this is very helpful, and sometimes it isn’t. 5.8.1 Basic Statistics on Vectors You can use functions built into R to inspect a vector and calculate basic statistics. length(v) # returns how many elements are within the object length(place) min(v) # minimum value max(v) # maximum value mean(v) median(v) sd(v) # standard deviation 5.9 Matrices, Arrays &amp; Lists Matrices are two-dimensional containers for values. All elements within a matrix must have the same data type. Arrays generalize vectors and matrices to higher dimensions. In contrast, lists are containers for elements with different data types. 5.10 Data Frames We frequently work with 2-dimensional tables of data. For a tabular data set, typically each row corresponds to a single subject and is called an observation. Each column corresponds to the data measures or responses – a feature or covariable. (Sometimes people will also refer to these as variables, but that can be confusing as “variable” means something else in R, so here we’ll try to avoid that term.) R’s structure for tabular data is the data frame. A data frame is a list of column vectors. Thus, elements of a column must all have the same type (like a vector), but elements of a row can have different types (like a list). Additionally, every row must be the same length. To make a data frame in R, you can combine vectors using the data.frame() command. distance.mi &lt;- c(3.1, 0.6, 0.8, 0.2, 0.5, 0.2, 0.7, 0.5, 0, 1.2, 1.2, 501, 1.6, 0.4, 4.7) time.min &lt;- v major &lt;- c(&quot;nutrition&quot;, &quot;psychology&quot;, &quot;global disease&quot;, &quot;political science&quot;, &quot;sociology&quot;, &quot;sustainable agriculture&quot;, &quot;economics&quot;, &quot;political science&quot;, &quot;undeclared&quot;, &quot;psychology&quot;, &quot;undeclared&quot;,&quot;economics&quot;,&quot;political science&quot;, &quot;english&quot;, &quot;economics&quot;) my.data &lt;- data.frame(place, distance.mi, time.min, major) 5.10.1 Inspecting Data Frames You can print a small dataset, but it can be slow and hard to read especially if there are a lot of coumns. R has many other functions to inspect objects: head(my.data) tail(my.data) nrow(my.data) ncol(my.data) ls(my.data) rownames(my.data) str(my.data) summary(my.data) 5.11 Subsetting Sometimes you will want to work with only specific elements in a vector or data frame. To do that, you can refer to the position of the element, which is also also called the index. length(time.min) time.min[15] You can also subset by using the name of an element in a list. The $ operator extracts a named element from a list, and is useful for extracting the columns from data frames. How can we use subsetting to look only at the distance response? my.data$distance.mi my.data[,2] distances2&lt;-my.data[[&quot;distance.mi&quot;]] distances3&lt;-my.data[[2]] What are the responses for political science majors? polisci_majors &lt;- my.data[which(my.data$major == &#39;political science&#39;), ] View(polisci_majors) which(my.data$major == &quot;political science&quot;) shortframe&lt;-my.data[c(4,8,13),] What are the majors of the first 5 students who replied? shortframe2 &lt;- my.data[1:5,&quot;major&quot;] # range for rows, columns You can also use $ to create an element within the data frame. my.data$mpm &lt;- my.data$distance.mi / my.data$time.min Factors* are the class that R uses to represent categorical data. Levels are categories of a factor. levels(my.data$major) "],["control-structures.html", "6 Control Structures 6.1 If Statement 6.2 Relationship Operators 6.3 If Else Statement 6.4 ifelse Statement 6.5 The switch Statement 6.6 The which Statement", " 6 Control Structures Control Structures are functions in computer programming the evaluate conditions (like, for example, the value of a variable) and change the way code behaves based upon evaluated values. For example, you might to perform one function if the value stored in the variable x is greater than 5 and a different function if it is less than less than 5. The Wikiversit Control Structures page contains a good, general description of control structures that is not programming language specific. The information that follows provides examples of the most frequetly used R control structures and how to implement them. For more complete documentation on control strcutures in R run the following help command: ?Control 6.1 If Statement The “If Statement” is the most basic of the R control structures. It tests whether a particular condition is true. For example, the below statement tests whether the value of the variable x is greater than 5. If it is, the code prints the phrase “Yay!” to screen. If it is not, the code does nothing: x &lt;- 7 if (x &gt; 5) { print(&quot;Yay!&quot;) } Note, the general syntax in the example is: control_statement (condition) { #code to execute condition is true } While you will occasionally see variations in how control structures are present, this is a fairly universal syntax across computer programming languages. The specific control structure being invoked is followed by the condition to be tested. Any actions to be performed if the condition evaluates to TRUE are place between curly brackets {} following the condition. 6.2 Relationship Operators The most common conditions evaluate whether one value is equal to ( x == y), equal to or greater than (x =&gt; y), equal to or lesser than (x &lt;= y), greater than (x &gt; y), or lesser than (x &lt; y) another value. Another common task is to test whether a BOOLEAN value is TRUE or FALSE. The syntax for this evaluation is: if (*x*) { #do something} Control structures in R also have a negation symbol which allows you to specify a negative condition. For example, the conditional statement in the following code evaluates to TRUE (meaning any code placed between the curly brackets will be executed) if the x IS NOT EQUAL to 5: if (x !=5) { #do something} 6.3 If Else Statement The “If Else” statement is similar to the “If Statement,” but it allows you specify one code path to execute if the conditional evaluates to TRUE and another to execute if the conditional evaluates to FALSE: x &lt;- 7 if (x &gt; 5) { print(&quot;Yay!&quot;) } else { print(&quot;Boo!&quot;) } 6.4 ifelse Statement R also offers a combined if/else syntax for quick execution of small code chunks: x &lt;- 12 ifelse(x &lt;= 10, &quot;x less than 10&quot;, &quot;x greater than 10&quot;) 6.5 The switch Statement The switch statement provides a mechanism for selecting between multiple possible conditions. For example, the following code returns one of several possible values from a list based upon the value of a variable: x &lt;- 3 switch(x,&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;) Note: if you pass switch a value that exceeds the number of elements in the list R will not compute a reply. 6.6 The which Statement The which statement is not a true conditional statement, but it provides a very useful way to test the values of a dataset and tell you which elements match a particular condition. In the example below, we load the R IRIS dataset and find out which rows have a Petal.Length greater than 1.4: data(&quot;iris&quot;) rows &lt;- which(iris$Petal.Length &gt; 1.4) note: you can see all of the R. build in datasets with the data() command. "],["iterating-loops.html", "7 Iterating (Loops) 7.1 For i in x Loops 7.2 While Loops 7.3 Repeat Loops 7.4 Break and Next 7.5 Iterating Data.Frame Rows in R 7.6 lapply()", " 7 Iterating (Loops) In computer programming iteration is a specific type of control structure that repeatedly runs a specified operation either for a set numbe of iterations or untul some condition is met. For example, you might want your code to peform the same math operation on all of the numbers stored in a vector of values; or perhaps you want the computer to look through a list until it finds the first entry with a value greater than 10; or, maybe you just want the computer to sound an alarm exactly 5 times. Each of these is a type of iteration or “Loop” as they are also commonly called. 7.1 For i in x Loops The most common type of loop is the “For i in x” loop which interates through each value (i) in a list (x) and does something with each value. For example, assume that x is a vector containing the following four names names: Sue, John, Heather, George, and that we want to print each of these names to screen. We can do so with the followig code: x &lt;- c(&quot;Sue&quot;, &quot;John&quot;, &quot;Heather&quot;, &quot;George&quot;) for (i in x) { print(i) } In the first line of code, we create our vecctor of names (x). Next we begin our “For i in x loop”, which has the following general syntax, which is similar to that of the conditional statements you’ve already mastered: for (condition) {} Beginning with the first element of the vector x, which in our case is “Sue”, for each iteration of the for loop the value of the corresponding element in x is assiged to the variable i and then i can be acted upon in the code icnluded between the curly brackets of the function call. In our case we simply tell the conputer to print the value of i to the sreen. Witgh each iteration, the next value in our vector is assigned to i and is subsequently printed to screen, resulting in the following output: [1] &quot;Sue&quot; [1] &quot;John&quot; [1] &quot;Heather&quot; [1] &quot;George&quot; In addition to acting on vectors or lists, For loops can also be coded to simply execute a chunk of code a designated number of times. For example, the following code will print “Hello World!” to screen exactly 10 times: for (i in 1:10) { print(&quot;Hello World!&quot; } 7.2 While Loops Unlike For loops, which iterate a defined number of times based on the length of a list of range of values provided in the method declaration, While loops continue to iterate infinitely as long as (while) a defined condition is met. For example, assume you have a boolean variable x the value of which is TRUE. You might want to write code that performs some function repeatly until the value of x is switched to FALSE. A good example of this is a case where your program asks the user to enter data, which can then be evaluated for correctness before the you allow the program to move on in its execution. In the example below, we ask the user to tell us the secret of the universe. If the user answeres with the correct answer (42), the code moves on. But if the user provides and incorrect answer, the code iterates back to the beginning of the loop and asks for input again. response &lt;- 0 while (response!=42) { response &lt;- as.integer(readline(prompt=&quot;What is the answer to the Ultimate Question of Life, the Universe, and Everything? &quot;)); } 7.3 Repeat Loops Like While loops, Repeat loops continue to iterate until a specified condition is met; but with Repeat loops that condition is defined not as an argument to the function but is a specific call to “break” that appears in the functions executable code. In the example below we assign the value 1 to a variable i and then loop through code that prints and then iterates the value of i until it reaches 10, at which time we forceably exit the loop: i &lt;- 1 repeat { print(i) i = i+1 if (i &gt; 10){ break } } 7.4 Break and Next In the previous section we saw the use of the break statement to force an exit from a repeat loop based on a conditional evaluation in an if statement. Break can actually be used inside any conditional (for, while, repeat) in order to force the end of iteration. This can be useful in a variety of contexts where you want to test for multiple conditions as a means of stopping iteration. The next command is similar to break in that it can be used inside any iteration structure to force R to skip execution of the iteration code for particular cases only. For example, we use next below to iterate through the nunbers 1 to 10 and print all values to screen EXCEPT the value 5: for (i in 1:10) { if (i == 5){ next } print(i) } 7.5 Iterating Data.Frame Rows in R In the section on for loops above, we learned that you can easily iterate across all values of a list using a “for i in x” loop. Working with R data.frames adds a bit of complexity to this process. Because R was developed as a language for statistial analysis, which always involves the comparison of multiple observations of the same variable (for example, all of the weights recroded across all patients), the default behavior of the “for i in x” loop when applied to data.frames is to iterate across columns (variables) rather than rows (observations). Consider the following example: for (i in iris) { print(i) } If you run the above code, in the first iteration R will assign the vector of values contained in the firt column (Sepal.Length) to i, in the second iteration it will assign vectore of values contained in the second column (Sepal.Width) to i, etc. Iterating through the data columns of a data.frame is useful for many (if not most) operations. However, there are time when we want to iterate through data one observation at a time. To accomplish this, we nee do specifically direct R to move through the data.frame by row, as follows: for (i in 1:nrow(iris)) { thisrow &lt;- iris[i,] print(thisrow) } 7.6 lapply() R has a built-in class of functions known as the apply family that provide a shorthand for iterating through collections of data. These behave like a for loop, but require much less actual code to accomplish. The lapply function iterates across lists, such as vectors. When you invoke lapply it applies a defined operation to each item in the subitted list and returns a list of equal length that contains the results of this calculation. In the code below, we assign the values 1 through 10 to a vector and then use lapply to subtract 1 from each item in the vector and finally print the results to screen: v &lt;- c(1:10) results &lt;- lapply(v, function(x) (x-1)) print(results) We could accomplish the exact same thing with the following for loop v &lt;- c(1:10) for (i in v) { x &lt;- i - 1 print(x) } The basic syntax of lapply is: lapply(list, function) where “list” is some list object supplied and “function” is pre-defined chunk of code that will be exectuted. You’ll learn more about functions in a future lesson. "],["packages-and-functions.html", "8 Packages and Functions 8.1 Learning objectives 8.2 What is a function? 8.3 What is the basic syntax of a function in R? 8.4 Step 1: Building a function 8.5 Step 2: Calling the function 8.6 A function can have more than one argument 8.7 Using a package and function to graph data and export a .png 8.8 Saving functions and calling them from another file", " 8 Packages and Functions 8.1 Learning objectives After this lecture, you should be able to: explain what a function is read and understand the basic syntax of a function in R use this syntax to call a function use this syntax to build your own function test your function install packages in R load libraries in R 8.2 What is a function? Why build code several or a hundred times when you can build it once and then call and run it as many times as you want? The answer is, don’t! A function allows you to perform an action multiple times in R by calling it and applying it in similar contexts. For instance, if you build a function that checks the class of all vectors in a dataframe, you can name this function and then apply it to do the same operation with any other dataframe. Or, if you build a function that graphs the correlation between two numeric vectors and exports this graph to a .png file, you can call this same function and apply it to two other vectors, again and again as needed. Functions can greatly increase the efficiency of your programming, and allow you to create flexible and customized solutions. 8.3 What is the basic syntax of a function in R? The basic syntax of a function in R, or the way it should be written so that R recognizes it and applies it do perform actions, is usually stated as follows: function_name &lt;- function(argument_1, argument_2, ...) { Function body } What this does not demonstrate is that there are actually two steps to a function: building it, and applying it. We will look at both steps in the following code from DataCamp: 8.4 Step 1: Building a function myFirstFun&lt;-function(n) { # Compute the square of integer `n` n*n } The code chunk builds the function, setting “myFirstFun” as the name, or variable, to which they have assigned the function. The function itself runs from the word “function” down through the closing curly brace. What is an argument? In the above example, “(n)” is the argument. R looks for this argument (in this case, “n”) in the body of the function, which in this case is n*n. When we run the above script, the function is saved as an object into the global environment so that it can be called elsewhere, as demonstrated in the code chunks below. The function has no effect unless you apply it. Until that happens, the function will do nothing but wait to be called. 8.5 Step 2: Calling the function The code chunk below calls “myFirstFun(n)” and tells R to assign the results of the operation the function performs (n*n) to the variable “u”. But if we run this code as it is (with “n” in the parentheses), we will get an error (unless we have previously assigned “n” as a variable with a value that will accept the operation to be performed — so “n” needs to be a number in this case so that it can be multiplied). We do not actually want to perform the function on the letter “n” but rather, on a number that we will insert in the place of “n.” We can apply this function by setting “n” as a number, such as 2, in the example below. # Call the function with argument `n` u &lt;- myFirstFun(2) # Call `u` u Once we have changed “n” to a number, R then performs this operation and saves the result to a new variable “u”. We can then ask R to tell us what “u” is, and R returns or prints the results of the function, which in this case, is the number 4 (2*2). The image below shows the results we get if we attempt to run the function without changing the argument “n” to a number (giving us an error), and the results when we change “n” to the number “2” which assigns the result of the function (4) to “u”, or the number “3” which assigns the result of the function (now 9) to “u”. It is important to understand that “n” is an argument of the function “myFirstFun.” R does not consider “n” a variable, but it acts like a variable because it can change as you call the function into different contexts. To R, “u” and “myFirstFun” are variables because they are names to which values and other content are assigned. Here is another example of a function with one argument: Step 1: Build the function In the code below, we will build a function that checks the classes of all vectors in a dataframe. #build function with one argument (variable) check_class &lt;- function(data) { lapply(data, class) } Step 2: Call the function in one or more contexts. In the code below, we will call the function we built above and apply it to two different datasets. Just as we saw in the example above where we inserted the numbers 2 or 3 in place of “n”, we will insert the name of the datasets we want to use in place of the word “data” to call the new function we have built. Note: you will need to load the built-in R datasets “mtcars” and “iris” in order to test the code below.* #run check_class function on two different dataframes check_class(mtcars) check_class(iris) 8.6 A function can have more than one argument A function works similarly when it has two or more arguments. Let’s say we only want to look at the first vector or column in the dataframe “mtcars.” We would write a line of code that looks like this: #pull the values of the first column /vector in the dataframe &quot;mtcars&quot; mtcars[1] But if we wanted to create a function that looks at any column/vector in any dataframe, we could write a function that looks like this: #build function with two arguments (variable) one_column &lt;- function(data, x) { data[x] } Note: if we want to tell a user what kind of input we want to include, we could instead do something like function(dataset, column_position) or function(dataset, column_name). Once we have run the above function (telling R to save it to the global environment), we would then call this new function, which we have named one_column, and apply it to various dataframes, and telling R which column or vector in each dataframe we want to view. #run one_column function on two different dataframes one_column(mtcars, 1) one_column(iris, 2) #Packages A package is a set of functions that other users and developers have made that allow R users to perform various operations. As with many applications and software, some R packages are well crafted, documented, and updated frequently, while others are not. You will want to use your best judgment and choose packages that you think will help you in your work, but will remain stable and functional. Try adding the packages below: dplyr wakefield rlang Go to Tools &gt; Install Packages in RStudio, search for the functions, and then follow the steps to install them. Once you have installed them, you will then need to load the libraries into your R environment by using the following code: #load libraries library(dplyr) library(wakefield) library(rlang) Click here to find out more about dplyr Click here to find out more about wakefield Click here to find out more about rlang If you have installed the above packages and loaded their libraries, you can then create a function that uses the table you made in the earlier session, “Introduction to R,” to add five rows of data, add a logical vector with randomly assigned logical values, and save this as a new table. Your function might look something like this code below. The comment tags indicate what each line of the function will do. Note: you will need to load in your data for my.table with the initial 15 rows before proceeding with the next steps. #Step 1: Build a function that adds a logical vector with randomly assigned TRUE/FALSE values make_logical.vec &lt;- function(dataset, new.col) { #make logical vector with random values vector_1 &lt;- r_sample_logical(15, prob = NULL, name = &quot;new.vector&quot;) %&gt;% as.logical() #tell R to read input for the name of new.col so that we can assign this name to the vector/column colName = quo_name(new.col) #add our new vector, with the name we have specified, to the dataset dataset %&gt;% mutate(!!quo_name(colName) := vector_1) #create new } #Step 2: Call our new function ‘make_logical.vec’ and assign the results to the table ‘my.data’. my.data &lt;- make_logical.vec(my.data, &quot;logical.vec&quot;) Note: If we call the function, setting the dataset to ‘my.data’ and the name of the new vector to ‘logical.vec’, it will create the dataframe but will only print it for us in our console. If we want to actually save the new dataframe to update our existing dataframe, we need to reassign it to ‘my.data’, so that the updated dataframe replaces the original dataframe. As we can see in the code above, a function can contain more than one variable, and can include several or many lines of code and perform many operations. The above example demonstrates this, and also shows that packages such as as the ones we have loaded here, while optional for working in R, can allow you to call many useful functions. 8.7 Using a package and function to graph data and export a .png We can install and load the ‘ggplot’ or ‘ggforce’ package to graph data from a dataframe and export the graph to a file. For example, below we can build a function that graphs the data from two columns/vectors, and then generates a .png file. We start by loading the package that contains the plotting functions we want to use: Note: if you have not installed ggforce already, you will want to do that now. #graph distance and time from our.data library(ggforce) Next, we could build a function that looks like this: # write function that graphs two variables from dataset graph_data &lt;- function(data, column1, column2, n) { distances &lt;- (data %&gt;% filter(column1 &lt;= &quot;n&quot;)) %&gt;% ggplot(aes(column2, column1)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) png(&quot;graph.png&quot;) print(graph) dev.off() } Lastly, we can call the above function, and apply it to the dataframe, my.table, to compare distance and time of travel. graph_data(my.data, my.data$distance.mi, my.data$time.min, 14.0) The above function generates a .png that looks like this: 8.8 Saving functions and calling them from another file You can save the functions you build to a separate file, and then load these as a source. For example, I might save my functions to an R script, called “functions.r”. I can then load these sources along with my packages into my R environment. Note: Although we loaded libraries as we went through this lesson, the best practice is to run your packages and source files at the very beginning of your new R script, as shown in the example that follows. library(dplyr) library(wakefield) library(rlang) library(ggforce) source(&quot;functions.r&quot;) The above code will allow you to call functions that are saved in these libraries and in the functions.r file. "],["file-input-and-output.html", "9 File Input and Output 9.1 Objectives 9.2 Basic Idea 9.3 File Formats 9.4 Filesystems and Paths 9.5 get and set working directory 9.6 saving and loading R data 9.7 Reading and Writing Text data 9.8 URLS as files", " 9 File Input and Output This lesson will cover some standard functions for reading and writing data in R. 9.1 Objectives getting and setting working directory save and load R objects to/from disk read and write tabular data read data from a url 9.2 Basic Idea As a data scientist, you will constantly be reading from and writing to files. Generally you are given some dataset that you need to analyze and report on. This means that you need to load the data into R, run some code, and finally save some outputs. This is all done with files. 9.3 File Formats When people talk about binary files, vs text files what they really mean is - is it human readable? A text file should have text data that a human can read with a text editor. A binary file has binary data that a human can’t really read, but the appropriate software can. 9.4 Filesystems and Paths At a high level, files are information stored on a computer. Each file has a name, and a unique file path. A filepath is the location of the file in the storage device. A file name as two parts: the name and the file extension. The file extension (everything after the .) is meant to indicate to the user (you) and the operating system what the file contains. This hint means you often times don’t need to open the file to know what kind of data it has. However, the extension is not enforced by anything, its just a useful suggestion. Paths can be relative or absolute. An absolute path is the full path through the filesystem to reach a file. A relative path is the path from some starting point to the file you want to reach. You can consider a relative path as something that needs to be combined with another path to reach a file. 9.5 get and set working directory Before we begin, we will get and set our working directory in R. You can think of the working directory as the part that gets combined with the relative path. getwd() will return the absolute file path of the working directory getwd() Call setwd to set the working directory to a path you specify as an input argument. setwd(&quot;~/Documents/file_io/&quot;) # notice the argument getwd() A really useful function in R is list.files(), which lists all the files at a given path. Listing the files should confirm for us that we are in the right place. list.files() 9.6 saving and loading R data 9.6.1 rds A simple way to save an R object directly to a file, such that it can be loaded into another R session is with the saveRDS function. saveRDS will write a single object to a specified file path. By default, it will save the object as a binary representation. This can be very useful for large objects, as the binary format will be significantly more space efficient. y = c(0,1,2,3,4) saveRDS(y, file=&quot;myvectors.rds&quot;) Confirm that it worked. list.files() The counterpart to saveRDS is readRDS. With readRDS, you can load in an rds file, which by definition contains a single R object, and assign it to a variable in your session. x = readRDS(&quot;myvector.rds&quot;) This will work for any R object. For example. saveRDS(mtcars, file=&quot;mtcars.rds&quot;) my_cars = readRDS(&quot;mtcars.rds&quot;) Saving and loading using readRDS is really powerful to save data. However, it does have a pretty significant drawback - its useless outside of R. For someone to explore the data, they would need to load R. 9.7 Reading and Writing Text data In addition to saveRDS and readRDS, R has functions for working with text files. These are commonly used for getting external data into R. And for exporting your data so that it can be used by other people. 9.7.1 tabular data Generally the data you work with in R will be tabular. Dataframes are an example of tabular data. 9.7.2 read and write table To write tabular data from a text file use the write.table function. Before running it, lets look at the documentation and understand the key arguments. ?write.table The important arguments are x, file, and sep. x is the dataframe you are saving. file is the name of the file you want to create and write to. sep is the field separator, also called delimiter. Notice that if file is left blank, then R will just print the results to the console, instead of into a file. Lets use this to explore what the sep argument does. small = head(my_cars) write.table(small) write.table(small, sep=&quot; &quot;) write.table(small, sep=&quot;.&quot;) write.table(small, sep=&quot;,&quot;) Lets write our data to a file. write.table(my_cars, file=&quot;cars.txt&quot;) list.files() # confirm it worked Now lets read the data back in. from_cars.txt = read.table(&quot;cars.txt&quot;) Always inspect your data to make sure everything worked colnames(from_cars.txt) dim(from_cars.txt) head(from_cars.txt) 9.7.3 CSV format A CSV (comma separated values) file is a text file that uses ‘,’ as the field separator. This is probably the most commonly used format for plain text tabular data. To write a csv in R use the write.csv function. This is equivalent to write.table(from_cars.txt, file=\"cars.csv\", sep=\",\") write.csv(from_cars.txt, file=&quot;cars.csv&quot;) from_cars.csv = read.csv(&quot;cars.csv&quot;) Again, double check that everything worked. head(from_cars.csv) colnames(from_cars.csv) dim(from_cars.csv) What went wrong here? In this case it was ambiguous if the first column was rownames or actual values. Lets fix it temp = from_cars.csv[, 2:12] rownames(temp) = from_cars.csv[,1] fixed = temp With these sorts of problems, you can generally fix them by using the appropriate arguments to the function calls of the read and write functions. Notice the argument in this function call. It specifies that the rownames can be read in from the first column of the tabular data in the file. from_cars.csv = read.csv(&quot;cars.csv&quot;, row.names =1) 9.7.4 Non tabular data There are functions in R for reading and writing text data that doesn’t represent tabular data. A common one is writeLines and readLines. texts = c(&quot;line one&quot;, &quot;line two&quot;) writeLines(texts, &quot;raw.txt&quot;) texts2 = readLines(&quot;raw.txt&quot;) 9.8 URLS as files Files can be transferred over the internet. URLs are a type of filepath, that denotes a filepath, and the computer that file is stored on. Many functions in R that involve reading and writing from files, can be given a url as the filepath argument. In that case, the file will be transferred over the internet, onto your computer, and then read into R. Here is an example of reading in a file from a url, using the readLines function. url = &quot;https://datalab.ucdavis.edu&quot; t = readLines(url) "],["strings-and-regular-expressions.html", "10 Strings and Regular Expressions 10.1 Printing Output 10.2 Escape Sequences 10.3 Character Encodings 10.4 The Tidyverse 10.5 The stringr Package 10.6 Regular Expressions", " 10 Strings and Regular Expressions After this lesson, you should be able to: Print strings with cat Read and write escape sequences and raw strings With the stringr package: Split strings on a pattern Replace parts of a string that match a pattern Extract parts of a string that match a pattern Read and write regular expressions, including: Anchors ^ and $ Character classes [] Quantifiers ?, *, and + Groups () 10.1 Printing Output The cat function prints a string in the R console. If you pass multiple arguments, they will be concatenated: cat(&quot;Hello&quot;) ## Hello cat(&quot;Hello&quot;, &quot;Nick&quot;) ## Hello Nick Pitfall 1: Printing a string is different from returning a string. The cat function only prints (and always returns NULL). For example: f = function() { cat(&quot;Hello&quot;) } x = f() ## Hello x ## NULL If you just want to concatenate some strings (but not necessarily print them), use paste instead of cat. The paste function returns a string. The str_c function in stringr (a package we’ll learn about later in this lesson) can also concatenate strings. Pitfall 2: Remember to print strings with the cat function, not the print function. The print function prints R’s representation of an object, the same as if you had entered the object in the console without calling print. For instance, print prints quotes around strings, whereas cat does not: print(&quot;Hello&quot;) ## [1] &quot;Hello&quot; cat(&quot;Hello&quot;) ## Hello 10.2 Escape Sequences In a string, an escape sequence or escape code consists of a backslash followed by one or more characters. Escape sequences make it possible to: Write quotes or backslashes within a string Write characters that don’t appear on your keyboard (for example, characters in a foreign language) For example, the escape sequence \\n corresponds to the newline character. Notice that the cat function translates \\n into a literal new line, whereas the print function doesn’t: x = &quot;Hello\\nNick&quot; cat(x) ## Hello ## Nick print(x) ## [1] &quot;Hello\\nNick&quot; As another example, suppose we want to put a literal quote in a string. We can either enclose the string in the other kind of quotes, or escape the quotes in the string: x = &#39;She said, &quot;Hi&quot;&#39; cat(x) ## She said, &quot;Hi&quot; y = &quot;She said, \\&quot;Hi\\&quot;&quot; cat(y) ## She said, &quot;Hi&quot; Since escape sequences begin with backslash, we also need to use an escape sequence to write a literal backslash. The escape sequence for a literal backslash is two backslashes: x = &quot;\\\\&quot; cat(x) ## \\ There’s a complete list of escape sequences for R in the ?Quotes help file. Other programming languages also use escape sequences, and many of them are the same as in R. 10.2.1 Raw Strings A raw string is a string where escape sequences are turned off. Raw strings are especially useful for writing regular expressions, which we’ll do later in this lesson. Raw strings begin with r\" and an opening delimiter (, [, or {. Raw strings end with a matching closing delimiter and quote. For example: x = r&quot;(quotes &quot; and backslashes \\)&quot; cat(x) ## quotes &quot; and backslashes \\ Raw strings were added to R in version 4.0 (April 2020), and won’t work correctly in older versions. 10.3 Character Encodings Computers store data as numbers. In order to store text on a computer, we have to agree on a character encoding, a system for mapping characters to numbers. For example, in ASCII, one of the most popular encodings in the United States, the character a maps to the number 97. Many different character encodings exist, and sharing text used to be an inconvenient process of asking or trying to guess the correct encoding. This was so inconvenient that in the 1980s, software engineers around the world united to create the Unicode standard. Unicode includes symbols for nearly all languages in use today, as well as emoji and many ancient languages (such as Egyptian hieroglyphs). Unicode maps characters to numbers, but unlike a character encoding, it doesn’t dictate how those numbers should be mapped to bytes (sequences of ones and zeroes). As a result, there are several different character encodings that support and are synonymous with Unicode. The most popular of these is UTF-8. In R, we can write Unicode characters with the escape sequence \\U followed by the number for the character in base 16. For instance, the number for a in Unicode is 97 (the same as in ASCII). In base 16, 97 is 61. So we can write an a as: x = &quot;\\U61&quot; # or &quot;\\u61&quot; x ## [1] &quot;a&quot; Unicode escape sequences are usually only used for characters that are not easy to type. For example, the cat emoji is number 1f408 (in base 16) in Unicode. So the string \"\\U1f408\" is the cat emoji. Note that being able to see printed Unicode characters also depends on whether the font your computer is using has a glyph (image representation) for that character. Many fonts are limited to a small number of languages. The NerdFont project patches fonts commonly used for programming so that they have better Unicode coverage. Using a font with good Unicode coverage is not essential, but it’s convenient if you expect to work with many different natural languages or love using emoji. 10.3.0.1 Character Encodings in Text Files Most of the time, R will handle character encodings for you automatically. However, if you ever read or write a text file (including CSV and other formats) and the text looks like gibberish, it might be an encoding problem. This is especially true on Windows, the only modern operating system that does not (yet) use UTF-8 as the default encoding. Encoding problems when reading a file can usually be fixed by passing the encoding to the function doing the reading. For instance, the code to read a UTF-8 encoded CSV file on Windows is: read.csv(&quot;my_data.csv&quot;, fileEncoding = &quot;UTF-8&quot;) Other reader functions may use a different parameter to set the encoding, so always check the documentation. On computers where the native language is not set to English, it can also help to set R’s native language to English with Sys.setlocale(locale = \"English\"). Encoding problems when writing a file are slightly more complicated to fix. See this blog post for thorough explanation. 10.4 The Tidyverse The Tidyverse is a popular collection of packages for doing data science in R. The packages are made by many of the same people that make RStudio. They provide alternatives to R’s built-in tools for: Manipulating strings (package stringr) Making visualizations (package ggplot2) Reading files (package readr) Manipulating data frames (packages dplyr, tidyr, tibble) And more Think of the Tidyverse as a different dialect of R. Sometimes the syntax is different, and sometimes ideas are easier or harder to express concisely. Whether to use base R or the Tidyverse is mostly subjective. As a result, the Tidyverse is somewhat polarizing in the R community. It’s useful to be literate in both, since both are popular. One advantage of the Tidyverse is that the packages are usually well-documented. For example, there are documentation websites and cheat sheets for most Tidyverse packages. 10.5 The stringr Package The rest of this lesson uses stringr, the Tidyverse package for string processing. R also has built-in functions for string processing. The main advantage of stringr is that all of the functions use a common set of parameters, so they’re easier to learn and remember. The first time you use stringr, you’ll have to install it with install.packages (the same as any other package). Then you can load the package with the library function: # install.packages(&quot;stringr&quot;) library(stringr) The typical syntax of a stringr function is: str_NAME(string, pattern, ...) Where: NAME describes what the function does string is the string to search within or transform pattern is the pattern to search for ... is additional, function-specific arguments For example, the str_detect function detects whether the pattern appears within the string: str_detect(&quot;hello&quot;, &quot;el&quot;) ## [1] TRUE str_detect(&quot;hello&quot;, &quot;ol&quot;) ## [1] FALSE Most of the stringr functions are vectorized: str_detect(c(&quot;hello&quot;, &quot;goodbye&quot;, &quot;lo&quot;), &quot;lo&quot;) ## [1] TRUE FALSE TRUE There are a lot of stringr functions. The remainder of this lesson focuses on three that are especially important, as well as some of their variants: str_split_fixed str_replace str_match You can find a complete list of stringr functions with examples in the documentation or cheat sheet. 10.5.1 Splitting Strings The str_split function splits the string at each position that matches the pattern. The characters that match are thrown away. For example, suppose we want to split a sentence into words. Since there’s a space between each word, we can use a space as the pattern: x = &quot;The students in this class are great!&quot; result = str_split(x, &quot; &quot;) result ## [[1]] ## [1] &quot;The&quot; &quot;students&quot; &quot;in&quot; &quot;this&quot; &quot;class&quot; &quot;are&quot; &quot;great!&quot; The str_split function always returns a list with one element for each input string. Here the list only has one element because x only has one element. We can get the first element with: result[[1]] ## [1] &quot;The&quot; &quot;students&quot; &quot;in&quot; &quot;this&quot; &quot;class&quot; &quot;are&quot; &quot;great!&quot; We have to use the double square bracket [[ operator here because x is a list (for a vector, we could use the single square bracket operator instead). Notice that in the printout for result, R gives us a hint that we should use [[ by printing [[1]]. To see why the function returns a list, consider what happens if we try to split two different sentences at once: x = c(x, &quot;Are you listening?&quot;) result = str_split(x, &quot; &quot;) result[[1]] ## [1] &quot;The&quot; &quot;students&quot; &quot;in&quot; &quot;this&quot; &quot;class&quot; &quot;are&quot; &quot;great!&quot; result[[2]] ## [1] &quot;Are&quot; &quot;you&quot; &quot;listening?&quot; Each sentence has a different number of words, so the vectors in the result have different lengths. So a list is the only way to store both. The str_split_fixed function is almost the same as str_split, but takes a third argument for the maximum number of splits to make. Because the number of splits is fixed, the function can return the result in a matrix instead of a list. For example: str_split_fixed(x, &quot; &quot;, 3) ## [,1] [,2] [,3] ## [1,] &quot;The&quot; &quot;students&quot; &quot;in this class are great!&quot; ## [2,] &quot;Are&quot; &quot;you&quot; &quot;listening?&quot; The str_split_fixed function is often more convenient than str_split because the nth piece of each input string is just the nth column of the result. For example, suppose we want to get the area code from some phone numbers: phones = c(&quot;717-555-3421&quot;, &quot;629-555-8902&quot;, &quot;903-555-6781&quot;) result = str_split_fixed(phones, &quot;-&quot;, 3) result[, 1] ## [1] &quot;717&quot; &quot;629&quot; &quot;903&quot; 10.5.2 Replacing Parts of Strings The str_replace function replaces the pattern the first time it appears in the string. The replacement goes in the third argument. For instance, suppose we want to change the word \"dog\" to \"cat\": x = c(&quot;dogs are great, dogs are fun&quot;, &quot;dogs are fluffy&quot;) str_replace(x, &quot;dog&quot;, &quot;cat&quot;) ## [1] &quot;cats are great, dogs are fun&quot; &quot;cats are fluffy&quot; The str_replace_all function replaces the pattern every time it appears in the string: str_replace_all(x, &quot;dog&quot;, &quot;cat&quot;) ## [1] &quot;cats are great, cats are fun&quot; &quot;cats are fluffy&quot; We can also use the str_replace and str_replace_all functions to delete part of a string by setting the replacement to the empty string \"\". For example, suppose we want to delete the comma: str_replace(x, &quot;,&quot;, &quot;&quot;) ## [1] &quot;dogs are great dogs are fun&quot; &quot;dogs are fluffy&quot; In general, stringr functions with the _all suffix affect all matches. Functions without _all only affect the first match. We’ll learn about str_match at the end of the next section. 10.6 Regular Expressions The stringr functions (including the ones we just learned) use a special language called regular expressions or regex for the pattern. The regular expressions language is also used in many other programming languages besides R. A regular expression can describe a complicated pattern in just a few characters, because some characters, called metacharacters, have special meanings. Letters and numbers are never metacharacters. They’re always literal. Here are a few examples of metacharacters (we’ll look at examples in the subsequent sections): Metacharacter Meaning . any single character (wildcard) \\ escape character (in both R and regex) ^ beginning of string $ end of string [ab] 'a' or 'b' [^ab] any character except 'a' or 'b' ? previous character appears 0 or 1 times * previous character appears 0 or more times + previous character appears 1 or more times () make a group More metacharacters are listed on the stringr cheatsheet, or in ?regex. The str_view function is especially helpful for testing regular expressions. It opens a browser window with the first match in the string highlighted. We’ll use it in the subsequent regex examples. The RegExr website is also helpful for testing regular expressions; it provides an interactive interface where you can write regular expressions and see where they match a string. 10.6.1 The Wildcard The regex wildcard character is . and matches any single character. For example: x = &quot;dog&quot; str_view(x, &quot;d.g&quot;) By default, regex searches from left to right: str_view(x, &quot;.&quot;) 10.6.2 Escape Sequences Like R, regular expressions can contain escape sequences that begin with a backslash. These are computed separately and after R escape sequences. The main use for escape sequences in regex is to turn a metacharacter into a literal character. For example, suppose we want to match a literal dot .. The regex for a literal dot is \\.. Since backslashes in R strings have to be escaped, the R string for this regex is \"\\\\.. Then the regex works: str_view(&quot;this.string&quot;, &quot;\\\\.&quot;) The double backslash can be confusing, and it gets worse if we want to match a literal backslash. We have to escape the backslash in the regex (because backslash is the regex escape character) and then also have to escape the backslashes in R (because backslash is also the R escape character). So to match a single literal backslash in R, the code is: str_view(&quot;this\\\\that&quot;, &quot;\\\\\\\\&quot;) Raw strings are helpful here, because they make the backslash literal in R strings (but still not in regex). We can use raw strings to write the above as: str_view(r&quot;(this\\that)&quot;, r&quot;(\\\\)&quot;) You can turn off regular expressions entirely in stringr with the fixed function: str_view(x, fixed(&quot;.&quot;)) It’s good to turn off regular expressions whenever you don’t need them, both to avoid mistakes and because they take longer to compute. 10.6.3 Anchors By default, a regex will match anywhere in the string. If you want to force a match at specific place, use an anchor. The beginning of string anchor is ^. It marks the beginning of the string, but doesn’t count as a character in the match. For example, suppose we want to match an a at the beginning of the string: x = c(&quot;abc&quot;, &quot;cab&quot;) str_view(x, &quot;a&quot;) str_view(x, &quot;^a&quot;) It doesn’t make sense to put characters before ^, since no characters can come before the beginning of the string. Likewise, the end of string anchor is $. It marks the end of the string, but doesn’t count as a character in the match. 10.6.4 Character Classes In regex, square brackets [ ] create a character class. A character class counts as one character, but that character can be any of the characters inside the square brackets. The square brackets themselves don’t count as characters in the match. For example, suppose we want to match a c followed by either a or t: x = c(&quot;ca&quot;, &quot;ct&quot;, &quot;cat&quot;, &quot;cta&quot;) str_view(x, &quot;c[ta]&quot;) You can use a dash - in a character class to create a range. For example, to match letters p through z: str_view(x, &quot;c[p-z]&quot;) Ranges also work with numbers and capital letters. To match a literal dash, place the dash at the end of the character class (instead of between two other characters), as in [abc-]. Most metacharacters are literal when inside a character class. For example, [.] matches a literal dot. A hat ^ at the beginning of the character class negates the class. So for example, [^abc] matches any one character except for a, b, or c: str_view(&quot;abcdef&quot;, &quot;[^abc]&quot;) 10.6.5 Quantifiers Quantifiers are metacharacters that affect how many times the preceeding character must appear in a match. The quantifier itself doesn’t count as a character in the match. For example, the ? quantifier means the preceeding character can appear 0 or 1 times. In other words, ? makes the preceeding character optional. For example: x = c(&quot;abc&quot;, &quot;ab&quot;, &quot;ac&quot;, &quot;abbc&quot;) str_view(x, &quot;ab?c&quot;) The * quantifier means the preceeding character can appear 0 or more times. In other words, * means the preceeding character can appear any number of times or not at all. str_view(x, &quot;ab*c&quot;) The + quantifier means the preceeding character must appear 1 or more times. Quantifiers are greedy, meaning they always match as many characters as possible. 10.6.6 Groups In regex, parentheses create a group. Groups can be affected by quantifiers, making it possible to repeat a pattern (rather than just a character). The parentheses themselves don’t count as characters in the match. For example: x = c(&quot;cats, dogs, and frogs&quot;, &quot;cats and frogs&quot;) str_view(x, &quot;cats(, dogs,)? and frogs&quot;) 10.6.7 Extracting Matches Groups are espcially useful with the stringr functions str_match and str_match_all. The str_match function extracts the overall match to the pattern, as well as the match to each group. So you can use str_match to split a string in more complicated ways than str_split, or to extract specifc pieces of a string. For example, suppose we want to split an email address: str_match(&quot;naulle@ucdavis.edu&quot;, &quot;([^@]+)@(.+)[.](.+)&quot;) ## [,1] [,2] [,3] [,4] ## [1,] &quot;naulle@ucdavis.edu&quot; &quot;naulle&quot; &quot;ucdavis&quot; &quot;edu&quot; "],["data-structures.html", "11 Data Structures 11.1 Tabular Data 11.2 Tree / Document Data Structures 11.3 Relational Databases 11.4 Non-Hierarchical Relational Data 11.5 Geospatial Data", " 11 Data Structures Merriam-Webster’s Dictionary defines data as: factual information (such as measurements or statistics) used as a basis for reasoning, discussion, or calculation information in digital form that can be transmitted or processed information output by a sensing device or organ that includes both useful and irrelevant or redundant information and must be processed to be meaningful Several key principals are introduced in the above definition: data is an intermediary step leading towards some form of analysis or or presentation, not typically an end in itself data comes in multiple formats, both digital and analogue data can be collected by both humans and machines not all data in a given dataset is necessarily meaningful, correct nor useful Data Scientists (as differentiated from statisticians or computer scientists, for example) are expert in understanding the nature of data itself and the steps necessary to assess the suitability of a given data set for answering specific research questions and the work required to properly prepare data for successful analysis. In the broadest terms, we call this process data forensics. The first step in the data forensics process is understanding the format(s) through which data are stored and transferred. 11.1 Tabular Data Tabular Data is the most ubiquitous form of data storage and the one most familiar to most users. Tabular data consists of organizing data in a table of rows and columns. Traditionally, each column in the table represents a Field of Variable and each row represents an observation or entity. For example, the table below shows a tabular organization of a subset of the mtcars dataset: Table 1.1: mpg cyl disp hp Mazda RX4 21.0 6 160.0 110 Mazda RX4 Wag 21.0 6 160.0 110 Datsun 710 22.8 4 108.0 93 Hornet 4 Drive 21.4 6 258.0 110 Hornet Sportabout 18.7 8 360.0 175 Valiant 18.1 6 225.0 105 Duster 360 14.3 8 360.0 245 Merc 240D 24.4 4 146.7 62 Merc 230 22.8 4 140.8 95 Merc 280 19.2 6 167.6 123 11.2 Tree / Document Data Structures Another popular form of data structure is the Tree structure, sometimes referred to as a Document based data structure. Tree data structures present data in a hierarchical tree-like structure in which all items related back to a single, root node. A “Family Tree” is a good example of tree structured data: The mtcars data from the above table can also be represented using a tree structure: The above image visually depicts the mtcars data as a tree, which works well for a human reader but is no parsable by the computer. There are a variety of ways to represent tree data as a computer file (or data stream) so that it can be read and parsed by the computer. In this class, we will cover two of the most popular formats: XML and JSON. 11.2.1 Structuring Data as XML XML is stands for Extensible Markup Language. Markup languages have been around since the 1960’s and were originally developed as a means to adding structured information to an existing unstructured text. In the days of analogue text preparation, professional editors typically used a blue or red pencil to make notes on typed manuscripts. The use of a specially collored pen or pencil for “marking up” documents, as the procedure was known in the industry, easily allowed subsequent readers to distinguish between editorial comment and formatting notes placed on typed manuscripts from the texts themselves. Computerized markup languages were developed as a means of allowing data specialists to markup a text in a manner that would allow the computer to distinguish between textual content and meta-information (information about the text) about the text when both types of information appear in the same file. XML is the most widely used form of markup today. In fact, nearly every webpage that you have ever viewed is actually an XML document that contains both content to be displayed and instructions for the computer on how to display that content embedded in the file using XML Tags, which are simply instructions contained with the special charcters “&lt;” and “&gt;”. For example, consider the following short email text: To: Tavi From: Jonna Subject: Meeting Date: Thursday, February 4, 2021 at 2:46 PM Don&#39;t forget about meeting with Sarah next week, 2pm in room 242. Thanks, Jonna This email contains quite a bit of structured email (sender, receiver, date/time, etc.), but there is no easy way for the computer easily extract this structure. We can solve this problem by using XML to embed information about the structure directly in the document as follows: &lt;head&gt; &lt;to&gt;Tavi&lt;/to&gt; &lt;from&gt;Jonna&lt;/from&gt; &lt;subject&gt;Meeting&lt;/subject&gt; &lt;datetime&gt; &lt;dayofweek&gt;Thursday&lt;/dayofweek&gt; &lt;month&gt;February&lt;/month&gt; &lt;day&gt;4&lt;/day&gt; &lt;year&gt;2021&lt;/year&gt; &lt;time&gt;2:46 PM&lt;/time&gt; &lt;/datetime&gt; &lt;/head&gt; &lt;body&gt; Don&#39;t forget about meeting with Sarah next week, 2pm in room 242. Thanks, &lt;signature&gt;Jonna&lt;/signuature&gt; &lt;/body&gt; By using XML, we are able to identify specific information in the email in a way that the computer is a capable of parsing. This allows us to use computational methods to easily extract information in bulk from many emails and it also allows us to program a computer program, such as an email client, to organize and properly display all of the parts of the email. The above XML example illustrates several important aspects of XML: All XML tags are enclosed in “&lt;” and “&gt;” symbols. There are 2 primary types of tags, opening tags, which designate the beginning character that is defined by the tag, and closing tags, which designate the end of the portion of the text to be associated with the opening tag. Closing tags are always indicated by slash character where tag is the name of the opening tag that is being closed. Tags be be embedded within each other in a tree-like structure. However, any tags opened within a tag must be closed before parent tag can be closed. For example, &lt;name&gt;&lt;first&gt;John&lt;/first&gt; &lt;last&gt;Doe&lt;/last&gt;&lt;/name&gt; is valid, but &lt;name&gt;&lt;first&gt;John&lt;/first&gt; &lt;last&gt;Doe&lt;/name&gt;&lt;/last&gt; is not valid. While XML was oringinally developed as a means of embedding meta information about a text directly in a text, it also quickly evolved into a stand-alone means of representing tree-structured data for exchange between computer systems. To this end, many computer applications use XML to store, share, and retrieve data. For exmaple, we can represent the data in our truncated mtcars dataset as XML as follows: &lt;cars&gt; &lt;make id=&quot;mazda&quot;&gt; &lt;model id=&quot;RX4&quot;&gt; &lt;mpg&gt;21.0&lt;/mpg&gt; &lt;cyl&gt;6&lt;/cyl&gt; &lt;disp&gt;160.0&lt;/disp&gt; &lt;hp&gt;110&lt;/hp&gt; &lt;/model&gt; &lt;model id=&quot;RX4 Wag&quot;&gt; &lt;mpg&gt;21.0&lt;/mpg&gt; &lt;cyl&gt;6&lt;/cyl&gt; &lt;disp&gt;160.0&lt;/disp&gt; &lt;hp&gt;110&lt;/hp&gt; &lt;/model&gt; &lt;/make&gt; &lt;make id=&quot;Datsun&quot;&gt; &lt;model id=&quot;710&quot;&gt; &lt;mpg&gt;22.8&lt;/mpg&gt; &lt;cyl&gt;4&lt;/cyl&gt; &lt;disp&gt;108.0&lt;/disp&gt; &lt;hp&gt;93&lt;/hp&gt; &lt;/model&gt; &lt;/make&gt; &lt;make id=&quot;Hornet&quot;&gt; &lt;model id=&quot;4 Drive&quot;&gt; &lt;mpg&gt;21.4&lt;/mpg&gt; &lt;cyl&gt;6&lt;/cyl&gt; &lt;disp&gt;258.0&lt;/disp&gt; &lt;hp&gt;110&lt;/hp&gt; &lt;/model&gt; &lt;model id=&quot;Sportabout&quot;&gt; &lt;mpg&gt;18.7&lt;/mpg&gt; &lt;cyl&gt;8&lt;/cyl&gt; &lt;disp&gt;360.0&lt;/disp&gt; &lt;hp&gt;175&lt;/hp&gt; &lt;/model&gt; &lt;/make&gt; &lt;make id=&quot;Valiant&quot;&gt; &lt;model id=&quot;valiant&quot;&gt; &lt;mpg&gt;18.1&lt;/mpg&gt; &lt;cyl&gt;6&lt;/cyl&gt; &lt;disp&gt;225.0&lt;/disp&gt; &lt;hp&gt;105&lt;/hp&gt; &lt;/model&gt; &lt;/make&gt; &lt;make id=&quot;Duster&quot;&gt; &lt;model id=&quot;360&quot;&gt; &lt;mpg&gt;14.3&lt;/mpg&gt; &lt;cyl&gt;8&lt;/cyl&gt; &lt;disp&gt;360.0&lt;/disp&gt; &lt;hp&gt;245&lt;/hp&gt; &lt;/model&gt; &lt;/make&gt; &lt;make id=&quot;Merc&quot;&gt; &lt;model id=&quot;240D&quot;&gt; &lt;mpg&gt;24.4&lt;/mpg&gt; &lt;cyl&gt;4&lt;/cyl&gt; &lt;disp&gt;146.7&lt;/disp&gt; &lt;hp&gt;62&lt;/hp&gt; &lt;/model&gt; &lt;model id=&quot;230&quot;&gt; &lt;mpg&gt;22.8&lt;/mpg&gt; &lt;cyl&gt;4&lt;/cyl&gt; &lt;disp&gt;140.8&lt;/disp&gt; &lt;hp&gt;95&lt;/hp&gt; &lt;/model&gt; &lt;model id=&quot;280&quot;&gt; &lt;mpg&gt;19.2&lt;/mpg&gt; &lt;cyl&gt;6&lt;/cyl&gt; &lt;disp&gt;167.6&lt;/disp&gt; &lt;hp&gt;123&lt;/hp&gt; &lt;/model&gt; &lt;/make&gt; &lt;/cars&gt; For an XML dataset to be technically valid, the tags used to markup the dataset must themselves be defined according to a schema, another XML document that defines all tags that can be used in marking up a dataset and the allowable tree structure of the markup (for example, which tags can be parents of which other tags, etc.). You do not need to understand, or even know, the schema being used to present data in order to read and parse an XML document. However, schemas are extremely useful (and often necessary) for building applications that perform advanced processing of XML documents, such as web browsers, emial clients, etc. For more information on XML and XML Schemas see the w3schools XML Tutorial at https://www.w3schools.com/xml/. 11.2.2 Structuring Data as JSON XML provides an excellent framework for encoding, saving, and transfering all kinds of data, and it was the dominant mode of transfering data across the internet for many years. However, XML has an Achilles’ Heel from the data transfer perspective: a lack of sparcity. If you look closely at the mtcars dataset XML example above, you will note that the markup accounts for more of the total characters in the document than the data itself. In a world where data is regularly being exchanged in real time across the network, the use of XML can result in the necessity to exchange a lot more data to accomplish the same task. This adds both time and cost to every data transaction. JavaScript Object Notation (JSON) was developed as a standard to address this problem and provides a sparse framework for representing data that introduces minimal, non-data elements into the overal data structure. JSON uses a key/value pair structure to represent data elements: &quot;model&quot;:&quot;RX4&quot; Individual data elements are then grouped to reflect more complex data structures: {&quot;model&quot;: {&quot;id&quot;: &quot;2&quot;, &quot;hp&quot;: &quot;120&quot;}} The example below shows the subsetted mtcars dataset represented as JSON. Note the use of the “[” character to indicated repeated elements in the data: { &quot;cars&quot;: [{ &quot;make&quot;: &quot;Mazda&quot;, &quot;model&quot;: [{ &quot;id&quot;: &quot;RX4&quot;, &quot;mpg&quot;: &quot;21.0&quot;, &quot;cyl&quot;: &quot;6&quot;, &quot;disp&quot;: &quot;160.0&quot;, &quot;hp&quot;: &quot;110&quot; }, { &quot;id&quot;: &quot;RX4 Wag&quot;, &quot;mpg&quot;: &quot;21.0&quot;, &quot;cyl&quot;: &quot;6&quot;, &quot;disp&quot;: &quot;160.0&quot;, &quot;hp&quot;: &quot;110&quot; } ] }, { &quot;make&quot;: &quot;Datsun&quot;, &quot;model&quot;: { &quot;id&quot;: &quot;710&quot;, &quot;mpg&quot;: &quot;22.8&quot;, &quot;cyl&quot;: &quot;4&quot;, &quot;disp&quot;: &quot;108.0&quot;, &quot;hp&quot;: &quot;93&quot; } }, { &quot;make&quot;: &quot;Hornet&quot;, &quot;model&quot;: [{ &quot;id&quot;: &quot;4 Drive&quot;, &quot;mpg&quot;: &quot;21.4&quot;, &quot;cyl&quot;: &quot;6&quot;, &quot;disp&quot;: &quot;258.0&quot;, &quot;hp&quot;: &quot;110&quot; }, { &quot;id&quot;: &quot;Sportabout&quot;, &quot;mpg&quot;: &quot;18.7&quot;, &quot;cyl&quot;: &quot;8&quot;, &quot;disp&quot;: &quot;360.0&quot;, &quot;hp&quot;: &quot;175&quot; } ] }, { &quot;make&quot;: &quot;Valiant&quot;, &quot;model&quot;: { &quot;id&quot;: &quot;valiant&quot;, &quot;mpg&quot;: &quot;18.1&quot;, &quot;cyl&quot;: &quot;6&quot;, &quot;disp&quot;: &quot;225.0&quot;, &quot;hp&quot;: &quot;105&quot; } }, { &quot;make&quot;: &quot;Duster&quot;, &quot;model&quot;: { &quot;id&quot;: &quot;360&quot;, &quot;mpg&quot;: &quot;14.3&quot;, &quot;cyl&quot;: &quot;8&quot;, &quot;disp&quot;: &quot;360.0&quot;, &quot;hp&quot;: &quot;245&quot; } }, { &quot;make&quot;: &quot;Merc&quot;, &quot;model&quot;: [{ &quot;id&quot;: &quot;240D&quot;, &quot;mpg&quot;: &quot;24.4&quot;, &quot;cyl&quot;: &quot;4&quot;, &quot;disp&quot;: &quot;146.7&quot;, &quot;hp&quot;: &quot;62&quot; }, { &quot;id&quot;: &quot;230&quot;, &quot;mpg&quot;: &quot;22.8&quot;, &quot;cyl&quot;: &quot;4&quot;, &quot;disp&quot;: &quot;140.8&quot;, &quot;hp&quot;: &quot;95&quot; }, { &quot;id&quot;: &quot;280&quot;, &quot;mpg&quot;: &quot;19.2&quot;, &quot;cyl&quot;: &quot;6&quot;, &quot;disp&quot;: &quot;167.6&quot;, &quot;hp&quot;: &quot;123&quot; } ] } ] } For information on the JSON format, see the Tutorialspoint JSON Tutorial at https://www.tutorialspoint.com/json/index.htm. You can also use the JSONLint Json Validator at https://jsonlint.com/ to check the syntax of any JSON representation. 11.3 Relational Databases Relational Databases, frequently referred to as Relational Database Management Systems (RDBMS), provide another way of structuring data. Unlike tabular, XML, and JSON data representations, RDBMS data is not easily human readable and specialized software is usually required to interact with data stored as relational data. Most programming environments (including r) provide specialized drivers for communicating with RDBMS in order to facilitate working with data stored in these systems. RDBMS have three primary purposes as a data storage format: To reduce duplication of data; To speed-up access and insertion of new data; To insure data integrity. Items 2 and 3 above are accomplished at the software level, by deploying strict checks on data input, complex data indexing systems, and implementing redundant, automated, backup systems, to name just a few of the functionalities offered by RDBMS. Item 1 above, reducing duplication of data, is accomplished by using a specific, “relational” data structure that encourages the use of controlled lists of data mapped to individual observations. Looking at our mtcars subset data, for example, we see that while there are ten observations, there are only 6 makes of cars. To represent this in RDBMS, we first create a “Table,” a named collection of data, that contains a unique list of car makes: Table 1.2: MAKE_TABLE id Make 1 Mazda 2 Datsun 3 Hornet 4 Valiant 5 Duster 6 Merc Once we have a table of unique lists, we then create and populate a table of our cars, associating each car with its appropriate make from the MAKE_TABLE table: Table 11.1: CARS_TABLE Make Model mpg cyl disp hp 1 RX4 21.0 6 160.0 110 1 RX4 Wag 21.0 6 160.0 110 2 710 22.8 4 108.0 93 3 4 Drive 21.4 6 258.0 110 3 Sportabout 18.7 8 360.0 175 4 Valiant 18.1 6 225.0 105 5 360 14.3 8 360.0 245 6 240D 24.4 4 146.7 62 6 230 22.8 4 140.8 95 6 280 19.2 6 167.6 123 In the above table, we only normalized the car Make field. In a fully normalized RDBMS data structure, we would also create a control table for the Model field in anticipation of the fact that we could have more than one observation for a given model. Fully normalized RBDMS data structures use control tables for all fields that contain string data. The image below shows a sample Entry Relationship Diagram (ERD) for a more complex dataset relating to course offerings and enrollments. Each line connecting two tables marks a field in a “join” table that uses the id field in a control table (known as a foreign key) to associate information in the control table with the records in the join table. 11.4 Non-Hierarchical Relational Data In the era of the social network, it is becoming increasingly necessary to represent relationships between entities that are not hierarchical. Unlike a family tree, the fact that you are connected to someone on Facebook or Instagram does not imply any type of hierarchical relationship. Such networks are typically represented using the Graph data structure: Graphs consists of collections of vertices or nodes, the entities being graphed, and edges, the relationships between nodes. Another important aspect of graph data is the concept of directionality. A directed graph indicates the direction of the relationship identified by the edge. We might, for example, wish to draw edges that indicate that one node was influenced by another node, in which case we could identify an “influence” edge and use directionality to indicate who influenced whom: Graph data can be stored and or transfered using any of the data formats discussed above or using specialized graph databases management software. 11.5 Geospatial Data Geospatial data represents a final type of data with it’s own, unique data structure. Geospatial data unique because it always realates directly to the physical world and, because it relies on world-wide standards which have been in development and communally accepted for hundreds of years. Because of its uniqueness as a data type, geospatial data will be covered as a stand-alone topic later in the course. "],["how-the-web-works.html", "12 How the Web Works 12.1 Client-Server Architecture 12.2 Understanding URLs", " 12 How the Web Works The discipline of Data Science was, in a large part, ushered into being by the increasing availability of information available on the World Wide Web or through other internet sources. Prior to the popularization of the internet as a publishing and communications platform, the majority of scientific research involved controlled studies in which researchers would collect their own data through various direct means of data collection (surveys, medical testing, etc.) in order to test a stated hypothesis. The vast amount of information available on the internet disrupted this centuries long dominance. Today, the dominant form of scientific research involves using data collected or produced by others for reasons having little or nothing to do with the research question being investigated by scholar. Users who post items about their favorite political candidate are not, for example, doing this so that sociologists can better under how politics function in America. However, their Tweets are being used in that and many other unforseen capacities. Because the internet provides such a rich trove of information for study, understanding how to effectively get, process, and prepare information from the internet for scientific research is a crucial skill for any data scientist. And in order to understand these workflows, the data scientist must first understand how the internet itself functions. 12.1 Client-Server Architecture The base architecture and functioning of the internet is quite simple: A content producer puts information on a computer called the server for others to retrieve; A user uses their local computer, called the client, to request the information from the sever; The server delivers the information to the client. Each of the above detailed steps is accomplished using a technically complex but conceptually simple set of computer protocols. The technical details are beyond the scope of this course. We are here concerned with their conceptual architecture. 12.1.1 Communication Between Clients and Servers Anytime a computer connects to any network, that computer is assigned a unique identifier known as an internet protocol (IP) address that uniquely identifies that computer on the network. IP addresses have the form x.x.x.x, where each x can be any integer from 0 to 255. For example, 169.237.102.141 is the current IP address of the computer that hosts the DataLab website. IP addresses are sometimes pre-designated for particular computers. A pre-designated IP address is known as static IP address. In other cases IP addresses are dynamically assigned from a range of available IP Address using a system known as the Dynamic Host Configuration Protocol (DHCP). Servers are typically assigned static IP addresses and clients are typically assigned dynamic IP addresses. As humans, we are used to accessing websites via a domain name (which we’ll discuss shortly), but you can also contact any server on the internet by simply typing the IP address into your browser address bar where you would normally enter the URL. For example, you can simply click on https://169.237.102.141 to access the DataLab website. (note: your browser may give you a security warning if you try to access a server directly using an IP address. For the link above, it is safe to proceed to the site.) 12.1.2 Domain Name Resolution IP addresses are the unique identifiers that make the internet work, but they are not very human friendly. To solve this problem, a system of domain name resolution was created. Under this system, internet service providers access a universal domain registry database that associates human readable domain names with machine readable IP addresses, and a secondary set of of internet connected servers known as domain name servers (DNS) provide a lookup service that translates domain names into IP addresses in the background. As the end-user, you enter and see only domain names, but the actual request process is a multi-step process in which domain names are translated to IP address in the background: A content produce puts information on a computer called the server for others to retrieve; A user uses their local computer, called the client, to request the information from the sever using a domain name using request software such as a web browser; The user’s client software first sends a request to a DNS server to retrieve the IP address of the server on the network associated with the entered domain name; The DNS server returns the associated IP address to the client; The client then makes the information request to the server using its retrieved IP address; The server delivers the information to the client. 12.1.3 Request Routing Our simple digram of the client server process shows only two computers. But when you connect to the internet you are not, of course, creating a direct connection to a single computer. Rather, you are connecting to vase network of literally millions of computers, what we have come to refer to as the cloud. In order to solve this problem, the internet backbone also deploys a routing system that directs requests and responses across the network to the appropriate servers and clients. When you connect to the WiFi network in your home, office, or the local coffee house, you are connecting to a router. That router receives all of your requests and, provided you are not requesting something directly from another computer that is connected to the same router, passes that request on to a larger routing network at the Internet Service Provider (ISP). When the ISP routers receive your request, they check to see if your requestion something from a computer that connected to their network. If it is, they deliver the request. If it is not, they pass the request on to another, regional routing network. And this routing process is repeated until your request if finally routed to the correct server. A content produce puts information on a computer called the server for others to retrieve; A user uses their local computer, called the client, to request the information from the sever using a domain name using request software such as a web browser; The user’s client software first sends a request to a DNS server to retrieve the IP address of the server on the network associated with the entered domain name; The DNS server returns the associated IP address to the client; The client sends the request to the local (in home, office, etc.) router; After check of IP addresses on local network, request is routed to the ISP’s routing system; The request is passed through the internet routing network until it reaches the routing system of the server’s ISP and, finally, the server itself. 12.1.4 The Server Response When a request is sent to a server across the internet, the request includes both the specific URL of the resource being request and also an hidden request header. The request header provides information to the server such as the IP address and the operating system of the client, the transfer protocol being used, and the software on the client that is making the request. The server uses this information to properly format it’s response and to route it back to the requesting client using the same IP routing process as described above. 12.1.5 Internet Transfer Protocols All of the information transferred between computers over the network is transfered as streams of binary data. In order to ensure data integrity, these streams are usually broken up into smaller packets of data which are transmitted independent of each other and then reassembled by the receiving computer once it has received all of the packets in the stream. The first packet returned (a header packet) typically delivers information about how many packets the client should expect to receive and about how they should be reassembled to recreate the original data stream. There are many different standards for how data streams are divided into packets. One standard might, for example, break the stream into a collection of 50 byte packets, while another might use 100 byte packages. These standards are called protocols. The two protocols that are familiar to most users are http and https, which define the hypertext transfer protocol and its sibling the hypertext transfer secure protocol. When you type a url like https://datalab.ucdavis.edu into your browser, you are instructing the browser to use the https protocol to exchange information. Because http and https are so common, most modern browsers do not require you to type the protocol name. They will simply insert the protocol for you in the background. 12.2 Understanding URLs URL is an acronym for Uniform Resource Locators. “Uniform” is a key term in this context. URLs are not arbitrary pointers to information. They are machine and human readable and parsable and contain a lot of information in them. All URLs are constructed using a standardized format. Consider the following URL: https://sfbaywildlife.info/species/common_birds.htm There are actually several distinct components to the above URL Table 1.1: protocol server path to file https:// sfbaywildlife.info /species/common_birds.htm We’ve already discussed Internet Protocols and domain names. The file path portion of the URL can also provide valuable information about the server. It reads exactly like a Unix file path on the command line. The path /species/common_birds.htm indicates that the file common_birds.htm is in the species directory on the server. 12.2.1 Dynamic Files In the above example, when you enter the URL https://sfbaywildlife.info/species/common_birds.htm, your browser requests the file at /species/common_birds.html on the server. The server simply finds the file and delivers it to your web browser. We call this a static web server because the server itself does not do any processing of files prior to delivery. It simply receives requests for files living on the server and then sends them to the client, whose browser renders the file for viewing. Many websites, however, use dynamic processing. Pages with file extensions such as .php or .jsp, for example, include computer code in them. When these pages are requested by the server, the server executes the code in the designated file and sends the output of that execution to the requesting client rather than the actual file. Many sites, such as online stores and blogs, use this functionality to connect their web pages to active databases that track inventory and orders, for example. 12.2.2 Query Strings Dynamic websites, such as e-commerce sites that are connected to databases, require a mechanism for users to submit information to the server for processing. This is accomplished through one of two HTTP commands: GET or POST. POST commands send submitted information to the server via a hidden HTTP header that is invisible to the end user. Scraping sites that require POST transactions is possible but can require significant sleuthing to determine the correct parameters and is beyond the scope of this course. GET requests, which are, happily for web scrapers more ubiquitous than POST requests, are much easier to understand. They are submitted via a query string that is simply appended to the request URL as in the following example: https://ebba.english.ucsb.edu/search_combined/?ft=dragon&amp;numkw=52 Here we see a Query String appended to the end of the actual URL: Table 1.2: protocol server path to file query string https:// ebba.english.ucsb.edu /search_combined/index.php ?ft=dragon&amp;numkw=52 Query strings always appear at the end of the URL and begin with the ? character followed by a series of key/value pairs separated by the &amp; character. In the above example we see that two parameters are submitted to the server via the query string as follows: ft=dragon numkw=52 The server will use these parameter values as input to perform a dynamic operation, in this case searching a database. "],["web-scraping.html", "13 Web Scraping 13.1 Getting Data from the Web 13.2 R’s XML Parsers 13.3 XPath 13.4 The Web Scraping Workflow 13.5 Case Study: CA Cities 13.6 Case Study: The CA Aggie 13.7 CSS Selectors", " 13 Web Scraping Scraping a web page means extracting information so that it can be used programmatically (for instance, in R). After this lesson, you should be able to: Explain and read hypertext markup language (HTML) View the HTML source of a web page Use Firefox or Chrome’s web developer tools to locate tags within a web page With the rvest package: Read HTML into R Extract HTML tables as data frames With the xml2 package: Use XPath to extract specific elements of a page 13.1 Getting Data from the Web Ways you can get data from the web, from most to least convenient: Direct download or “data dump” R or Python package (there are packages for many popular web APIs) Documented web API Undocumented web API Scraping 13.1.1 What’s in a Web Page? Modern web pages usually consist of many files: Hypertext markup language (HTML) for structure and formatting Cascading style sheets (CSS) for more formatting JavaScript (JS) for interactivity Images HTML is the only component that always has to be there. Since HTML is what gives a web page structure, it’s what we’ll focus on when scraping. HTML is closely related to eXtensible markup language (XML). Both languages use tags to mark structural elements of data. In HTML, the elements literally correspond to the elements of a web page: paragraphs, links, tables, and so on. Most tags come in pairs. The opening tag marks the beginning of an element and the closing tag marks the end. Opening tags are written &lt;NAME&gt;, where NAME is the name of the tag. Closing tags are written &lt;/NAME&gt;. A singleton tag is a tag that stands alone, rather than being part of a pair. Singleton tags are written &lt;NAME /&gt;. In HTML (but not XML) they can also be written &lt;NAME&gt;. Fortunately, HTML only has a few singleton tags, so they can be distinguished by name regardless of which way they’re written. For example, here’s some HTML that uses the em (emphasis, usually italic) and strong (usually bold) tags, as well as the singleton br (line break) tag: &lt;em&gt;&lt;strong&gt;This text&lt;/strong&gt; is emphasized.&lt;br /&gt;&lt;/em&gt; Not emphasized A pair of tags can contain other elements (paired or singleton tags), but not a lone opening or closing tag. This creates a strict, treelike hierarchy. Opening and singleton tags can have attributes that contain additional information. Attributes are name-value pairs written NAME=\"VALUE\" after the tag name. For instance, the HTML a (anchor) tag creates a link to the URL provided for the href attribute: &lt;a href=&quot;http://www.google.com/&quot; id=&quot;mytag&quot;&gt;My Search Engine&lt;/a&gt; In this case the tag also has a value set for the id attribute. Now let’s look at an example of HTML for a complete, albeit simple, web page: &lt;html&gt; &lt;head&gt; &lt;title&gt;This is the page title!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is a header!&lt;/h1&gt; &lt;p&gt;This is a paragraph. &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s a website!&lt;/a&gt; &lt;/p&gt; &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; In most web browsers, you can examine the HTML for a web page by right-clicking and choosing “View Page Source”. See here for a more detailed explanation of HTML, and here for a list of valid HTML elements. 13.2 R’s XML Parsers A parser converts structured data into familiar data structures. R has two popular packages for parsing XML (and HTML): The “XML” package The “xml2” package The XML package has more features. The xml2 package is more user-friendly, and as part of the Tidyverse, it’s relatively well-documented. This lesson focuses on xml2, since most of the additional features in the XML package are related to writing (rather than parsing) XML documents. The xml2 package is often used in conjunction with the “rvest” package, which provides support for CSS selectors (described later in this lesson) and automates scraping HTML tables. The first time you use these packages, you’ll have to install them: install.packages(&quot;xml2&quot;) install.packages(&quot;rvest&quot;) Let’s start by parsing the example of a complete web page from earlier. The xml2 function read_xml reads an XML document, and the rvest function read_html reads an HTML document. Both accept an XML/HTML string or a file path (including URLs): html = r&quot;( &lt;html&gt; &lt;head&gt; &lt;title&gt;This is the page title!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is a header!&lt;/h1&gt; &lt;p&gt;This is a paragraph. &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s a website!&lt;/a&gt; &lt;/p&gt; &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; )&quot; library(xml2) library(rvest) doc = read_html(html) doc ## {html_document} ## &lt;html&gt; ## [1] &lt;head&gt;\\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8 ... ## [2] &lt;body&gt;\\n &lt;h1&gt;This is a header!&lt;/h1&gt;\\n &lt;p&gt;This is a paragraph.\\n ... The xml_children function returns all of the immediate children of a given element. The top element of our document is the html tag, and its immediate children are the head and body tags: tags = xml_children(doc) The result from xml_children is a node set (xml_nodeset object). Think of a node set as a vector where the elements are tags rather than numbers or strings. Just like a vector, you can access individual elements with the indexing (square bracket [) operator: length(tags) ## [1] 2 head = tags[1] head ## {xml_nodeset (1)} ## [1] &lt;head&gt;\\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8 ... The xml_text function returns the text contained in a tag. Let’s get the text in the title tag, which is beneath the head tag. First we isolate the tag, then use xml_text: title = xml_children(head) xml_text(title) ## [1] &quot;&quot; &quot;This is the page title!&quot; Navigating through the tags by hand is tedious and easy to get wrong, but fortunately there’s a better way to find the tags we want. 13.3 XPath An XML document is a tree, similar to the file system on your computer: html ├── head │ └── title └── body ├── h1 ├── p └── p └── a When we wanted to find files, we wrote file paths. We can do something similar to find XML elements. XPath is a language for writing paths to elements in an XML document. XPath is not R-specific. At a glance, an XPath looks similar to a file path: XPath Description / root, or element separator . current tag .. parent tag * any tag (wildcard) The xml2 function xml_find_all finds all elements at given XPath: xml_find_all(doc, &quot;/html/body/p&quot;) ## {xml_nodeset (2)} ## [1] &lt;p&gt;This is a paragraph.\\n &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s ... ## [2] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; Unlike a file path, an XPath can identify multiple elements. If you only want a specific element, use indexing to get it from the result. XPath also has some features that are different from file paths. The // separator means “at any level beneath.” It’s a useful shortcut when you want to find a specific element but don’t care where it is. Let’s get all of the p elements at any level of the document: xml_find_all(doc, &quot;//p&quot;) ## {xml_nodeset (2)} ## [1] &lt;p&gt;This is a paragraph.\\n &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s ... ## [2] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; Let’s also get all a elements at any level beneath a p element: xml_find_all(doc, &quot;//p/a&quot;) ## {xml_nodeset (1)} ## [1] &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s a website!&lt;/a&gt; The vertical bar | means “or.” You can use it to get two different sets of elements in one query. Let’s get all h1 or p tags: xml_find_all(doc, &quot;//h1|//p&quot;) ## {xml_nodeset (3)} ## [1] &lt;h1&gt;This is a header!&lt;/h1&gt; ## [2] &lt;p&gt;This is a paragraph.\\n &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s ... ## [3] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; 13.3.1 Predicates In XPath, the predicate operator [] gets elements at a position or matching a condition. Most conditions are about the attributes of the element. In the predicate operator, attributes are always prefixed with @. For example, suppose we want to find all tags where the id attribute is equal to \"hello\": xml_find_all(doc, &quot;//*[@id = &#39;hello&#39;]&quot;) ## {xml_nodeset (1)} ## [1] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; Notice that the equality operator in XPath is =, not ==. Strings in XPath can be quoted with single or double quotes. You can combine multiple conditions in the predicate operator with and and or. There are also several XPath functions you can use in the predicate operator. These functions are not R functions, but rather built into XPath. Here are a few: XPath Description not() negation contains() check string x contains y text() get tag text substring() get a substring For instance, suppose we want to get elements that contain the word “paragraph”: xml_find_all(doc, &quot;//*[contains(text(), &#39;paragraph&#39;)]&quot;) ## {xml_nodeset (2)} ## [1] &lt;p&gt;This is a paragraph.\\n &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s ... ## [2] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; Finally, note that you can also use the predicate operator to get elements at a specific position. For example, to get the second p element anywhere in the document: xml_find_all(doc, &quot;//p[2]&quot;) ## {xml_nodeset (1)} ## [1] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; Notice that this is the same as if we had used R to get the second element: xml_find_all(doc, &quot;//p&quot;)[2] ## {xml_nodeset (1)} ## [1] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; Beware that although the XPath predicate operator resembles R’s indexing operator, the syntax is not always the same. We’ll learn more XPath in the examples. There’s a complete list of XPath functions on Wikipedia. 13.4 The Web Scraping Workflow Scraping a web page is part technology, part art. The goal is to find an XPath that’s concise but specific enough to identify only the elements you want. If you plan to scrape the web page again later or want to scrape a lot of similar web pages, the XPath also needs to be general enough that it still works even if there are small variations. Firefox and Chrome include “web developer tools” that are invaluable for planning a web scraping strategy. Press Ctrl + Shift + i (Cmd + Shift + i on OS X) in Firefox or Chrome to open the web developer tools. We can also use the web developer tools to interactively identify the element that corresponds to a specific part of a web page. Press Ctrl + Shift + c and then click on the part of the web page you want to identify. The best way to approach web scraping (and programming in general) is as an incremental, iterative process. Use the web developer tools to come up with a basic strategy, try it out in R, check which parts don’t work, and then repeat to adjust the strategy. Expect to go back and forth between your web browser and R several times when you’re scraping. Most scrapers follow the same four steps, regardless of the web page and the language of the scraper: Download pages with an HTTP request (usually GET) Parse pages to extract text Clean up extracted text with string methods or regex Save cleaned results In R, xml2’s read_xml function takes care of step 1 for you, although you can also use httr functions to make the request yourself. 13.4.1 Being Polite Making an HTTP request is not free! It has a real cost in CPU time and also cash. Server administrators will not appreciate it if you make too many requests or make requests too quickly. So: If you’re making multiple requests, slow them down by using R’s Sys.sleep function to make R do nothing for a moment. Aim for no more than 20-30 requests per second, unless you’re using an API that says more are okay. Avoid requesting the same page twice. One way to do this is by caching (saving) the results of the requests you make. You can do this manually, or use a package that does it automatically, like the httpcache package. Failing to be polite can get you banned from websites! Also check the website’s terms of service to make sure scraping is not explicitly forbidden. 13.5 Case Study: CA Cities Wikipedia has many pages that are just tables of data. For example, there’s this list of cities and towns in California. Let’s scrape the table to get a data frame. Step 1 is to download the page: wiki_url = &quot;https://en.wikipedia.org/wiki/List_of_cities_and_towns_in_California&quot; wiki_doc = read_html(wiki_url) Step 2 is to extract the table element from the page. We can use Firefox or Chrome’s web developer tools to identify the table. HTML tables usually use the table tag. Let’s see if it’s the only table in the page: tables = xml_find_all(wiki_doc, &quot;//table&quot;) tables ## {xml_nodeset (4)} ## [1] &lt;table class=&quot;wikitable&quot;&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scope=&quot;row&quot; style=&quot;background ... ## [2] &lt;table class=&quot;wikitable plainrowheaders sortable&quot;&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scop ... ## [3] &lt;table class=&quot;nowraplinks hlist mw-collapsible autocollapse navbox-inner&quot; ... ## [4] &lt;table class=&quot;nowraplinks mw-collapsible autocollapse navbox-inner&quot; style ... The page has 4 tables. We can either make our XPath more specific, or use indexing to get the table we want. Refining the XPath makes our scraper more robust, but indexing is easier. For the sake of learning, let’s refine the XPath. Going back to the browser, we can see that the table includes \"wikitable\" and \"sortable\" in its class attribute. So let’s search for these among the table elements: tab = xml_find_all(tables, &quot;//*[contains(@class, &#39;sortable&#39;)]&quot;) tab ## {xml_nodeset (1)} ## [1] &lt;table class=&quot;wikitable plainrowheaders sortable&quot;&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th scop ... Now we get just one table! Here we used a second XPath applied only to the results from the first, but we also could’ve done this all with one XPath: //table[contains(@class, 'sortable')]. The next part of extracting the data is to extract the value from each individual cell in the table. HTML tables have a strict layout order, with tags to indicate rows and cells. We could extract each cell by hand and then reassemble them into a data frame, but the rvest function html_table can do it for us automatically: cities = html_table(tab, fill = TRUE) cities = cities[[1]] head(cities) ## Name Type County Population (2010)[1][8][9] Land area[1] ## 1 Name Type County Population (2010)[1][8][9] sq mi ## 2 Adelanto City San Bernardino 31,765 56.01 ## 3 Agoura Hills City Los Angeles 20,330 7.79 ## 4 Alameda City Alameda 73,812 10.61 ## 5 Albany City Alameda 18,539 1.79 ## 6 Alhambra City Los Angeles 83,089 7.63 ## Land area[1] Incorporated[7] ## 1 Land area[1] km2 ## 2 145.1 December 22, 1970 ## 3 20.2 December 8, 1982 ## 4 27.5 April 19, 1854 ## 5 4.6 September 22, 1908 ## 6 19.8 July 11, 1903 The fill = TRUE argument ensures that empty cells are filled with NA. We’ve successfully imported the data from the web page into R, so we’re done with step 2. 13.5.1 Data Cleaning Step 3 is to clean up the data frame. The column names contain symbols, the first row is part of the header, and the column types are not correct. # Fix column names. names(cities) = c(&quot;city&quot;, &quot;type&quot;, &quot;county&quot;, &quot;population&quot;, &quot;mi2&quot;, &quot;km2&quot;, &quot;date&quot;) # Remove fake first row. cities = cities[-1, ] # Reset row names. rownames(cities) = NULL How can we clean up the date column? The as.Date function converts a string into a date R understands. The idea is to match the date string to a format string where the components of the date are indicated by codes that start with %. For example, %m stands for the month as a two-digit number. You can read about the different date format codes in ?strptime. Here’s the code to convert the dates in the data frame: dates = as.Date(cities$date, &quot;%B %m, %Y&quot;) cities$date = dates We can also convert the population to a number: class(cities$population) ## [1] &quot;character&quot; # Remove commas and footnotes (e.g., [1]) before conversion library(stringr) pop = str_replace_all(cities$population, &quot;,&quot;, &quot;&quot;) pop = str_replace_all(pop, &quot;\\\\[[0-9]+\\\\]&quot;, &quot;&quot;) pop = as.numeric(pop) # Check for missing values, which can mean conversion failed any(is.na(pop)) ## [1] FALSE cities$population = pop 13.6 Case Study: The CA Aggie Suppose we want to scrape The California Aggie. In particular, we want to get all the links to news articles on the features page https://theaggie.org/features/. This could be one part of a larger scraping project where we go on to scrape individual articles. First, let’s download the features page so we can extract the links: url = &quot;https://theaggie.org/features/&quot; doc = read_html(url) We know that links are in a tags, but we only want links to articles. Looking at the features page with the web developer tools, the links to feature articles are all inside of a section tag. So let’s get the section tag: xml_find_all(doc, &quot;//section&quot;) # OR html_nodes(doc, &quot;section&quot;) ## {xml_nodeset (1)} ## [1] &lt;section id=&quot;blog-grid&quot;&gt;&lt;div class=&quot;blog-grid-container&quot;&gt;\\n\\n\\t\\t\\t\\t\\t&lt;d ... Just to be safe, let’s also use the id attribute, which is \"blog-grid\". Usually the id of an element is unique, so this ensures that we get the right section even if later the web developer for The Aggie adds other section tags. We can also add in a part about getting links now: section = xml_find_all(doc, &quot;//section[@id = &#39;blog-grid&#39;]&quot;) # OR html_nodes(doc, &quot;section#blog-grid&quot;) links = xml_find_all(section, &quot;//a&quot;) # OR html_nodes(section, &quot;a&quot;) length(links) ## [1] 267 That gives us 267 links, but there are only 15 articles on the page, so something’s still not right. Inspecting the page again, there are actually three links to each article: on the image, on the title, and on “Continue Reading”. Let’s focus on the title link. There are a couple different ways we can identify the title link: Always inside an h2 tag Always has title attribute that starts with “Permanent” Generally it’s more robust to rely on tags (structure) than to rely on attributes (other than id and class). So let’s use the h2 tag here: links = xml_find_all(section, &quot;//h2/a&quot;) # OR html_nodes(section, &quot;h2 &gt; a&quot;) length(links) ## [1] 15 Now we’ve got the 15 links, so let’s get the URLs from the href attribute. feature_urls = xml_attr(links, &quot;href&quot;) The other article listings (Sports, Science, etc) on The Aggie have a similar structure, so we can potentially reuse our code to scrape those. So let’s turn our code into a function. The input will be a downloaded page, and the output will be the article links. parse_article_links = function(page) { section = xml_find_all(page, &quot;//section[@id = &#39;blog-grid&#39;]&quot;) links = xml_find_all(section, &quot;//h2/a&quot;) xml_attr(links, &quot;href&quot;) } We can test this out on the Sports page. First we download the page: sports = read_html(&quot;https://theaggie.org/sports&quot;) Then we call the function on the document: sports_urls = head(parse_article_links(sports)) head(sports_urls) ## [1] &quot;https://theaggie.org/2021/02/19/pickleball-the-rising-sport/&quot; ## [2] &quot;https://theaggie.org/2021/02/19/2021-olympic-games-are-in-limbo/&quot; ## [3] &quot;https://theaggie.org/2021/02/12/wild-year-for-football-culminates-in-super-bowl/&quot; ## [4] &quot;https://theaggie.org/2021/02/12/american-sports-sees-a-lack-of-diversity-in-team-coach-composition/&quot; ## [5] &quot;https://theaggie.org/2021/02/10/preview-of-the-uefa-champions-league-knockout-stage/&quot; ## [6] &quot;https://theaggie.org/2021/02/05/out-of-the-bubble-trouble/&quot; It looks like the function works even on other pages! We can also set up the function to extract the link to the next page, in case we want to scrape multiple pages of links. The link to the next page of features (an arrow at the bottom) is an a tag with class next. Let’s see if that’s specific enough to isolate the tag: next_page = xml_find_all(doc, &quot;//a[contains(@class, &#39;next&#39;)]&quot;) # OR html_nodes(doc, &quot;a.next&quot;) It looks like it is. We use contains here rather than = because it is common for the class attribute to have many parts. It only has one here, but using contains makes our code robust against changes in the future. We can now modify our parser function to return the link to the next page: parse_article_links = function(page) { # Get article URLs section = xml_find_all(page, &quot;//section[@id = &#39;blog-grid&#39;]&quot;) links = xml_find_all(section, &quot;//h2/a&quot;) urls = xml_attr(links, &quot;href&quot;) # Get next page URL next_page = xml_find_all(page, &quot;//a[contains(@class, &#39;next&#39;)]&quot;) next_url = xml_attr(next_page, &quot;href&quot;) # Using a list allows us to return two objects list(urls = urls, next_url = next_url) } Since our function gets URL for the next page, what happens on the last page? Looking at the last page in the browser, there is no link to the next page. Let’s see what our scraper function does: last_page = read_html(&quot;https://theaggie.org/features/page/180/&quot;) parse_article_links(last_page) ## $urls ## [1] &quot;https://theaggie.org/2008/03/14/daily-calendar/&quot; ## [2] &quot;https://theaggie.org/2008/03/14/facial-hair-takes-root-at-uc-davis/&quot; ## [3] &quot;https://theaggie.org/2008/03/13/daily-calendar/&quot; ## [4] &quot;https://theaggie.org/2008/03/12/corrections/&quot; ## [5] &quot;https://theaggie.org/2008/03/12/daily-calendar/&quot; ## [6] &quot;https://theaggie.org/2008/03/12/five-years-in-iraq-part-two/&quot; ## [7] &quot;https://theaggie.org/2008/03/11/daily-calendar/&quot; ## [8] &quot;https://theaggie.org/2008/03/11/deals-around-davis/&quot; ## [9] &quot;https://theaggie.org/2008/03/11/five-years-in-iraq-part-one/&quot; ## ## $next_url ## character(0) We get an empty character vector as the URL for the next page. This is because the xml_find_all function returns an empty node set for the next page URL, so there aren’t any href fields for xml_attr to extract. It’s convenient that the xml2 functions behave this way, but we could also add an if-statement to the function to check (and possibly return NA as the next URL in this case). Then the code becomes: parse_article_links = function(page) { # Get article URLs section = xml_find_all(page, &quot;//section[@id = &#39;blog-grid&#39;]&quot;) links = xml_find_all(section, &quot;//h2/a&quot;) urls = xml_attr(links, &quot;href&quot;) # Get next page URL next_page = xml_find_all(page, &quot;//a[contains(@class, &#39;next&#39;)]&quot;) if (length(next_page) == 0) { next_url = NA } else { next_url = xml_attr(next_page, &quot;href&quot;) } # Using a list allows us to return two objects list(urls = urls, next_url = next_url) } Now our function should work well even on the last page. If we want to scrape links to all of the articles in the features section, we can use our function in a loop: # NOTE: This code is likely to take a while to run, and is meant more for # reading than for you to run and try out. url = &quot;https://theaggie.org/features/&quot; article_urls = list() i = 1 # On the last page, the next URL will be `NA`. while (!is.na(url)) { # Download and parse the page. page = read_html(url) result = parse_article_links(page) # Save the article URLs in the `article_urls` list. The variable `i` is the # page number. article_urls[[i]] = result$url i = i + 1 # Set the URL to the next URL. url = result$next_url # Sleep for 1/30th of a second so that we never make more than 30 requests # per second. Sys.sleep(1/30) } Now we’ve got the basis for a simple scraper. 13.7 CSS Selectors Cascading style sheets (CSS) is a language used to control the formatting of an XML or HTML document. CSS selectors are the CSS way to write paths to elements. CSS selectors are more concise than XPath, so many people prefer them. Even if you prefer CSS selectors, it’s good to know XPath because CSS selectors are less flexible. Here’s the basic syntax of CSS selectors: CSS Description a tags a a &gt; b tags b directly beneath a a b tags b anywhere beneath a a, b tags a or b #hi tags with attribute id=\"hi\" .hi tags with attribute class that contains \"hi\" [foo=\"hi\"] tags with attribute foo=\"hi\" [foo*=\"hi\"] tags with attribute foo that contains \"hi\" If you want to learn more, CSS Diner is an interactive tutorial that covers the entire CSS selector language. In Firefox, you can get CSS selectors from the web developer tool. Right-click the tag you want a selector for and choose “Copy Unique Selector”. Beware that the selectors Firefox generates are often too specific to be useful for anything beyond the simplest web scrapers. The rvest package uses CSS selectors by default. Behind the scenes, the package translates these into XPath and passes them to xml2. Here are a few examples of CSS selectors, using rvest’s html_nodes function: html = r&quot;( &lt;html&gt; &lt;head&gt; &lt;title&gt;This is the page title!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;This is a header!&lt;/h1&gt; &lt;p&gt;This is a paragraph. &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s a website!&lt;/a&gt; &lt;/p&gt; &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; )&quot; doc = read_html(html) # Get all p elements html_nodes(doc, &quot;p&quot;) ## {xml_nodeset (2)} ## [1] &lt;p&gt;This is a paragraph.\\n &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s ... ## [2] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; # Get all links html_nodes(doc, &quot;a&quot;) ## {xml_nodeset (1)} ## [1] &lt;a href=&quot;http://www.r-project.org/&quot;&gt;Here&#39;s a website!&lt;/a&gt; # Get all tags with id=&quot;hello&quot; html_nodes(doc, &quot;#hello&quot;) ## {xml_nodeset (1)} ## [1] &lt;p id=&quot;hello&quot;&gt;This is another paragraph.&lt;/p&gt; "],["optical-character-recognition.html", "14 Optical Character Recognition 14.1 Loading Page Images 14.2 Running OCR 14.3 Accuracy 14.4 Unreadable Text", " 14 Optical Character Recognition Much of the data we’ve used in the course thus far has been born-digital. That is, we’ve used data that originates from a digital source and does not exist elsewhere in some other form. Think back, for example, to the lecture on strings in R: your homework required you to type text directly into RStudio, manipulate it, and print it to screen. But millions, even billions, of data-rich documents do not originate from digital sources. The United States Census, for example, dates back to 1790; we still have these records and could go study them to get a sense of what the population was like hundreds of years ago. Likewise, printing and publishing far precedes the advent of computers; much of the literary record is still bound up between the covers books or stowed away in archives. Computers, however, can’t read the way we read, so if we wanted to use digital methods to analyze such materials, we’d need to convert them into a computationally tractable form. How do we do so? One way would be to transcribe documents by hand, either by typing out plaintext versions with word processing software or by using other data entry methods like keypunching to record the information those documents contain. Amazon’s Mechanical Turk service is an example of this kind of data entry. It’s also worth noting that, for much of the history of computing, data entry was highly gendered and considered to be “dumb”, secretarial work that young women would perform. Much of the divisions between “cool” coding and computational grunt work that, in a broad, cultural sense, continue to inform how we think about programming, and indeed who gets to program, stem from such perceptions. In spite of (or perhaps because of) such perceptions, huge amounts of data owe their existence to manual data entry. That said, the process itself is expensive, time consuming, error-prone, and, well, dull. Optical character recognition, or OCR, is an attempt to offload the work of digitization onto computers. Speaking in a general sense, this process ingests images of print pages (such as those available on Google Books or HathiTrust), applies various preprocessing procedures to those images to make them a bit easier to read, and then scans through them, trying to match the features it finds with a “vocabulary” of text elements it keeps as a point of reference. When it makes a match, OCR records a character and enters it into a text buffer (a temporary data store). Oftentimes this buffer also includes formatting data for spaces, new lines, paragraphs, and so on. When OCR is finished, it outputs its matches as a data object, which you can then further manipulate or analyze using other code. 14.1 Loading Page Images OCR “reads” by tracking pixel variations across page images. This means every page you want to digitize must be converted into an image format. For the purposes of introducing you to OCR, we won’t go through the process of creating these images from scratch; instead, we’ll be using ready-made examples. The most common page image formats you’ll encounter are pdf and png. They’re lightweight, portable, and usually retain the image quality OCR software needs to find text. The pdftools package is good for working with these files: # install.packages(&quot;pdftools&quot;) library(pdftools) ## Using poppler version 21.01.0 Once you’ve downloaded/installed it, you can load a pdf into RStudio from your computer by entering its filesystem location as a string and assigning that string to a variable, like so: pdf &lt;- &quot;./pdf_sample.pdf&quot; Note that we haven’t used a special load function, like read.csv() or readRDS(). pdftools will grab this file from its location and load it properly when you run a process on it. (You can also just write the string out in whatever function you want to call, but we’ll keep our pdf location in a variable for the sake of clarity.) The same method works with web addresses. We’ll be using web material. First, write out an address and assign it to a variable. pdf &lt;- &quot;https://datalab.ucdavis.edu/adventures-in-datascience/pdf_sample.pdf&quot; Some pdf files will have text data already encoded into them. This is especially the case if someone made a file with word processing software (like when you write a paper in Word and email a pdf to your TA or professor). You can check whether a pdf has text data with pdf_text(). Assign this function’s output to a variable and print it to screen with cat(), like so: text_data &lt;- pdf_text(pdf) cat(text_data) ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## ## ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## ## ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## ## ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. ## ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## The quick brown fox jumps over the lazy dog. ## See how the RStudio terminal recreates the original formatting from the pdf. If you were to use print() on the text output, you’d see all the line breaks and spaces pdf_text() created to match its output with the file. This re-creation would be even more apparent if you were to save the output to a new file with write(). Doing so would produce a close, plaintext approximation of the original pdf. You can also process multi-page pdf files with pdf_text(), with more or less success. It can transcribe whole books and will keep them in a single text buffer, which you can then assign to a variable or save to a file. Keep in mind, however, that if your pdf files have headers, footers, page numbers, chapter breaks, or other such paratextual information, pdf_text() will pick this up and include it in its output. A later lecture in the course will discuss how to go about dealing with this extra data. If, when you run pdf_text(), you find that your file already contains text data, you’re set! There’s no need to perform OCR and you can immediately start working with your data. However, if you run the function and find that it outputs a blank character string, you’ll need to OCR it. The next section shows you how. 14.2 Running OCR First, you’ll need to download/install another package, tesseract, which complements pdftools. The latter only loads/reads pdfs, whereas tesseract actually performs OCR. Download/install tesseract: # install.packages(&quot;tesseract&quot;) library(tesseract) And assign a new pdf to a new variable: new_pdf &lt;- &quot;https://jeroen.github.io/images/ocrscan.pdf&quot; To run OCR on this pdf, use the following: ocr_output &lt;- ocr(new_pdf) ## Converting page 1 to file3d28b478a92f2ocrscan_1.png... done! Print the output to screen with cat() and see if the process worked: cat(ocr_output) ## | SAPORS LANE - BOOLE - DORSET - BH 25 8 ER ## TELEPHONE BOOLE (945 13) 51617 - TELEX 123456 ## ## Our Ref. 350/PJC/EAC 18th January, 1972, ## Dr. P.N. Cundall, ## Mining Surveys Ltd., ## Holroyd Road, ## Reading, ## Berks. ## Dear Pete, ## ## Permit me to introduce you to the facility of facsimile ## transmission. ## ## In facsimile a photocell is caused to perform a raster scan over ## ## ‘ the subject copy. The variations of print density on the document ## cause the photocell to generate an analogous electrical video signal. ## This signal is used to modulate a carrier, which is transmitted to a ## remote destination over a radio or cable communications link. ## ## At the remote terminal, demodulation reconstructs the video ## signal, which is used to modulate the density of print produced by a ## printing device. This device is scanning in a raster scan synchronised ## with that at the transmitting terminal. As a result, a facsimile ## copy of the subject document is produced. ## ## Probably you have uses for this facility in your organisation. ## ## Yours sincerely, ## f{ {. ## P.J. CROSS ## Group Leader - Facsimile Research ## Registered in England: No. 2038 ## No. 1 Registered Office: 680 Vicara Lane, Ilford. Esaex, Voila! You’ve just digitized text. The formatting is a little off, but things look good overall. And most importantly, it looks like everything has been transcribed correctly. As you ran this process, you might’ve noticed that a new png file briefly appeared on your computer. This is because tesseract converts pdfs to png under the hood as part of its pre-processing work and then silently deletes that png when it outputs its matches. If you have a collection of pdf files that you’d like to OCR, it can sometimes be faster and less memory intensive to convert them all to png first. You can perform this conversion like so: png &lt;- pdf_convert(new_pdf, format=&quot;png&quot;, filenames=&quot;./img/png_example.png&quot;) ## Converting page 1 to ./img/png_example.png... done! In addition to making a png object in your RStudio environment, pdf_convert() will also save that file directly to your working directory. Imagine, for example, how you might put a vector of pdf files through a for loop and save them to a directory, where they can be stored until you’re ready to OCR them. pdfs &lt;- c(&quot;list.pdf&quot;, &quot;of.pdf&quot;, &quot;files.pdf&quot;, &quot;to.pdf&quot;, &quot;convert.pdf&quot;) outfiles &lt;- c(&quot;list.png&quot;, &quot;of.png&quot;, &quot;files.png&quot;, &quot;to.png&quot;, &quot;convert.png&quot;) for (i in 1:length(pdfs)) { pdf_convert(pdfs[i], format=&quot;png&quot;, filenames=outfiles[i]) } ocr() can work with a number of different image types. It takes pngs in the same way as it takes pdfs: png_ocr_output &lt;- ocr(png) 14.3 Accuracy If you cat() the output from the above png file, you might notice that the text is messier than it was when we used pdf_text_ocr(). cat(png_ocr_output) ## THE SLEREXE COMPANY LIMITED ## SAPORS LANE - BOOLE - DORSET - BH 25 $ER ## e sous (4513) 617 - Tk 12345 ## Our Ref. 350/BIC/EAC 186 Janvary, 1972. ## De. PN, Cundall, ## Kining Surveys Lid., ## Holroyd Road, ## Reading, ## Berks. ## Dear Pece, ## ## Pernit ne to introduce you to the facility of facsinile ## transmission. ## ## In facainile a photocell is coused to perforn a raster scan over ## the subject copy. The varistions of princ density on the docunent ## cause the photecell o generate an analogous electrical video signal. ## This signal is used to mdulate a carrier, vhich is cransmitted to o ## cemote destination over &amp; radio or cable communications link. ## ## A¢ the remote cerminal, demodulation reconstructs the video ## signal, which is used to modulate the density of print produced by @ ## printing device. Tnis device is scanning in 4 raster scan synchronised ## Uich that at the cransmitring terminal. As &amp; result, a facsisile ## Copy of the subject document is produced. ## ## Probably you have uees for this facility in your organisation. ## ## Yours sincerely, ## P.J. cross ## Group Leader - Facsinile Research This doesn’t have to do with the png file format per se but rather with the way we created our file. If you open it, you’ll see that it’s quite blurry, which has made it harder for ocr() to match the text it represents: This blurriness is because pdf_convert() defaults its conversions to 72 dpi, or dots per inch. Dpi is a measure of image resolution (originally from inkjet printing), which describes the amount of pixels your computer uses to create images. More pixels means higher image resolution, though this comes with a trade off: images with a high dpi are also bigger and take up more space on your computer. Usually, a dpi of 150 is sufficient for most OCR jobs, especially if your documents were printed with technologies like typewriters, dot matrix printers, and so on and if they feature fairly legible typefaces (Times New Roman, for example). A dpi of 300, however, is ideal. You can set the dpi in pdf_convert() by adding a dpi argument in the function: hi_res_png &lt;- pdf_convert(new_pdf, format=&quot;png&quot;, dpi=150, filenames=&quot;./img/hi_res_png_example.png&quot;) ## Converting page 1 to ./img/hi_res_png_example.png... done! Another function, ocr_data()outputs a data frame that contains all of the words tesseract found when it scanned through your image, along with a column of confidence scores. These scores, which range from 0-100, provide valuable information about how well the OCR process has performed, which in turn may tell you whether you need to modify your pdf or png files further before OCRing them (more on this below). Generally, you can trust scores of 93 and above. To get confidence scores for an OCR job, call ocr_data() and subset the confidence column, like so: ocr_data &lt;- ocr_data(hi_res_png) confidence_scores &lt;- ocr_data$confidence print(confidence_scores) ## [1] 92.13857 91.38475 91.23807 91.23807 93.29996 92.56295 93.26220 70.64086 ## [9] 93.01996 89.35526 89.52242 89.52242 42.67688 42.67688 96.07313 92.71711 ## [17] 87.83458 96.88795 91.54445 87.78777 87.78777 87.65559 91.62273 92.34843 ## [25] 89.77596 90.55594 91.76022 92.06514 92.69786 89.87141 92.24236 92.18182 ## [33] 91.00060 85.50681 92.09026 91.46124 92.45944 91.51769 91.51769 92.03702 ## [41] 92.01013 90.96066 92.24164 92.24998 90.49390 79.35881 48.94280 91.96535 ## [49] 91.78830 93.19865 90.28869 90.28869 91.80365 91.80365 92.41957 93.18517 ## [57] 91.35117 91.66459 92.26031 59.55725 91.65620 92.85319 88.85143 88.85143 ## [65] 91.43013 92.53618 91.01624 46.33485 90.00519 92.77856 92.17099 91.57552 ## [73] 92.91947 91.35083 91.35083 89.52011 92.17740 92.17690 91.17965 92.13211 ## [81] 90.32191 92.12690 92.57925 91.50474 92.65192 91.54854 92.03278 92.12846 ## [89] 92.12846 92.59993 93.13262 91.75418 92.46236 92.56086 92.50134 91.19598 ## [97] 91.44257 89.06452 92.32296 92.01079 92.46326 91.14729 90.52568 91.94347 ## [105] 91.94347 90.66655 91.42926 91.71403 86.76886 92.14970 92.17909 90.94286 ## [113] 92.76601 93.08193 92.06605 92.16745 91.70026 91.56775 91.12645 91.00975 ## [121] 92.05129 93.12570 93.27691 93.27691 91.80145 91.35611 71.01427 92.27676 ## [129] 89.75899 83.44016 89.61749 87.48296 92.16154 93.15559 92.01822 91.42703 ## [137] 91.79588 92.10561 92.70488 91.68903 90.74780 90.74780 91.49944 92.60815 ## [145] 92.56828 91.94787 92.36919 90.87371 91.16226 91.95363 91.07956 91.07956 ## [153] 91.82436 92.90215 92.83604 92.72958 91.67342 92.18327 92.68385 92.30362 ## [161] 92.14813 92.26443 90.58723 90.73596 92.27166 50.64243 59.75372 56.96629 ## [169] 85.22475 88.63677 91.58677 91.72172 93.29646 92.40235 90.71992 86.72282 ## [177] 84.96437 84.08060 91.98026 95.90424 88.61440 81.63094 90.19997 75.30827 ## [185] 82.44823 75.63014 57.31424 63.12554 44.16006 The mean is a good indicator of the overall OCR quality: confidence_mean &lt;- mean(confidence_scores) print(confidence_mean) ## [1] 88.55039 Looks pretty good, though there were a few low scores that dragged the score down a bit. Let’s look at the median: confidence_median &lt;- median(confidence_scores) print(confidence_median) ## [1] 91.67342 We can work with that! If we want to check our output a bit more closely, we can do two things. First, we can look directly at ocr_data and compare, row by row, a given word and its confidence score. print(ocr_data) ## word confidence bbox ## 1 SAPORS 92.13857 422,194,497,208 ## 2 LANE 91.38475 508,194,560,208 ## 3 - 91.23807 570,203,575,205 ## 4 BOOLE 91.23807 585,193,651,208 ## 5 - 93.29996 661,202,666,205 ## 6 DORSET 92.56295 676,193,755,208 ## 7 - 93.26220 764,203,769,205 ## 8 BH25 70.64086 780,193,831,208 ## 9 8 93.01996 842,193,850,208 ## 10 ER 89.35526 856,194,883,208 ## 11 TELEPHONE 89.52242 449,232,534,243 ## 12 BOOLE 89.52242 544,232,589,243 ## 13 (945 42.67688 600,229,634,246 ## 14 13) 42.67688 640,229,664,246 ## 15 51617 96.07313 675,229,719,244 ## 16 - 92.71711 730,237,735,240 ## 17 TELEX 87.83458 746,232,792,243 ## 18 123456 96.88795 804,228,857,244 ## 19 Our 91.54445 211,392,246,408 ## 20 Ref. 87.78777 261,391,306,407 ## 21 350/PJC/EAC 87.78777 325,389,459,409 ## 22 18th 87.65559 863,389,910,405 ## 23 January, 91.62273 924,389,1020,408 ## 24 1972. 92.34843 1038,388,1095,405 ## 25 Dr. 89.77596 212,492,244,508 ## 26 P.N. 90.55594 262,492,307,508 ## 27 Cundall, 91.76022 325,491,419,510 ## 28 Mining 92.06514 212,516,286,538 ## 29 Surveys 92.69786 301,518,383,536 ## 30 Ltd., 89.87141 398,516,457,535 ## 31 Holroyd 92.24236 212,543,298,562 ## 32 Road, 92.18182 313,542,369,561 ## 33 Reading, 91.00060 213,566,308,587 ## 34 Berks. 85.50681 213,593,282,608 ## 35 Dear 92.09026 213,668,261,683 ## 36 Pete, 91.46124 275,668,333,686 ## 37 Permit 92.45944 276,715,348,732 ## 38 me 91.51769 362,721,386,732 ## 39 to 91.51769 402,719,423,732 ## 40 introduce 92.03702 439,715,548,731 ## 41 you 92.01013 562,720,599,735 ## 42 to 90.96066 614,718,636,731 ## 43 the 92.24164 652,716,685,731 ## 44 facility 92.24998 702,714,799,735 ## 45 of 90.49390 813,715,836,731 ## 46 facsimile 79.35881 852,713,961,731 ## 47 transmission. 48.94280 215,740,371,757 ## 48 In 91.96535 278,793,300,807 ## 49 facsimile 91.78830 316,790,424,807 ## 50 a 93.19865 439,796,450,806 ## 51 photocell 90.28869 463,791,573,811 ## 52 is 90.28869 589,790,611,806 ## 53 caused 91.80365 627,791,700,807 ## 54 to 91.80365 714,793,736,806 ## 55 perform 92.41957 751,790,839,810 ## 56 a 93.18517 852,794,862,806 ## 57 raster 91.35117 876,793,950,806 ## 58 scan 91.66459 965,794,1013,806 ## 59 over 92.26031 1026,793,1075,805 ## 60 . 59.55725 16,824,18,826 ## 61 the 91.65620 215,817,249,832 ## 62 subject 92.85319 265,815,349,836 ## 63 copy. 88.85143 364,820,421,835 ## 64 The 88.85143 451,816,486,831 ## 65 variations 91.43013 501,814,623,831 ## 66 of 92.53618 639,815,661,831 ## 67 print 91.01624 675,814,736,835 ## 68 denmsity 46.33485 752,814,837,834 ## 69 on 90.00519 851,819,875,830 ## 70 the 92.77856 890,814,924,830 ## 71 document 92.17099 939,814,1037,830 ## 72 cause 91.57552 215,846,275,857 ## 73 the 92.91947 290,841,324,857 ## 74 photocell 91.35083 338,841,449,861 ## 75 to 91.35083 465,844,487,857 ## 76 generate 89.52011 502,844,599,860 ## 77 an 92.17740 614,845,637,857 ## 78 analogous 92.17690 652,841,761,861 ## 79 electrical 91.17965 777,839,898,856 ## 80 video 92.13211 914,838,975,856 ## 81 signal. 90.32191 989,838,1071,859 ## 82 This 92.12690 215,865,261,881 ## 83 signal 92.57925 278,865,349,886 ## 84 is 91.50474 365,865,386,881 ## 85 used 92.65192 402,866,450,882 ## 86 to 91.54854 465,868,487,881 ## 87 modulate 92.03278 501,865,599,881 ## 88 a 92.12846 615,870,626,881 ## 89 carrier, 92.12846 639,865,735,884 ## 90 which 92.59993 750,864,812,881 ## 91 is 93.13262 828,864,849,881 ## 92 transmitted 91.75418 865,863,1000,881 ## 93 to 92.46236 1015,867,1037,880 ## 94 a 92.56086 1052,868,1063,879 ## 95 remote 92.50134 215,894,287,907 ## 96 destination 91.19598 302,890,438,907 ## 97 over 91.44257 451,895,500,906 ## 98 a 89.06452 514,895,525,906 ## 99 radio 92.32296 539,889,599,906 ## 100 or 92.01079 614,895,637,906 ## 101 cable 92.46326 653,891,712,906 ## 102 communications 91.14729 727,888,899,906 ## 103 link. 90.52568 915,888,972,905 ## 104 At 91.94347 277,941,300,956 ## 105 the 91.94347 316,941,350,956 ## 106 remote 90.66655 365,943,437,956 ## 107 terminal, 91.42926 453,939,560,962 ## 108 demodulation 91.71403 577,939,725,956 ## 109 reconstructs 86.76886 740,942,886,956 ## 110 the 92.14970 903,940,937,956 ## 111 video 92.17909 951,938,1013,955 ## 112 signal, 90.94286 215,964,297,986 ## 113 which 92.76601 314,964,375,981 ## 114 is 93.08193 390,964,411,981 ## 115 used 92.06605 427,965,475,981 ## 116 to 92.16745 490,968,512,981 ## 117 modulate 91.70026 526,965,625,981 ## 118 the 91.56775 641,965,675,981 ## 119 density 91.12645 690,964,775,984 ## 120 of 91.00975 789,964,812,980 ## 121 print 92.05129 826,963,887,984 ## 122 produced 93.12570 901,964,1001,984 ## 123 by 93.27691 1013,964,1038,983 ## 124 a 93.27691 1052,968,1063,979 ## 125 printing 91.80145 215,989,314,1010 ## 126 device. 91.35611 327,989,410,1006 ## 127 This 71.01427 440,989,486,1006 ## 128 device 92.27676 502,989,575,1006 ## 129 is 89.75899 590,989,611,1006 ## 130 scanning 83.44016 628,989,726,1010 ## 131 in 89.61749 741,989,763,1005 ## 132 a 87.48296 777,994,788,1005 ## 133 raster 92.16154 802,992,876,1005 ## 134 scan 93.15559 890,994,938,1005 ## 135 synchronised 92.01822 953,988,1101,1009 ## 136 with 91.42703 213,1015,263,1031 ## 137 that 91.79588 278,1015,325,1031 ## 138 at 92.10561 340,1018,362,1031 ## 139 the 92.70488 379,1015,413,1031 ## 140 transmitting 91.68903 428,1014,576,1035 ## 141 terminal. 90.74780 591,1014,697,1031 ## 142 As 90.74780 727,1015,749,1031 ## 143 a 91.49944 765,1019,775,1030 ## 144 result, 92.60815 789,1015,873,1034 ## 145 a 92.56828 890,1019,901,1030 ## 146 facsimile 91.94787 915,1012,1026,1030 ## 147 copy 92.36919 215,1045,263,1060 ## 148 of 90.87371 278,1040,300,1056 ## 149 the 91.16226 317,1041,350,1056 ## 150 subject 91.95363 365,1039,450,1060 ## 151 document 91.07956 465,1040,562,1056 ## 152 is 91.07956 578,1039,599,1055 ## 153 produced. 91.82436 614,1040,722,1060 ## 154 Probably 92.90215 278,1091,375,1110 ## 155 you 92.83604 389,1095,427,1110 ## 156 have 92.72958 439,1091,488,1106 ## 157 uses 91.67342 503,1094,550,1106 ## 158 for 92.18327 566,1090,601,1106 ## 159 this 92.68385 616,1089,662,1106 ## 160 facility 92.30362 678,1088,775,1110 ## 161 in 92.14813 792,1088,814,1105 ## 162 your 92.26443 827,1094,876,1110 ## 163 organisation. 90.58723 890,1087,1049,1110 ## 164 Yours 90.73596 678,1141,737,1156 ## 165 sincerely, 92.27166 753,1139,874,1160 ## 166 f{ 50.64243 699,1202,778,1272 ## 167 &#39;/ 59.75372 808,1209,823,1266 ## 168 . 56.96629 828,1257,834,1266 ## 169 P.J. 85.22475 678,1304,724,1319 ## 170 CROSS 88.63677 742,1304,802,1319 ## 171 Group 91.58677 678,1329,739,1347 ## 172 Leader 91.72172 753,1328,827,1344 ## 173 - 93.29646 840,1334,852,1338 ## 174 Facsimile 92.40235 867,1326,978,1344 ## 175 Research 90.71992 992,1327,1092,1344 ## 176 Registered 86.72282 521,1574,600,1587 ## 177 in 84.96437 607,1574,621,1584 ## 178 England: 84.08060 629,1573,695,1586 ## 179 No. 91.98026 725,1574,749,1584 ## 180 2038 95.90424 756,1574,793,1584 ## 181 No. 88.61440 72,1597,99,1610 ## 182 1 81.63094 110,1597,114,1609 ## 183 Registered 90.19997 457,1592,535,1605 ## 184 Office: 75.30827 545,1592,595,1603 ## 185 80 82.44823 627,1592,644,1602 ## 186 Vicara 75.63014 651,1592,700,1602 ## 187 Lane, 57.31424 723,1592,763,1605 ## 188 Ilford. 63.12554 771,1592,817,1602 ## 189 Esasx, 44.16006 825,1592,873,1603 That’s a lot of information though. Something a little more sparse might be better. We can use base R’s table() function to count the number of times unique words appear in the OCR data. We do this with the word column in our ocr_data variable from above: ocr_vocabulary &lt;- table(ocr_data$word) ocr_vocabulary &lt;- as.data.frame(ocr_vocabulary) Let’s look at the first 30 words: head(ocr_vocabulary, 30) ## Var1 Freq ## 1 - 5 ## 2 . 2 ## 3 &#39;/ 1 ## 4 (945 1 ## 5 1 1 ## 6 123456 1 ## 7 13) 1 ## 8 18th 1 ## 9 1972. 1 ## 10 2038 1 ## 11 350/PJC/EAC 1 ## 12 51617 1 ## 13 8 1 ## 14 80 1 ## 15 a 9 ## 16 an 1 ## 17 analogous 1 ## 18 As 1 ## 19 at 1 ## 20 At 1 ## 21 Berks. 1 ## 22 BH25 1 ## 23 BOOLE 2 ## 24 by 1 ## 25 cable 1 ## 26 carrier, 1 ## 27 cause 1 ## 28 caused 1 ## 29 communications 1 ## 30 copy 1 This representation makes it easy to spot errors like discrepancies in spelling. We could correct those either manually or with string matching. One way to further examine this table is to look for words that only appear once or twice in the output; among such entries you’ll often find misspellings. The table does, however, have its limitations. Looking at this data can quickly become overwhelming if you send in too much text. Additionally, notice that punctuation “sticks” to words and that uppercase and lowercase variants of words are counted separately, rather than together. These quirks are fine, useful even, if we’re just spot-checking for errors, but we’d need to further clean this data if we wanted to use it in computational text analysis. A later lecture will discuss other methods that we can use to clean text. When working in a data-forensic mode with page images, it’s a good idea to pull a few files at random and run them through ocr_data() to see what you’re working with. OCR accuracy is often wholly reliant on the quality of the page images, and most of the work that goes into digitizing text involves properly preparing those images for OCR. Adjustments include making sure images are converted to black and white, increasing image contrast and brightness, increasing dpi, and rotating images so that their text is more or less horizontal. tesseract performs some of these tasks itself, but you can also do them ahead of time and often you’ll have more control over quality this way. The tesseract documentation goes into detail about what you can do to improve accuracy before even opening RStudio; we can’t cover this in depth, but keep the resource in mind as you work with this type of material. And remember: the only way to completely trust your accuracy is to go through the OCR output yourself. It’s a very common thing to have to make small tweaks to output. In this sense, we haven’t quite left the era of hand transcription. 14.4 Unreadable Text All that said, these various strategies for improving accuracy will only get you so far if your page images are composed in a way OCR just can’t read. OCR systems contain a lot of in-built assumptions about what “normal” text is, and they are incredibly brittle when they encounter text that diverges from that norm. Early systems, for example, required documents to be printed with special, machine-readable typefaces; texts that contained anything other than this design couldn’t be read. Now, OCR is much better at handling a variety of text styling, but systems still struggle with old print materials like blackletter. Running: ballad &lt;- &quot;https://ebba.english.ucsb.edu/images/cache/hunt_1_18305_2448x2448.jpg&quot; ballad_out &lt;- ocr(ballad) Produces: cat(ballad_out) ## CAditeription of Qoptons falcehoo ) ## nf Doge thyze, and of bis fatall farewell, ## ache fatal fineof Sratteurs lees : ## \\ 4Bp gulice due, deferuyng foe. . : ## Flate (alas) the great tntruth = Whe Crane wolvetipedpto the funne, ort, bis futtrpug long (be fare) 7 ## Mf Wrattours, hotw ttfped % heavdit once of olde: _ TH pll pay bis foes atlak: : : ## WU do lit toknolv, hal herex-aae And with the kyng ofbpresdinitrine his metcpe moued once alway, : ## Wotv late allegeance fed. wp Fame, J beardittolve ~~ He hall them quight out caté j ## @ 3f Riucrsrage againt the Sea. Qnodotwac ihe wolve not fal fre ne, WH ith fentence int fo2 their bntruth, 7 ## And {well with fondeine rayne s Wut higher pid nidmoury ? And boeakpng of his tupll: : ## Wolw gla ave they to fall agapne, il patt her veach (faith woe repo2te) Che fruits of their fedictous feds, E ## Anodtrace their wwonted traine? Shame madea backe recour She barnes of earth thail fpll. ## B) 3f fire by force wolde forge the fall 3 touch no Armes herein at all, Wheterfoules God wot foze clogd w crime ## Df any fumptuoufe place, sButthelvafable wpe: _ and their potteritic ## A) 3f water flods byd him leaueof, Wi hote mo2all fence doth reper MWelpotted fore with theirabule, ## dis flames be wyll difgrace. DF clpmers bye the guyle. And ttand by their folie. ## 3f Goo command the wyrdes to ceale, Who buyloes a boule of many &gt; heir linpngs left their namea thame, ## ‘ Ibis blattes are lapo full low: andlatth not ground yorker heir dedes tith popfon (ped: ; ## H 3f God command the eas to calmes 4But doth ertortethe groundt ig, Sbeirdeathesatvagefor wantofgrace ## i hey tyll notrageo2 flow. _ Wis builopng can not dure, SUbeir honours quite ts dead, 4 ## A all thinges at Gods commandemet be, @€ Who fekes furmifing to dip heir leth tofedethe kytes andcrowes ## f afbetheirflateregarde: : a Kuler fentby GOD: aCheir armes a maze fo2 men; ie ## H Audnoman lines whole veftinie 4s fubiec {ure, deuoide of grace. Sbeir guerdon as eramples are Bs ## wy hint ts bupeeparde. he caufe of bis olune rod. Co Dafh dolte Dunces den, ke ## ) iSut when a mait fo2lakes thethip, - A byave that Wyll bernett defple Whol vp pour fnouts pou fluggih forte Q ## s ° Androlwles in wallowing wanes; ‘By right ould lofe a wyng: Poumumming malkpng route : : ## And of bis valuntarte wyil, Qua thents thee no fying fouls €rtoll pour erclantations vp, ## i Wis one god bap depraues + {But How as other thyng. 4Baals chapletnes,champions ffoute. &amp; ## HM olw hal be bopetolcape the gulfe 2 Anobe that lofeth all at games, Make fate fo2 pardons, papitts boaue, ii ## : Wow Mhal be thinke todeale 2 2 {pendes infotule ercefle: Foz traitours indulgence; o ## A iolw thal his fanfic baing him found Andhopesbybhapsto bealebisharme, . fend out fome purgatorte (craps, ; ## i Zo Safties tore with faple 2 Mutt deivke of Beare diftrefte. Home wWulls with peter pence. FE ## : otw (hall his fraight tn fine fuccede 2 Go fpeake of b2pdles to reftrapne D fwarine of D20nes, how dare pe fol Bi ## 4 Alas what thall be gapne 2 aLhis wylfull waptward cretpe ¢ With labourpng Wes contend if ## # Uibatfeare by foes do makebimquake bey care not foz the bake of God, ou fought forhonte fromthe hiues, ; ## j Wow ofte fubieceto payne 2 Do princes, men bntrue. Wut gall pou foundinend. F ## ] ioin fundzie tintes in Dangers den Co cuntrye, caufers of much woe, hele walpes do watk, their lings beout F ## : 4s th2owne theman onivpfe 2 Sp eotal freeones, afall: Whee {pight wyll not auaple ; ## F) bo climes withouten holde on bye, ano Gtpeir one eftates, altpng, BWhele Peacocks proudearenakedlette fF ## z sBeware, ¥ hint adutse. a others, arpeas gall. Of their oifplayed tayple. ‘ ## S Alifuchas trut to falfe contracs, D Looe, how long thele Liserds lurkt, hele Lurkype cocks tu cullour red, , ## | D2 fecret harmes confpire? GuvG O D&gt; bow great a whple _ Solong banelurkt alofe : é ## f iBefure, with Portonstbey Haltafte Were they in Handwith fetgnedbarts Whe Beare (althongh but foty of fote) 4 ## 7 A right deferucd hire. ACbeir cuntrye to defple 2 Hath pluc his wynages by peofe. : ## &amp; Whey can not lwike for better (pede, Holv did they frame theirfurniture? . Whe Done her borotyenlighthath lol, fe ## o Soa death fo2luch to fells Iolv fit they made thet toles ¢ She wapnedas we fee : ; ## F @odgvant the tuftice of the wozlde Wow Symon fought our engipt) Wrote Who hoped by bap of othersharmes, E ## ie qput by the papnes of hell. Mo hapng to Romaine (coles. © full Bone once to be. B ## &amp; F02(uchapentiuerale it is, Holy Simon Magus playd his parte, SCbe Lyon (uffrea long the wuil, 3 ## : hat Cnglith harts did dare ain Wabilon balwde pidrage: Wis noble mynd to trpe: i ## @ io pale the boundes of duties latuc, Iolv walan bulles begon to bell, Wntpll the wWull was rageyng tod, A ## i @2 of theircuntrie care. How Judas fought bis wage. And from bis take dia hye. vi ## # Andmercie bath fo long releat Iolw Jannes and Jamb2es od abpde acben time ft twas to bid him tap : ## | Dffendours (God doth knoi) aie bount of boatneficke acs, perforce, bis hoanes to cut + u ## 4 Gnd bountic of our curteous Nuene oww Dathan, Chore, Abiram femd Andmake him leaue bis rageing tanes 4 ## ‘ ao long hath fpared ber foe. Xo path our Moyles facs. Au fcilence to be put. ° ## By But God, whole grace infpiresherbarte, Wow womaine marchant feta fret Andall the calues of Wafan kynd i ## t WA pil not abyoe the fpight iHfs pardons beaue a fale, Are weaned from their with ; if ## | Of Rebels rage, who rampeto reach Jor alwapes fomeagaint the ruth Whe Wircan Wigers tamed now, i‘ ## : From ber, her title quight. WMlolde d2eame afencelestale. __ Lemathon eates no fith. i ## A Although the flowe in pitifull seale, Gods bicar from bis god receaued 4Bebholde befoze pour balefullepes i ## L nd loueth to fucke no biwd : Gbekeyestolofcandbynds She purchace of pour parte, a ## fH 3oet Goda caueat iyll her lend sBaals chapleinthoght bo fire wolk” ie Suruep pour forefnefozrowful fight 4 ## a © appeale thole Wipers made, Such was bis pagan mynd. With fighes of bubble barte, 4 ## B) aman that fees bts bouteon fire, Godiorre howhits thetertthete ts Lament thelackeot pour alies : ## ol WH pli (eke to quench the fame: That faith fuch men tall he _ Religious rebells all: 2 ## i) Gls from the fpople fomeparteconucy, Au their religion hot nozcolne ABewwepe that pli fuccelle of yours, : ## i Cis (eke the heate to tame, Of much baviette. Come curfe pour fodcine fall. “i ## Ht who feea penthoule wether beate, And Cundey (oats of fects farts And when pe haue pour guilesoutfought # ## : Ano beares a botttroule ipndes - iuifion thall appeare ¢ , And all pour craft app2oued, 3 ## iM sButhedefull faletie of himfelte, Againk thefather, fonnethe —7UL&gt; ppeccauimus thall be pour fong ; ## : WA pil force him fuccour fynde 2 Gaink mother, saughter +k our ground tpozke is remoued, : ## abe pitifull pactent Pelican, 4s {t not come to palfe trot pra? Andlokehow Poztons(pedtheivwills &amp; ## 4 er blwd although He teas aged, battards (urethep bes _ Euen fo thetr fet all baue, bs ## i ject inyll he femeher dateto end, Cabo our gad mother Nueneo - : po better let thenthope to gayne a; ## : } @Da2tare her poung be fpen. &amp; lt ied see a “a $ut gallowes without graue. ## Ll she Cagle fpngesbher pong onesdowne Canod is bengeance long retat See : ## | What fight a at erate? eatbere bis oy feruants tele cFINIS. pee olan. a ## i) winpertec folwles the aeadly bates, Aniurioute fights of godlede men, ey : ## ‘ And rightly Cuch mitble, ‘ Moho turne as doth a whele 2 A Q eo CE OH iE ## £ ‘ ie ## a Ampzinted at London by Alerander Lacte, foz Henrie Ayskehams, divellpng at the fiqne 4 ## HC of the blacke Move, at the midole sprozth doze of Paules church. ¢ i ## i &#39; i (Note by the way that this example used a jpg file. ocr() can handle those too.) Even though every page is an “image” to OCR, OCR struggles with imagistic or unconventional page layouts, as well as inset graphics. Add to that sub-par scans of archival documents, as in the newspaper page below, and the output will contain way more errors than correct matches. newspaper &lt;- &quot;https://chroniclingamerica.loc.gov/data/batches/mimtptc_inkster_ver01/data/sn88063294/00340589130/1945120201/0599.pdf&quot; newspaper_ocr &lt;- ocr(newspaper) ## Converting page 1 to filef5983ab50c2a0599_1.png... done! Beautifully messy output results: cat(newspaper_ocr) ## ai . a ## 5 IE EI ## UNIVERSAL KEYBOARD i DVORAK KEYBOARD ## ne in o fu “ % Z x f= 7 ## ‘ . pA ‘ eee . . \\ “a fr J s a . ## . : , : og oF Sn ’ &lt; f &#39; » | mii } a a} ) ## &#39; © /\\ e MF gp O ES nn i ; ; \\2/\\4 &gt; 5 | ## | Ly FP eT a ## oh a 7 &lt; Pa “ : : E BNED Bye ee “4 = ete 2 2 s ms a m3 = tan&quot; ## ane SO a A os a &gt;) ny P\\GGYC YR + e222 ## . 1 f A P i . ae 5 iat sc dae, Sa on a ot ai , ,} Lr AT \\J CJ (JTtila ## Si a MR aie tS eR” Mi OS ## | ? S fis 7 eee. ae ie ate NS »)( * ) +702 ## : &gt; ~ ; sat 6 F S &gt; 2 me te oat hs F oy . ‘ ’ j 4 , } ## a er ae See 8 ake apa wei ## ff yee seer Ng a ‘ ## , fy Seg 33 . oe . Oy A ae . Base *) as ear , o*% ## 7 Jt grte&#39;y® Ne i . oe . &quot; “ 4 4 nd ; : . ’ vi ’ J , = ~ , ## ’ Be Sa i . SEH, . ## ff See ‘= Ps sf , ed Bad fl N . 4 ## a MA . ’ 22 , ## (Rr, ; uC ## . rai / ¢: a m * , a ## &quot; y . 4 . -— ~~ ae ## i ° : a PA — 3 : eee 7 mer | . 3 ## ; ; neg a 7 a i ~ a ; # ## : q 5 3 : sale LSIGOE emt ‘ ## : ee » &lt;3 ‘ a ‘ ## ; 7 Base ; \\ , _ 4 . ; ## ee SS ty * , : ## : i ka ee Poy Les r . »* 7 ## 5S a ead _ ’ ; tA ## ! Bea ; &lt; - 4 ; ## ? Pe ee ta i 2B. ## es - + 2 Bes 186. iy | : &#39; ## os 4 &quot; . . . peas AY Be or &#39; ## ‘ ss , bgt AAI 7. ## } ; re er &amp; aes ¢ ; ## | fo | a anti | Oa . Ss ## Py . 3 . ne i. | | | ## ; . € “ &gt; a a J ) ## “@ a ~_ . MA jj j , ## J . . oo b tt - + ; ; | ## ¥ pe ‘ OMe? ) | ## - =&lt; | ~~ . 4 Pan Pe ° . ee Pr ee oe © abe “« ~—— meheeaethae @ ‘ ## $ &lt;4 a6 : a, a m — &#39; e . x 7 | ## : \\ NG - gy oe - 2 | 2 ## h =&gt;. ” ‘“ ) . ## &#39; &#39; ’ ; ™~, ~~ es i ro ys vv a ‘ { 20 : ## &#39; ~~ aS ee , | &quot; - \\ . ## : : . ## L , ‘~S —s icin j &gt; 2 } ## = | nee ‘ner Ne ## ——————————eV—V—ake eo ntl sant * 5 é. mm rr i en mmr ## ~s = . . . ; ## e “ , Standard Typewriter Key ## : “¢ board (Left) Is the Same ## &amp; &amp; Now as When Christopher ## Sholes Invented the First ## s ————- ites &#39; = ## ) kt Typewriter (Center) in 1475, ## ; — : But It May Give Way to ## ; q i the New Dvorak Keyboard ## a a ~~ (Right). Figures Indicate ## ““% : Comparative Loads for Each ## —— Row, Hand and Finger. ## ’ . t ie v « ## r ae ” ## + ae » 2 ## | » to Tt] hedule for treamlini &#39; I post : : reek typewrite! ve ## SO aS Sa aie . : ## vorld: the typewriter keyboa t present is a ar. Commander Dvorak ## . : ; ~ ; 7 on @ is ## mn) ti¢ 2c 2 rie \\ ie built f ‘ : i.? &quot; ¥ { - 3 turned his Arts ion ## Sal jped tke adtot-ef-other things, ty Tt? &#39; ‘ . to those who lost ## } rt il usc in t} { ™~ ivy Ts 1 { 7 Noy , 3 an arm auring the ## ljuction a nuch a : | . as wark Working ## n fox jumps over the ut ¥ closely with Coionel ## il good m« in &#39; I , { &#39; ts Robert 5S a ## f offort. en ee noted newspapel ## 7 st ‘ ‘ ‘ ‘ man who i ’ hi . ## nical t li | | » =f right arr is a re ## : ne ’ ’ ult of i Ww und at ## . a Ohrdruf, Germany, ## the commander de ## ‘ &#39; i vi loped a one-har s ## ; | : m4 U typewriter. In fact ## ‘ tha | ; he invented two ot ## , them, one for th ## eft hand and or ## , ted for the rignt ## | 5 There is no rea ## ; | 4 iT) wrt y in arn, ## , DULtAe—At mputee cant typ ## ot th . is fast as the aver ## ‘ : \\ ’ ioe person * he ¢*&gt; ## bout it q plained. “On thes ## = Nee ee cnich make up 9 ## rt m . , pe &#39; a! (a POS. ? . . Cale ## i 5 Ee, a Hy Ag” a -ae Pa 7 per cent of all typ ## am 3 | eee . eS ae ae ety Oe «4 . ing —21 letters and ## t} : coy ,eer se ’ oe, | , thie period ane ## ‘ ,* | ‘ . &gt;} ’ re - 4 . ‘ ## , Bera &#39; i: ene 8 . Trias Att »&#39; ithin ## &#39; the load \\ 2 a i isv reach of the ## oft eaker, |} |: that t — han Th, ## ™ &#39; : &#39; i i ## : | fit) ri &lt;x . oa ata , e thy, &#39; five l¢ Pere ## : e 4 . sete ‘\\)y ’ it every rir 4 ; — ## / : in f to . c.. ence . naking Up Lie per ## » | 4} ‘ F ‘ tir : oe - ## | Set isis cuit acini Dl oe ee, Re on ent of typing are ## sere are overworked while ne i, ee X. - reached with son ## | ‘7 ; ~ 4 . . ee “ os sf ## ers } &#39;- ala ’ — a _—™ - i 2 en h &#39; ulty, but with ## (‘omn rier Dvorak. ee &#39; , trie hand still ! ## rwmer director of re | as he ele ice) &quot; home position.— ## irch of the University § i ta RI fi sp ‘ om — ae By using the sp ## : . . en 7 Sot fi a2 Pa £4 bas eh a nnn on Soe i : , 7 ’ - &#39; ## f&gt;) VA asnineton and now a on Oe % 6 EWE: Giga , a ce, 5 Su gy er . bal Keybo il ## ga : . — no ” &quot;s * or Re ## naval et] f Cy expert, a ae i ra mSstirmates trat } ## , rked out cif) ‘ tirely ee ages . a rie ty} word ; ## iifferent arrangement ; sae ute will not hb ## piacing the impo! tant inusual for Ol ## kave on the “hom row. On the Dvorak Keyboard, ind typists ## : ; : : _- ## one on which the fin Which She Is Demonstrating, Lenore Fenton Knowing tha ## ‘fers rest MacLain, “the Lastest Secretary in the World,” Is Able to Type 182 Net Words a Minute terans who ga&#39; ## , : &#39; - . ## “The differe &gt; y . Up an aft for the ## \\ +3. } ry? &#39; he ’ Poe &#39; \\ | ; &#39; | f e © crert lor , ; ## ; : fir rtiry ; ‘ t} ‘ t? &#39; &#39; fellov | i! t! ## from 1 } i day put ol 0 &#39; it ne said ## &#39; the new kevbhboard &#39; it wont be easy to co ## the lard J yoard, only ; | pra thie ind Di ## , i without : Lf ; &#39; 7 7 ; enang eetu ## ’ : | } ° ’ ; ry : | ; }\\ :) ri¢ ’ { | : if I 1% it ib ## ent thie be laded alti ## ) , ‘ —_ ## ) } ’ ‘) ; ; &#39; . . rie | &#39; ty ## , . : : &quot; , c&quot; ## aa &#39; . ! nder ad nded I&#39;ll tell ## . 5 -F | Vv] &#39; , , ru ## &#39; &#39; | i : | \\ : ’ ## 2 December 2. IN to 7388 LMERIC AUN WEED Y ## “ One strategy you might use to work with sources like this is to crop out everything you don’t want to OCR. This would be especially effective if, for example, you had a newspaper column that always appeared in the top left-hand corner of the page. You could preprocess your page images so that they only showed that part of the newspaper and left out any ads, images, or extra text. Doing so would likely increase the quality of your OCR output. Such a strategy can be achieved outside of R with software ranging from Adobe Photoshop or the open-source GIMP to Apple’s Automator workflows. Within R, packages like tabulizer and magick enable this. You won’t, however, be required to use these tools in the course, though we may have a chance to demonstrate some of them during lecture. There are several other scenarios where OCR might not be able to read text. Two final (and major) ones are worth highlighting. First, for a long time OCR support for non-alphabetic writing systems was all but nonexistent. New datasets have been released in recent years that mostly rectify these absences, but sometimes support remains spotty and your milage may vary. Second, OCR continues to struggle with handwriting. While it is possible to train unsupervised learning processes on datasets of handwriting and get good results, as of yet there is no general purpose method for OCRing handwritten texts. The various ways people write just don’t conform to the standardized methods of printing that enable computers to recognize text in images. If, someday, you figure out a solution for this, you’ll have solved one of the most challenging problems in computer vision and pattern recognition to date! "]]
