<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>20 Data Forensics and Cleaning: Unstructured Data | Adventures in Data Science</title>
  <meta name="description" content="20 Data Forensics and Cleaning: Unstructured Data | Adventures in Data Science" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="20 Data Forensics and Cleaning: Unstructured Data | Adventures in Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ucdavisdatalab.github.io/adventures_in_data_science/" />
  
  
  <meta name="github-repo" content="ucdavisdatalab/adventures_in_data_science" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="20 Data Forensics and Cleaning: Unstructured Data | Adventures in Data Science" />
  
  
  

<meta name="author" content="Dr. Carl Stahmer" />
<meta name="author" content="Dr. Pamela L. Reynolds" />
<meta name="author" content="Dr. Nick Ulle" />
<meta name="author" content="Dr. Tyler Shoemaker" />
<meta name="author" content="Dr. Michele Tobias" />
<meta name="author" content="Dr. Wesley Brooks" />
<meta name="author" content="Arthur Koehl" />
<meta name="author" content="Carrie Alexander" />
<meta name="author" content="Jared Joseph" />


<meta name="date" content="2022-01-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-forensics-and-cleaning-structured-data.html"/>
<link rel="next" href="data-forensics-and-cleaning-geospatial-data.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://datalab.ucdavis.edu/">
  <img src="img/datalab-logo-full-color-rgb.png" style="height: 100%; width: 100%; object-fit: contain" />
</a></li>
<li><a href="./" style="font-size: 18px">Adventures in Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="1" data-path="working-with-the-command-line.html"><a href="working-with-the-command-line.html"><i class="fa fa-check"></i><b>1</b> Working with the Command Line</a>
<ul>
<li class="chapter" data-level="1.1" data-path="working-with-the-command-line.html"><a href="working-with-the-command-line.html#interacting-with-the-command-line"><i class="fa fa-check"></i><b>1.1</b> Interacting with the Command Line</a></li>
<li class="chapter" data-level="1.2" data-path="working-with-the-command-line.html"><a href="working-with-the-command-line.html#common-command-line-commands"><i class="fa fa-check"></i><b>1.2</b> Common Command Line Commands</a></li>
<li class="chapter" data-level="1.3" data-path="working-with-the-command-line.html"><a href="working-with-the-command-line.html#command-line-text-editors"><i class="fa fa-check"></i><b>1.3</b> Command Line Text Editors</a></li>
<li class="chapter" data-level="1.4" data-path="working-with-the-command-line.html"><a href="working-with-the-command-line.html#basic-vim-commands"><i class="fa fa-check"></i><b>1.4</b> Basic Vim Commands</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html"><i class="fa fa-check"></i><b>2</b> Introduction to Version Control</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#what-is-version-control"><i class="fa fa-check"></i><b>2.1</b> What is Version Control?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#software-assisted-version-control"><i class="fa fa-check"></i><b>2.2</b> Software Assisted Version Control</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#local-vs-server-based-version-control"><i class="fa fa-check"></i><b>2.3</b> Local vs Server Based Version Control</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#central-version-control-systems"><i class="fa fa-check"></i><b>2.4</b> Central Version Control Systems</a></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#distributed-version-control-systems"><i class="fa fa-check"></i><b>2.5</b> Distributed Version Control Systems</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#the-best-of-both-worlds"><i class="fa fa-check"></i><b>2.6</b> The Best of Both Worlds</a></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#vcs-and-the-computer-file-system"><i class="fa fa-check"></i><b>2.7</b> VCS and the Computer File System</a></li>
<li class="chapter" data-level="2.8" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#how-computers-store-and-access-information"><i class="fa fa-check"></i><b>2.8</b> How Computers Store and Access Information</a></li>
<li class="chapter" data-level="2.9" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#how-vcs-manage-your-files"><i class="fa fa-check"></i><b>2.9</b> How VCS Manage Your Files</a></li>
<li class="chapter" data-level="2.10" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#graph-based-data-management"><i class="fa fa-check"></i><b>2.10</b> Graph-Based Data Management</a></li>
<li class="chapter" data-level="2.11" data-path="introduction-to-version-control.html"><a href="introduction-to-version-control.html#additional-resources"><i class="fa fa-check"></i><b>2.11</b> Additional Resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html"><i class="fa fa-check"></i><b>3</b> Git Version Control Basics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#save-stage-commit"><i class="fa fa-check"></i><b>3.1</b> Save, Stage, Commit</a></li>
<li class="chapter" data-level="3.2" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#creating-your-first-repo"><i class="fa fa-check"></i><b>3.2</b> Creating Your First Repo</a></li>
<li class="chapter" data-level="3.3" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#checking-the-status-of-a-repo"><i class="fa fa-check"></i><b>3.3</b> Checking the Status of a Repo</a></li>
<li class="chapter" data-level="3.4" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#version-of-a-file"><i class="fa fa-check"></i><b>3.4</b> Version of a File</a></li>
<li class="chapter" data-level="3.5" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#view-a-history-of-your-commits"><i class="fa fa-check"></i><b>3.5</b> View a History of Your Commits</a></li>
<li class="chapter" data-level="3.6" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#comparing-commits"><i class="fa fa-check"></i><b>3.6</b> Comparing Commits</a></li>
<li class="chapter" data-level="3.7" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#comparing-files"><i class="fa fa-check"></i><b>3.7</b> Comparing Files</a></li>
<li class="chapter" data-level="3.8" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#to-view-an-earlier-commit"><i class="fa fa-check"></i><b>3.8</b> To View an Earlier Commit</a></li>
<li class="chapter" data-level="3.9" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#undoing-things"><i class="fa fa-check"></i><b>3.9</b> Undoing Things</a></li>
<li class="chapter" data-level="3.10" data-path="git-version-control-basics.html"><a href="git-version-control-basics.html#when-things-go-wrong"><i class="fa fa-check"></i><b>3.10</b> When Things go Wrong!</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="git-branching.html"><a href="git-branching.html"><i class="fa fa-check"></i><b>4</b> Git Branching</a>
<ul>
<li class="chapter" data-level="4.1" data-path="git-branching.html"><a href="git-branching.html#merging-branches"><i class="fa fa-check"></i><b>4.1</b> Merging Branches</a></li>
<li class="chapter" data-level="4.2" data-path="git-branching.html"><a href="git-branching.html#branching-workflows"><i class="fa fa-check"></i><b>4.2</b> Branching Workflows</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html"><i class="fa fa-check"></i><b>5</b> Working with Remote Repositories</a>
<ul>
<li class="chapter" data-level="5.1" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#github-basics"><i class="fa fa-check"></i><b>5.1</b> GitHub Basics</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#communicating-through-github"><i class="fa fa-check"></i><b>5.1.1</b> Communicating Through GitHub</a></li>
<li class="chapter" data-level="5.1.2" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#what-should-i-push-to-github"><i class="fa fa-check"></i><b>5.1.2</b> What Should I Push to GitHub?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#basic-github-account-setup"><i class="fa fa-check"></i><b>5.2</b> Basic GitHub Account Setup</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#locally-setting-up-your-git-credentials"><i class="fa fa-check"></i><b>5.2.1</b> Locally Setting Up Your Git Credentials</a></li>
<li class="chapter" data-level="5.2.2" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#ssh-keys-and-github"><i class="fa fa-check"></i><b>5.2.2</b> SSH Keys and GitHub</a></li>
<li class="chapter" data-level="5.2.3" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#connecting-to-github-with-ssh"><i class="fa fa-check"></i><b>5.2.3</b> Connecting to GitHub with SSH</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#github-desktop-or-the-command-line"><i class="fa fa-check"></i><b>5.3</b> GitHub Desktop, or the Command Line?</a></li>
<li class="chapter" data-level="5.4" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#sync-with-github"><i class="fa fa-check"></i><b>5.4</b> Sync with GitHub</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#preparing-to-sync-your-repository"><i class="fa fa-check"></i><b>5.4.1</b> Preparing to Sync Your Repository</a></li>
<li class="chapter" data-level="5.4.2" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#pushing-a-local-repository"><i class="fa fa-check"></i><b>5.4.2</b> Pushing a Local Repository</a></li>
<li class="chapter" data-level="5.4.3" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#tracking-files-remotely"><i class="fa fa-check"></i><b>5.4.3</b> Tracking Files Remotely</a></li>
<li class="chapter" data-level="5.4.4" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#pulling-changes-from-a-remote-repository"><i class="fa fa-check"></i><b>5.4.4</b> Pulling Changes from a Remote Repository</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#cloning-a-repository"><i class="fa fa-check"></i><b>5.5</b> Cloning a Repository</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="working-with-remote-repositories.html"><a href="working-with-remote-repositories.html#how-to-clone-a-repository"><i class="fa fa-check"></i><b>5.5.1</b> How to Clone a Repository</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>6</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#learning-objectives"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#before-we-start"><i class="fa fa-check"></i><b>6.2</b> Before We Start</a></li>
<li class="chapter" data-level="6.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#mathematical-operations"><i class="fa fa-check"></i><b>6.3</b> Mathematical Operations</a></li>
<li class="chapter" data-level="6.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#variables"><i class="fa fa-check"></i><b>6.4</b> Variables</a></li>
<li class="chapter" data-level="6.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#calling-functions"><i class="fa fa-check"></i><b>6.5</b> Calling Functions</a></li>
<li class="chapter" data-level="6.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#help"><i class="fa fa-check"></i><b>6.6</b> HELP!</a></li>
<li class="chapter" data-level="6.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#when-something-goes-wrong-and-it-will"><i class="fa fa-check"></i><b>6.7</b> When Something Goes Wrong (and it will)</a></li>
<li class="chapter" data-level="6.8" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-types-and-classes"><i class="fa fa-check"></i><b>6.8</b> Data Types and Classes</a></li>
<li class="chapter" data-level="6.9" data-path="introduction-to-r.html"><a href="introduction-to-r.html#vectors"><i class="fa fa-check"></i><b>6.9</b> Vectors</a></li>
<li class="chapter" data-level="6.10" data-path="introduction-to-r.html"><a href="introduction-to-r.html#inspecting-vectors"><i class="fa fa-check"></i><b>6.10</b> Inspecting Vectors</a></li>
<li class="chapter" data-level="6.11" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-frames"><i class="fa fa-check"></i><b>6.11</b> Data Frames</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#inspecting-data-frames"><i class="fa fa-check"></i><b>6.11.1</b> Inspecting Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="6.12" data-path="introduction-to-r.html"><a href="introduction-to-r.html#subsetting"><i class="fa fa-check"></i><b>6.12</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="control-structures.html"><a href="control-structures.html"><i class="fa fa-check"></i><b>7</b> Control Structures</a>
<ul>
<li class="chapter" data-level="7.1" data-path="control-structures.html"><a href="control-structures.html#if-statement"><i class="fa fa-check"></i><b>7.1</b> <em>If</em> Statement</a></li>
<li class="chapter" data-level="7.2" data-path="control-structures.html"><a href="control-structures.html#relationship-operators"><i class="fa fa-check"></i><b>7.2</b> Relationship Operators</a></li>
<li class="chapter" data-level="7.3" data-path="control-structures.html"><a href="control-structures.html#if-else-statement"><i class="fa fa-check"></i><b>7.3</b> <em>If Else</em> Statement</a></li>
<li class="chapter" data-level="7.4" data-path="control-structures.html"><a href="control-structures.html#ifelse-statement"><i class="fa fa-check"></i><b>7.4</b> <em>ifelse</em> Statement</a></li>
<li class="chapter" data-level="7.5" data-path="control-structures.html"><a href="control-structures.html#the-switch-statement"><i class="fa fa-check"></i><b>7.5</b> The <em>switch</em> Statement</a></li>
<li class="chapter" data-level="7.6" data-path="control-structures.html"><a href="control-structures.html#the-which-statement"><i class="fa fa-check"></i><b>7.6</b> The <em>which</em> Statement</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="iterating-loops.html"><a href="iterating-loops.html"><i class="fa fa-check"></i><b>8</b> Iterating (Loops)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="iterating-loops.html"><a href="iterating-loops.html#for-i-in-x-loops"><i class="fa fa-check"></i><b>8.1</b> For <em>i</em> in <em>x</em> Loops</a></li>
<li class="chapter" data-level="8.2" data-path="iterating-loops.html"><a href="iterating-loops.html#while-loops"><i class="fa fa-check"></i><b>8.2</b> <em>While</em> Loops</a></li>
<li class="chapter" data-level="8.3" data-path="iterating-loops.html"><a href="iterating-loops.html#repeat-loops"><i class="fa fa-check"></i><b>8.3</b> <em>Repeat</em> Loops</a></li>
<li class="chapter" data-level="8.4" data-path="iterating-loops.html"><a href="iterating-loops.html#break-and-next"><i class="fa fa-check"></i><b>8.4</b> <em>Break</em> and <em>Next</em></a></li>
<li class="chapter" data-level="8.5" data-path="iterating-loops.html"><a href="iterating-loops.html#iterating-data.frame-rows-in-r"><i class="fa fa-check"></i><b>8.5</b> Iterating Data.Frame Rows in R</a></li>
<li class="chapter" data-level="8.6" data-path="iterating-loops.html"><a href="iterating-loops.html#lapply"><i class="fa fa-check"></i><b>8.6</b> <em>lapply()</em></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="packages-and-functions.html"><a href="packages-and-functions.html"><i class="fa fa-check"></i><b>9</b> Packages and Functions</a>
<ul>
<li class="chapter" data-level="9.1" data-path="packages-and-functions.html"><a href="packages-and-functions.html#learning-objectives-1"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="packages-and-functions.html"><a href="packages-and-functions.html#what-is-a-function"><i class="fa fa-check"></i><b>9.2</b> What is a function?</a></li>
<li class="chapter" data-level="9.3" data-path="packages-and-functions.html"><a href="packages-and-functions.html#what-is-the-basic-syntax-of-a-function-in-r"><i class="fa fa-check"></i><b>9.3</b> What is the basic syntax of a function in R?</a></li>
<li class="chapter" data-level="9.4" data-path="packages-and-functions.html"><a href="packages-and-functions.html#step-1-building-a-function"><i class="fa fa-check"></i><b>9.4</b> Step 1: Building a function</a></li>
<li class="chapter" data-level="9.5" data-path="packages-and-functions.html"><a href="packages-and-functions.html#step-2-calling-the-function"><i class="fa fa-check"></i><b>9.5</b> Step 2: Calling the function</a></li>
<li class="chapter" data-level="9.6" data-path="packages-and-functions.html"><a href="packages-and-functions.html#a-function-can-have-more-than-one-argument"><i class="fa fa-check"></i><b>9.6</b> A function can have more than one argument</a></li>
<li class="chapter" data-level="9.7" data-path="packages-and-functions.html"><a href="packages-and-functions.html#using-a-package-and-function-to-graph-data-and-export-a-.png"><i class="fa fa-check"></i><b>9.7</b> Using a package and function to graph data and export a .png</a></li>
<li class="chapter" data-level="9.8" data-path="packages-and-functions.html"><a href="packages-and-functions.html#saving-functions-and-calling-them-from-another-file"><i class="fa fa-check"></i><b>9.8</b> Saving functions and calling them from another file</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="file-input-and-output.html"><a href="file-input-and-output.html"><i class="fa fa-check"></i><b>10</b> File Input and Output</a>
<ul>
<li class="chapter" data-level="10.1" data-path="file-input-and-output.html"><a href="file-input-and-output.html#objectives"><i class="fa fa-check"></i><b>10.1</b> Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="file-input-and-output.html"><a href="file-input-and-output.html#basic-idea"><i class="fa fa-check"></i><b>10.2</b> Basic Idea</a></li>
<li class="chapter" data-level="10.3" data-path="file-input-and-output.html"><a href="file-input-and-output.html#file-formats"><i class="fa fa-check"></i><b>10.3</b> File Formats</a></li>
<li class="chapter" data-level="10.4" data-path="file-input-and-output.html"><a href="file-input-and-output.html#filesystems-and-paths"><i class="fa fa-check"></i><b>10.4</b> Filesystems and Paths</a></li>
<li class="chapter" data-level="10.5" data-path="file-input-and-output.html"><a href="file-input-and-output.html#get-and-set-working-directory"><i class="fa fa-check"></i><b>10.5</b> get and set working directory</a></li>
<li class="chapter" data-level="10.6" data-path="file-input-and-output.html"><a href="file-input-and-output.html#saving-and-loading-r-data"><i class="fa fa-check"></i><b>10.6</b> saving and loading R data</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="file-input-and-output.html"><a href="file-input-and-output.html#rds"><i class="fa fa-check"></i><b>10.6.1</b> rds</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="file-input-and-output.html"><a href="file-input-and-output.html#reading-and-writing-text-data"><i class="fa fa-check"></i><b>10.7</b> Reading and Writing Text data</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="file-input-and-output.html"><a href="file-input-and-output.html#tabular-data"><i class="fa fa-check"></i><b>10.7.1</b> tabular data</a></li>
<li class="chapter" data-level="10.7.2" data-path="file-input-and-output.html"><a href="file-input-and-output.html#read-and-write-table"><i class="fa fa-check"></i><b>10.7.2</b> read and write table</a></li>
<li class="chapter" data-level="10.7.3" data-path="file-input-and-output.html"><a href="file-input-and-output.html#csv-format"><i class="fa fa-check"></i><b>10.7.3</b> CSV format</a></li>
<li class="chapter" data-level="10.7.4" data-path="file-input-and-output.html"><a href="file-input-and-output.html#non-tabular-data"><i class="fa fa-check"></i><b>10.7.4</b> Non-tabular data</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="file-input-and-output.html"><a href="file-input-and-output.html#urls-as-files"><i class="fa fa-check"></i><b>10.8</b> URLS as files</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html"><i class="fa fa-check"></i><b>11</b> Strings and Regular Expressions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#printing-output"><i class="fa fa-check"></i><b>11.1</b> Printing Output</a></li>
<li class="chapter" data-level="11.2" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#escape-sequences"><i class="fa fa-check"></i><b>11.2</b> Escape Sequences</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#raw-strings"><i class="fa fa-check"></i><b>11.2.1</b> Raw Strings</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#character-encodings"><i class="fa fa-check"></i><b>11.3</b> Character Encodings</a></li>
<li class="chapter" data-level="11.4" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#the-tidyverse"><i class="fa fa-check"></i><b>11.4</b> The Tidyverse</a></li>
<li class="chapter" data-level="11.5" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#the-stringr-package"><i class="fa fa-check"></i><b>11.5</b> The stringr Package</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#splitting-strings"><i class="fa fa-check"></i><b>11.5.1</b> Splitting Strings</a></li>
<li class="chapter" data-level="11.5.2" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#replacing-parts-of-strings"><i class="fa fa-check"></i><b>11.5.2</b> Replacing Parts of Strings</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#regular-expressions"><i class="fa fa-check"></i><b>11.6</b> Regular Expressions</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#the-wildcard"><i class="fa fa-check"></i><b>11.6.1</b> The Wildcard</a></li>
<li class="chapter" data-level="11.6.2" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#escape-sequences-1"><i class="fa fa-check"></i><b>11.6.2</b> Escape Sequences</a></li>
<li class="chapter" data-level="11.6.3" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#anchors"><i class="fa fa-check"></i><b>11.6.3</b> Anchors</a></li>
<li class="chapter" data-level="11.6.4" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#character-classes"><i class="fa fa-check"></i><b>11.6.4</b> Character Classes</a></li>
<li class="chapter" data-level="11.6.5" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#quantifiers"><i class="fa fa-check"></i><b>11.6.5</b> Quantifiers</a></li>
<li class="chapter" data-level="11.6.6" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#groups"><i class="fa fa-check"></i><b>11.6.6</b> Groups</a></li>
<li class="chapter" data-level="11.6.7" data-path="strings-and-regular-expressions.html"><a href="strings-and-regular-expressions.html#extracting-matches"><i class="fa fa-check"></i><b>11.6.7</b> Extracting Matches</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="data-structures.html"><a href="data-structures.html"><i class="fa fa-check"></i><b>12</b> Data Structures</a>
<ul>
<li class="chapter" data-level="12.1" data-path="data-structures.html"><a href="data-structures.html#tabular-data-1"><i class="fa fa-check"></i><b>12.1</b> Tabular Data</a></li>
<li class="chapter" data-level="12.2" data-path="data-structures.html"><a href="data-structures.html#tree-document-data-structures"><i class="fa fa-check"></i><b>12.2</b> Tree / Document Data Structures</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="data-structures.html"><a href="data-structures.html#structuring-data-as-xml"><i class="fa fa-check"></i><b>12.2.1</b> Structuring Data as XML</a></li>
<li class="chapter" data-level="12.2.2" data-path="data-structures.html"><a href="data-structures.html#structuring-data-as-json"><i class="fa fa-check"></i><b>12.2.2</b> Structuring Data as JSON</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="data-structures.html"><a href="data-structures.html#relational-databases"><i class="fa fa-check"></i><b>12.3</b> Relational Databases</a></li>
<li class="chapter" data-level="12.4" data-path="data-structures.html"><a href="data-structures.html#non-hierarchical-relational-data"><i class="fa fa-check"></i><b>12.4</b> Non-Hierarchical Relational Data</a></li>
<li class="chapter" data-level="12.5" data-path="data-structures.html"><a href="data-structures.html#geospatial-data"><i class="fa fa-check"></i><b>12.5</b> Geospatial Data</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="how-the-web-works.html"><a href="how-the-web-works.html"><i class="fa fa-check"></i><b>13</b> How the Web Works</a>
<ul>
<li class="chapter" data-level="13.1" data-path="how-the-web-works.html"><a href="how-the-web-works.html#client-server-architecture"><i class="fa fa-check"></i><b>13.1</b> Client-Server Architecture</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="how-the-web-works.html"><a href="how-the-web-works.html#communication-between-clients-and-servers"><i class="fa fa-check"></i><b>13.1.1</b> Communication Between Clients and Servers</a></li>
<li class="chapter" data-level="13.1.2" data-path="how-the-web-works.html"><a href="how-the-web-works.html#domain-name-resolution"><i class="fa fa-check"></i><b>13.1.2</b> Domain Name Resolution</a></li>
<li class="chapter" data-level="13.1.3" data-path="how-the-web-works.html"><a href="how-the-web-works.html#request-routing"><i class="fa fa-check"></i><b>13.1.3</b> Request Routing</a></li>
<li class="chapter" data-level="13.1.4" data-path="how-the-web-works.html"><a href="how-the-web-works.html#the-server-response"><i class="fa fa-check"></i><b>13.1.4</b> The Server Response</a></li>
<li class="chapter" data-level="13.1.5" data-path="how-the-web-works.html"><a href="how-the-web-works.html#internet-transfer-protocols"><i class="fa fa-check"></i><b>13.1.5</b> Internet Transfer Protocols</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="how-the-web-works.html"><a href="how-the-web-works.html#understanding-urls"><i class="fa fa-check"></i><b>13.2</b> Understanding URLs</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="how-the-web-works.html"><a href="how-the-web-works.html#dynamic-files"><i class="fa fa-check"></i><b>13.2.1</b> Dynamic Files</a></li>
<li class="chapter" data-level="13.2.2" data-path="how-the-web-works.html"><a href="how-the-web-works.html#query-strings"><i class="fa fa-check"></i><b>13.2.2</b> Query Strings</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="web-scraping.html"><a href="web-scraping.html"><i class="fa fa-check"></i><b>14</b> Web Scraping</a>
<ul>
<li class="chapter" data-level="14.1" data-path="web-scraping.html"><a href="web-scraping.html#getting-data-from-the-web"><i class="fa fa-check"></i><b>14.1</b> Getting Data from the Web</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="web-scraping.html"><a href="web-scraping.html#whats-in-a-web-page"><i class="fa fa-check"></i><b>14.1.1</b> What’s in a Web Page?</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="web-scraping.html"><a href="web-scraping.html#rs-xml-parsers"><i class="fa fa-check"></i><b>14.2</b> R’s XML Parsers</a></li>
<li class="chapter" data-level="14.3" data-path="web-scraping.html"><a href="web-scraping.html#xpath"><i class="fa fa-check"></i><b>14.3</b> XPath</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="web-scraping.html"><a href="web-scraping.html#predicates"><i class="fa fa-check"></i><b>14.3.1</b> Predicates</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="web-scraping.html"><a href="web-scraping.html#the-web-scraping-workflow"><i class="fa fa-check"></i><b>14.4</b> The Web Scraping Workflow</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="web-scraping.html"><a href="web-scraping.html#being-polite"><i class="fa fa-check"></i><b>14.4.1</b> Being Polite</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="web-scraping.html"><a href="web-scraping.html#case-study-ca-cities"><i class="fa fa-check"></i><b>14.5</b> Case Study: CA Cities</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="web-scraping.html"><a href="web-scraping.html#data-cleaning"><i class="fa fa-check"></i><b>14.5.1</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="web-scraping.html"><a href="web-scraping.html#case-study-the-ca-aggie"><i class="fa fa-check"></i><b>14.6</b> Case Study: The CA Aggie</a></li>
<li class="chapter" data-level="14.7" data-path="web-scraping.html"><a href="web-scraping.html#css-selectors"><i class="fa fa-check"></i><b>14.7</b> CSS Selectors</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="optical-character-recognition.html"><a href="optical-character-recognition.html"><i class="fa fa-check"></i><b>15</b> Optical Character Recognition</a>
<ul>
<li class="chapter" data-level="15.1" data-path="optical-character-recognition.html"><a href="optical-character-recognition.html#loading-page-images"><i class="fa fa-check"></i><b>15.1</b> Loading Page Images</a></li>
<li class="chapter" data-level="15.2" data-path="optical-character-recognition.html"><a href="optical-character-recognition.html#running-ocr"><i class="fa fa-check"></i><b>15.2</b> Running OCR</a></li>
<li class="chapter" data-level="15.3" data-path="optical-character-recognition.html"><a href="optical-character-recognition.html#accuracy"><i class="fa fa-check"></i><b>15.3</b> Accuracy</a></li>
<li class="chapter" data-level="15.4" data-path="optical-character-recognition.html"><a href="optical-character-recognition.html#unreadable-text"><i class="fa fa-check"></i><b>15.4</b> Unreadable Text</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>16</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="16.1" data-path="data-visualization.html"><a href="data-visualization.html#factors"><i class="fa fa-check"></i><b>16.1</b> Factors</a></li>
<li class="chapter" data-level="16.2" data-path="data-visualization.html"><a href="data-visualization.html#r-graphics-overview"><i class="fa fa-check"></i><b>16.2</b> R Graphics Overview</a></li>
<li class="chapter" data-level="16.3" data-path="data-visualization.html"><a href="data-visualization.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>16.3</b> The Grammar of Graphics</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="data-visualization.html"><a href="data-visualization.html#making-a-plot"><i class="fa fa-check"></i><b>16.3.1</b> Making a Plot</a></li>
<li class="chapter" data-level="16.3.2" data-path="data-visualization.html"><a href="data-visualization.html#saving-plots"><i class="fa fa-check"></i><b>16.3.2</b> Saving Plots</a></li>
<li class="chapter" data-level="16.3.3" data-path="data-visualization.html"><a href="data-visualization.html#example-bar-plot"><i class="fa fa-check"></i><b>16.3.3</b> Example: Bar Plot</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="data-visualization.html"><a href="data-visualization.html#designing-a-visualization"><i class="fa fa-check"></i><b>16.4</b> Designing a Visualization</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="network-analysis.html"><a href="network-analysis.html"><i class="fa fa-check"></i><b>17</b> Network Analysis</a>
<ul>
<li class="chapter" data-level="17.1" data-path="network-analysis.html"><a href="network-analysis.html#overview-1"><i class="fa fa-check"></i><b>17.1</b> Overview</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="network-analysis.html"><a href="network-analysis.html#while-you-wait"><i class="fa fa-check"></i><b>17.1.1</b> While you wait</a></li>
<li class="chapter" data-level="17.1.2" data-path="network-analysis.html"><a href="network-analysis.html#learning-objectives-2"><i class="fa fa-check"></i><b>17.1.2</b> Learning Objectives</a></li>
<li class="chapter" data-level="17.1.3" data-path="network-analysis.html"><a href="network-analysis.html#roadmap"><i class="fa fa-check"></i><b>17.1.3</b> Roadmap</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="network-analysis.html"><a href="network-analysis.html#what-is-network-analysis"><i class="fa fa-check"></i><b>17.2</b> What is Network Analysis</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="network-analysis.html"><a href="network-analysis.html#networks-in-research---social-sciences"><i class="fa fa-check"></i><b>17.2.1</b> Networks in research - Social Sciences</a></li>
<li class="chapter" data-level="17.2.2" data-path="network-analysis.html"><a href="network-analysis.html#networks-in-research---neuroscience"><i class="fa fa-check"></i><b>17.2.2</b> Networks in research - Neuroscience</a></li>
<li class="chapter" data-level="17.2.3" data-path="network-analysis.html"><a href="network-analysis.html#networks-in-research---chemistry"><i class="fa fa-check"></i><b>17.2.3</b> Networks in research - Chemistry</a></li>
<li class="chapter" data-level="17.2.4" data-path="network-analysis.html"><a href="network-analysis.html#networks-in-research---the-internet"><i class="fa fa-check"></i><b>17.2.4</b> Networks in research - The Internet</a></li>
<li class="chapter" data-level="17.2.5" data-path="network-analysis.html"><a href="network-analysis.html#networks-in-research---infrastructure"><i class="fa fa-check"></i><b>17.2.5</b> Networks in research - Infrastructure</a></li>
<li class="chapter" data-level="17.2.6" data-path="network-analysis.html"><a href="network-analysis.html#networks-in-research---security"><i class="fa fa-check"></i><b>17.2.6</b> Networks in research - Security</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="network-analysis.html"><a href="network-analysis.html#network-data"><i class="fa fa-check"></i><b>17.3</b> Network Data</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="network-analysis.html"><a href="network-analysis.html#edgelist"><i class="fa fa-check"></i><b>17.3.1</b> Edgelist</a></li>
<li class="chapter" data-level="17.3.2" data-path="network-analysis.html"><a href="network-analysis.html#adjacency-matrix"><i class="fa fa-check"></i><b>17.3.2</b> Adjacency Matrix</a></li>
<li class="chapter" data-level="17.3.3" data-path="network-analysis.html"><a href="network-analysis.html#edge-weights"><i class="fa fa-check"></i><b>17.3.3</b> Edge Weights</a></li>
<li class="chapter" data-level="17.3.4" data-path="network-analysis.html"><a href="network-analysis.html#attributes"><i class="fa fa-check"></i><b>17.3.4</b> Attributes</a></li>
<li class="chapter" data-level="17.3.5" data-path="network-analysis.html"><a href="network-analysis.html#create-an-example-network"><i class="fa fa-check"></i><b>17.3.5</b> Create an Example Network</a></li>
<li class="chapter" data-level="17.3.6" data-path="network-analysis.html"><a href="network-analysis.html#components"><i class="fa fa-check"></i><b>17.3.6</b> Components</a></li>
<li class="chapter" data-level="17.3.7" data-path="network-analysis.html"><a href="network-analysis.html#limitations-of-network-data"><i class="fa fa-check"></i><b>17.3.7</b> Limitations of Network Data</a></li>
<li class="chapter" data-level="17.3.8" data-path="network-analysis.html"><a href="network-analysis.html#projected-networks"><i class="fa fa-check"></i><b>17.3.8</b> Projected Networks</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="network-analysis.html"><a href="network-analysis.html#graph-level-properties"><i class="fa fa-check"></i><b>17.4</b> Graph Level Properties</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="network-analysis.html"><a href="network-analysis.html#directed-or-un-directed"><i class="fa fa-check"></i><b>17.4.1</b> Directed or Un-directed</a></li>
<li class="chapter" data-level="17.4.2" data-path="network-analysis.html"><a href="network-analysis.html#density"><i class="fa fa-check"></i><b>17.4.2</b> Density</a></li>
<li class="chapter" data-level="17.4.3" data-path="network-analysis.html"><a href="network-analysis.html#centralization"><i class="fa fa-check"></i><b>17.4.3</b> Centralization</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="network-analysis.html"><a href="network-analysis.html#node-level-properties"><i class="fa fa-check"></i><b>17.5</b> Node Level Properties</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="network-analysis.html"><a href="network-analysis.html#degree"><i class="fa fa-check"></i><b>17.5.1</b> Degree</a></li>
<li class="chapter" data-level="17.5.2" data-path="network-analysis.html"><a href="network-analysis.html#geodesic-distance"><i class="fa fa-check"></i><b>17.5.2</b> Geodesic Distance</a></li>
<li class="chapter" data-level="17.5.3" data-path="network-analysis.html"><a href="network-analysis.html#centrality"><i class="fa fa-check"></i><b>17.5.3</b> Centrality</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="network-analysis.html"><a href="network-analysis.html#network-workflow"><i class="fa fa-check"></i><b>17.6</b> Network Workflow</a></li>
<li class="chapter" data-level="17.7" data-path="network-analysis.html"><a href="network-analysis.html#network-tools"><i class="fa fa-check"></i><b>17.7</b> Network Tools</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="network-analysis.html"><a href="network-analysis.html#network-models"><i class="fa fa-check"></i><b>17.7.1</b> Network Models</a></li>
<li class="chapter" data-level="17.7.2" data-path="network-analysis.html"><a href="network-analysis.html#network-visualization"><i class="fa fa-check"></i><b>17.7.2</b> Network Visualization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>18</b> Statistics</a>
<ul>
<li class="chapter" data-level="18.1" data-path="statistics.html"><a href="statistics.html#introduction"><i class="fa fa-check"></i><b>18.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="statistics.html"><a href="statistics.html#mice_pot-dataset"><i class="fa fa-check"></i><b>18.1.1</b> <code>mice_pot</code> dataset</a></li>
<li class="chapter" data-level="18.1.2" data-path="statistics.html"><a href="statistics.html#barnacles-dataset"><i class="fa fa-check"></i><b>18.1.2</b> <code>barnacles</code> dataset</a></li>
<li class="chapter" data-level="18.1.3" data-path="statistics.html"><a href="statistics.html#sample-and-population"><i class="fa fa-check"></i><b>18.1.3</b> Sample and population</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="statistics.html"><a href="statistics.html#uses-of-simulation"><i class="fa fa-check"></i><b>18.2</b> Uses of simulation</a></li>
<li class="chapter" data-level="18.3" data-path="statistics.html"><a href="statistics.html#mathematical-statistics"><i class="fa fa-check"></i><b>18.3</b> Mathematical statistics</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="statistics.html"><a href="statistics.html#law-of-large-numbers"><i class="fa fa-check"></i><b>18.3.1</b> Law of large numbers</a></li>
<li class="chapter" data-level="18.3.2" data-path="statistics.html"><a href="statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>18.3.2</b> Central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="statistics.html"><a href="statistics.html#statistical-inference"><i class="fa fa-check"></i><b>18.4</b> Statistical inference</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="statistics.html"><a href="statistics.html#confidence-intervals"><i class="fa fa-check"></i><b>18.4.1</b> Confidence intervals</a></li>
<li class="chapter" data-level="18.4.2" data-path="statistics.html"><a href="statistics.html#two-population-test"><i class="fa fa-check"></i><b>18.4.2</b> Two-population test</a></li>
<li class="chapter" data-level="18.4.3" data-path="statistics.html"><a href="statistics.html#hypothesis-tests-for-non-normal-data"><i class="fa fa-check"></i><b>18.4.3</b> Hypothesis tests for non-normal data</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="statistics.html"><a href="statistics.html#regression"><i class="fa fa-check"></i><b>18.5</b> Regression</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="statistics.html"><a href="statistics.html#fitting-a-regression-line"><i class="fa fa-check"></i><b>18.5.1</b> Fitting a regression line</a></li>
<li class="chapter" data-level="18.5.2" data-path="statistics.html"><a href="statistics.html#assumptions-and-diagnostics"><i class="fa fa-check"></i><b>18.5.2</b> Assumptions and diagnostics</a></li>
<li class="chapter" data-level="18.5.3" data-path="statistics.html"><a href="statistics.html#functions-for-inspecting-regression-fits"><i class="fa fa-check"></i><b>18.5.3</b> Functions for inspecting regression fits</a></li>
<li class="chapter" data-level="18.5.4" data-path="statistics.html"><a href="statistics.html#a-model-that-fails-diagnostics"><i class="fa fa-check"></i><b>18.5.4</b> A model that fails diagnostics</a></li>
<li class="chapter" data-level="18.5.5" data-path="statistics.html"><a href="statistics.html#predictions-and-variability"><i class="fa fa-check"></i><b>18.5.5</b> Predictions and variability</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="statistics.html"><a href="statistics.html#model-selection"><i class="fa fa-check"></i><b>18.6</b> Model selection</a></li>
<li class="chapter" data-level="18.7" data-path="statistics.html"><a href="statistics.html#cross-validation"><i class="fa fa-check"></i><b>18.7</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html"><i class="fa fa-check"></i><b>19</b> Data Forensics and Cleaning: Structured Data</a>
<ul>
<li class="chapter" data-level="19.1" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#introduction-1"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#tidy-data"><i class="fa fa-check"></i><b>19.2</b> Tidy Data</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#columns-into-rows"><i class="fa fa-check"></i><b>19.2.1</b> Columns into Rows</a></li>
<li class="chapter" data-level="19.2.2" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#rows-into-columns"><i class="fa fa-check"></i><b>19.2.2</b> Rows into Columns</a></li>
<li class="chapter" data-level="19.2.3" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#separating-values"><i class="fa fa-check"></i><b>19.2.3</b> Separating Values</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#data-types"><i class="fa fa-check"></i><b>19.3</b> Data Types</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#dates"><i class="fa fa-check"></i><b>19.3.1</b> Dates</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#special-values"><i class="fa fa-check"></i><b>19.4</b> Special Values</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#reasoning-about-missing-values"><i class="fa fa-check"></i><b>19.4.1</b> Reasoning about Missing Values</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="data-forensics-and-cleaning-structured-data.html"><a href="data-forensics-and-cleaning-structured-data.html#outliers"><i class="fa fa-check"></i><b>19.5</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html"><i class="fa fa-check"></i><b>20</b> Data Forensics and Cleaning: Unstructured Data</a>
<ul>
<li class="chapter" data-level="20.1" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#preliminaries"><i class="fa fa-check"></i><b>20.1</b> Preliminaries</a></li>
<li class="chapter" data-level="20.2" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#from-file-names-to-metadata"><i class="fa fa-check"></i><b>20.2</b> From File Names to Metadata</a></li>
<li class="chapter" data-level="20.3" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#loading-a-corpus"><i class="fa fa-check"></i><b>20.3</b> Loading a Corpus</a></li>
<li class="chapter" data-level="20.4" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#preprocessing"><i class="fa fa-check"></i><b>20.4</b> Preprocessing</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#tokenizing-and-bags-of-words"><i class="fa fa-check"></i><b>20.4.1</b> Tokenizing and Bags of Words</a></li>
<li class="chapter" data-level="20.4.2" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#text-normalization"><i class="fa fa-check"></i><b>20.4.2</b> Text Normalization</a></li>
<li class="chapter" data-level="20.4.3" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#stop-words"><i class="fa fa-check"></i><b>20.4.3</b> Stop Words</a></li>
<li class="chapter" data-level="20.4.4" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#tokenizers"><i class="fa fa-check"></i><b>20.4.4</b> Tokenizers</a></li>
<li class="chapter" data-level="20.4.5" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#document-chunking-and-n-grams"><i class="fa fa-check"></i><b>20.4.5</b> Document Chunking and N-grams</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#counting-terms"><i class="fa fa-check"></i><b>20.5</b> Counting Terms</a>
<ul>
<li class="chapter" data-level="20.5.1" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#term-frequency"><i class="fa fa-check"></i><b>20.5.1</b> Term Frequency</a></li>
<li class="chapter" data-level="20.5.2" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#plotting-term-frequency"><i class="fa fa-check"></i><b>20.5.2</b> Plotting Term Frequency</a></li>
<li class="chapter" data-level="20.5.3" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#comparing-term-frequencies-across-documents"><i class="fa fa-check"></i><b>20.5.3</b> Comparing Term Frequencies Across Documents</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#text-mining-pipepline"><i class="fa fa-check"></i><b>20.6</b> Text Mining Pipepline</a></li>
<li class="chapter" data-level="20.7" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#document-term-matrix"><i class="fa fa-check"></i><b>20.7</b> Document Term Matrix</a></li>
<li class="chapter" data-level="20.8" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#corpus-analytics"><i class="fa fa-check"></i><b>20.8</b> Corpus Analytics</a>
<ul>
<li class="chapter" data-level="20.8.1" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#corpus-term-counts"><i class="fa fa-check"></i><b>20.8.1</b> Corpus Term Counts</a></li>
<li class="chapter" data-level="20.8.2" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#tfidf-scores"><i class="fa fa-check"></i><b>20.8.2</b> tf–idf Scores</a></li>
<li class="chapter" data-level="20.8.3" data-path="data-forensics-and-cleaning-unstructured-data.html"><a href="data-forensics-and-cleaning-unstructured-data.html#unique-terms-in-a-document"><i class="fa fa-check"></i><b>20.8.3</b> Unique Terms in a Document</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html"><i class="fa fa-check"></i><b>21</b> Data Forensics and Cleaning: Geospatial Data</a>
<ul>
<li class="chapter" data-level="21.1" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#learning-objectives-3"><i class="fa fa-check"></i><b>21.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="21.2" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#what-is-geospatial-data"><i class="fa fa-check"></i><b>21.2</b> What is Geospatial Data?</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#attributes-1"><i class="fa fa-check"></i><b>21.2.1</b> Attributes</a></li>
<li class="chapter" data-level="21.2.2" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#coordinate-reference-system"><i class="fa fa-check"></i><b>21.2.2</b> Coordinate Reference System</a></li>
<li class="chapter" data-level="21.2.3" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#coordinates"><i class="fa fa-check"></i><b>21.2.3</b> Coordinates</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#geospatial-data-models"><i class="fa fa-check"></i><b>21.3</b> Geospatial Data Models</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#vector-data"><i class="fa fa-check"></i><b>21.3.1</b> Vector Data</a></li>
<li class="chapter" data-level="21.3.2" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#raster-data"><i class="fa fa-check"></i><b>21.3.2</b> Raster Data</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#data-structures-applied-to-geospatial-data"><i class="fa fa-check"></i><b>21.4</b> Data Structures Applied to Geospatial Data</a></li>
<li class="chapter" data-level="21.5" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#cleaning-geospatial-data"><i class="fa fa-check"></i><b>21.5</b> Cleaning Geospatial Data</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#example-data"><i class="fa fa-check"></i><b>21.5.1</b> Example Data</a></li>
<li class="chapter" data-level="21.5.2" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#making-location-data-usable"><i class="fa fa-check"></i><b>21.5.2</b> Making Location Data Usable</a></li>
<li class="chapter" data-level="21.5.3" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#cleaning-location-data"><i class="fa fa-check"></i><b>21.5.3</b> Cleaning Location Data</a></li>
<li class="chapter" data-level="21.5.4" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#cleaning-attribute-data"><i class="fa fa-check"></i><b>21.5.4</b> Cleaning Attribute Data</a></li>
<li class="chapter" data-level="21.5.5" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#checking-coordinate-reference-systems"><i class="fa fa-check"></i><b>21.5.5</b> Checking Coordinate Reference Systems</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#conclusions"><i class="fa fa-check"></i><b>21.6</b> Conclusions</a></li>
<li class="chapter" data-level="21.7" data-path="data-forensics-and-cleaning-geospatial-data.html"><a href="data-forensics-and-cleaning-geospatial-data.html#optional-further-reading"><i class="fa fa-check"></i><b>21.7</b> Optional Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>22</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Adventures in Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-forensics-and-cleaning-unstructured-data" class="section level1" number="20">
<h1><span class="header-section-number">20</span> Data Forensics and Cleaning: Unstructured Data</h1>
<div id="preliminaries" class="section level2" number="20.1">
<h2><span class="header-section-number">20.1</span> Preliminaries</h2>
<p><strong>Lesson Objectives</strong></p>
<p>By the end of this lesson, you should:</p>
<ul>
<li>Be able to identify patterns in unstructured data</li>
<li>Create metadata about a collection of documents</li>
<li>Load and clean a collection of text files into R, which entails:
<ul>
<li>Tokenizing words</li>
<li>Determining and applying stop words</li>
<li><del>Normalizing, lemmatizing, and stemming texts</del></li>
<li><del>Creating a document-term matrix</del></li>
<li><del>Getting high-level data about text documents (term frequencies, tf–idf scores)</del></li>
</ul></li>
<li>Understand how preprocessing steps impact analysis</li>
</ul>
<p><strong>Packages</strong></p>
<pre><code>install.packages(c(&quot;tidyverse&quot;, &quot;tokenizers&quot;, &quot;tm&quot;, &quot;cluster&quot;))</code></pre>
</div>
<div id="from-file-names-to-metadata" class="section level2" number="20.2">
<h2><span class="header-section-number">20.2</span> From File Names to Metadata</h2>
<p>First, let’s get some information about a collection of files.</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb499-1" aria-hidden="true" tabindex="-1"></a>input_dir <span class="ot">&lt;-</span> <span class="st">&quot;./IST8_text_corpus/&quot;</span></span>
<span id="cb499-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb499-2" aria-hidden="true" tabindex="-1"></a>fnames <span class="ot">&lt;-</span> <span class="fu">list.files</span>(input_dir)</span></code></pre></div>
<p>While we could start analyzing these files immediately, their names contain a
lot of metadata, which could be helpful. We’ll need to structure this info
first (yes, we’re structuring unstructured data so we can structure <em>more</em>
unstructured data—welcome to data forensics!). Mercifully, whoever created
these files had a convention in mind for giving them names. We can latch onto
the patterns within this convention to make our own representation of the
files’ metadata.</p>
<p>Here’s the pattern:</p>
<p><code>[LANGUAGE]_[YEAR]_[LASTNAME,FIRSTNAME]_[N OR G].txt</code></p>
<p>Let’s use it to make a data frame. Using <code>stringr</code> in combination with regex
patterns will be essential to do so. First, let’s break apart the strings on
their underscores and transform that output into a data frame.</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb500-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb500-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb500-2" aria-hidden="true" tabindex="-1"></a>C19_novels <span class="ot">&lt;-</span> <span class="fu">str_split_fixed</span>(fnames, <span class="st">&quot;_&quot;</span>, <span class="dv">5</span>)</span>
<span id="cb500-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb500-3" aria-hidden="true" tabindex="-1"></a>C19_novels <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(C19_novels)</span></code></pre></div>
<p>This is already pretty close to a good data sheet for us, but we’ll want to
refine it a little further. First, let’s name our columns. The letters in the
file names are genre tags, which stand for either “gothic” or “not gothic,” so
we’ll be sure to record them.</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb501-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(C19_novels) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;lang&quot;</span>, <span class="st">&quot;year&quot;</span>, <span class="st">&quot;author_name&quot;</span>, <span class="st">&quot;title&quot;</span>, <span class="st">&quot;genre&quot;</span>)</span></code></pre></div>
<p>Now, let’s split author names into “first” and “last” and add them back to the
data frame.</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb502-1" aria-hidden="true" tabindex="-1"></a>author_names <span class="ot">&lt;-</span> <span class="fu">str_split_fixed</span>(C19_novels<span class="sc">$</span>author_name, <span class="st">&quot;,&quot;</span>, <span class="dv">2</span>)</span>
<span id="cb502-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb502-2" aria-hidden="true" tabindex="-1"></a>C19_novels<span class="sc">$</span>last_name <span class="ot">&lt;-</span> author_names[, <span class="dv">1</span>]</span>
<span id="cb502-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb502-3" aria-hidden="true" tabindex="-1"></a>C19_novels<span class="sc">$</span>first_name <span class="ot">&lt;-</span> author_names[, <span class="dv">2</span>]</span></code></pre></div>
<p>And for good measure, let’s remove the <code>.txt</code> extension in the genre tags and
convert those tags to factors.</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb503-1" aria-hidden="true" tabindex="-1"></a>C19_novels<span class="sc">$</span>genre <span class="ot">&lt;-</span> <span class="fu">sapply</span>(C19_novels<span class="sc">$</span>genre, <span class="cf">function</span>(x) <span class="fu">str_remove_all</span>(x, <span class="st">&quot;.txt&quot;</span>))</span>
<span id="cb503-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb503-2" aria-hidden="true" tabindex="-1"></a>C19_novels<span class="sc">$</span>genre <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(C19_novels<span class="sc">$</span>genre)</span></code></pre></div>
<p>Finally, we’ll clean up, removing the <code>author_names</code> and <code>lang</code> columns and
doing a bit of reordering. (Language could be useful in some instances, but
we don’t need it for now, especially because these novels are all in English.)</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb504-1" aria-hidden="true" tabindex="-1"></a>C19_novels <span class="ot">&lt;-</span> <span class="fu">subset</span>(C19_novels, <span class="at">select=</span> <span class="sc">-</span><span class="fu">c</span>(lang, author_name))</span>
<span id="cb504-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb504-2" aria-hidden="true" tabindex="-1"></a>C19_novels <span class="ot">&lt;-</span> C19_novels[, <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">3</span>)]</span>
<span id="cb504-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb504-3" aria-hidden="true" tabindex="-1"></a>C19_novels</span></code></pre></div>
<pre><code>##    last_name  first_name                         title year genre
## 1   Beckford     William                        Vathek 1786     G
## 2  Radcliffe         Ann              ASicilianRomance 1790     G
## 3  Radcliffe         Ann         TheMysteriesofUdolpho 1794     G
## 4      Lewis     Matthew                       TheMonk 1795     G
## 5     Austen        Jane           SenseandSensibility 1811     N
## 6    Shelley        Mary                  Frankenstein 1818     G
## 7      Scott      Walter                       Ivanhoe 1820     N
## 8        Poe  EdgarAllen TheNarrativeofArthurGordonPym 1838     N
## 9     Bronte       Emily              WutheringHeights 1847     G
## 10 Hawthorne   Nathaniel      TheHouseoftheSevenGables 1851     N
## 11   Gaskell   Elizabeth                 NorthandSouth 1854     N
## 12   Collins      Wilkie               TheWomaninWhite 1860     N
## 13   Dickens     Charles             GreatExpectations 1861     N
## 14     James       Henry               PortraitofaLady 1881     N
## 15 Stevenson RobertLouis                TreasureIsland 1882     N
## 16 Stevenson RobertLouis                 JekyllandHyde 1886     G
## 17     Wilde       Oscar        ThePictureofDorianGray 1890     G
## 18    Stoker        Bram                       Dracula 1897     G</code></pre>
<p>Nice and tidy!</p>
</div>
<div id="loading-a-corpus" class="section level2" number="20.3">
<h2><span class="header-section-number">20.3</span> Loading a Corpus</h2>
<p>With our metadata structured, it’s time to load our files.</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb506-1" aria-hidden="true" tabindex="-1"></a>files <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">paste0</span>(input_dir, fnames), readLines)</span></code></pre></div>
<p>Loading our files like this will create a giant list of vectors, where each
vector is a full text file. Those vectors are chunked by paragraph right now,
but for our purposes it would be easier if each vector was a single stream of
text (like the output of <code>ocr()</code>, if you’ll remember). We can collapse them
together with <code>paste()</code>.</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb507-1" aria-hidden="true" tabindex="-1"></a>files <span class="ot">&lt;-</span> <span class="fu">lapply</span>(files, <span class="cf">function</span>(x) <span class="fu">paste</span>(x, <span class="at">collapse=</span><span class="st">&quot; &quot;</span>))</span></code></pre></div>
<p>From here, we can wrap these files in a special “corpus” object, which the <code>tm</code>
package enables (a corpus is a large collection of texts). A <code>tm</code> corpus works
somewhat like a database. It has a section for “content,” which contains text
data, as well as various metadata sections, which we can populate with
additional information about our texts, if we wished. Taken together, these
features make it easy to streamline workflows with text data.</p>
<p>To make a corpus with <code>tm</code>, we call the <code>Corpus()</code> function, specifying with
<code>VectorSource()</code> (because our texts are vectors):</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb508-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb508-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tm)</span>
<span id="cb508-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb508-2" aria-hidden="true" tabindex="-1"></a>corpus <span class="ot">&lt;-</span> <span class="fu">Corpus</span>(<span class="fu">VectorSource</span>(files))</span></code></pre></div>
<p>Here’s a high-level glimpse at what’s in this object:</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb509-1" aria-hidden="true" tabindex="-1"></a>corpus</span></code></pre></div>
<pre><code>## &lt;&lt;SimpleCorpus&gt;&gt;
## Metadata:  corpus specific: 1, document level (indexed): 0
## Content:  documents: 18</code></pre>
<p>Zooming in to metadata about a text in the corpus:</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb511-1" aria-hidden="true" tabindex="-1"></a>corpus[[<span class="dv">6</span>]]</span></code></pre></div>
<pre><code>## &lt;&lt;PlainTextDocument&gt;&gt;
## Metadata:  7
## Content:  chars: 424017</code></pre>
<p>Not much here so far, but we’ll add more later.</p>
<p>Finally, we can get content from a text:</p>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb513-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str_sub</span>(corpus[[<span class="dv">6</span>]]<span class="sc">$</span>content, <span class="dv">1</span>, <span class="dv">500</span>)</span></code></pre></div>
<pre><code>## [1] &quot;FRANKENSTEIN:  OR,  THE MODERN PROMETHEUS.  BY MARY W. SHELLEY.  PREFACE.  The event on which this fiction is founded, has been supposed, by Dr. Darwin, and some of the physiological writers of Germany, as not of impossible occurrence. I shall not be supposed as according the remotest degree of serious faith to such an imagination; yet, in assuming it as the basis of a work of fancy, I have not considered myself as merely weaving a series of supernatural terrors. The event on which the interest &quot;</code></pre>
<p>In this last view, you can see that the text file is still formatted (at least
we didn’t have to OCR it!). This formatting is unwieldy and worse, it makes it so
we can’t really access the elements that comprise each novel. We’ll need to do
more work to <strong>preprocess</strong> our texts before we can analyze them.</p>
</div>
<div id="preprocessing" class="section level2" number="20.4">
<h2><span class="header-section-number">20.4</span> Preprocessing</h2>
<p>Part of preprocessing entails making decisions about the kinds of information we
want to know about our data. Knowing what information we want often guides the
way we structure data. Put another way: <em>research questions drive preprocessing</em>.</p>
<div id="tokenizing-and-bags-of-words" class="section level3" number="20.4.1">
<h3><span class="header-section-number">20.4.1</span> Tokenizing and Bags of Words</h3>
<p>For example, it’d be helpful to know how many words are in each novel, which
might enable us to study patterns and differences between authors’ styles. To
get word counts, we need to split the text vectors into individual words. One
way to do this would be to first strip out everything in each novel that isn’t
an alphabetic character or a space. Let’s grab one text to experiment with.</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb515-1" aria-hidden="true" tabindex="-1"></a>frankenstein <span class="ot">&lt;-</span> corpus[[<span class="dv">6</span>]]<span class="sc">$</span>content</span>
<span id="cb515-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb515-2" aria-hidden="true" tabindex="-1"></a>frankenstein <span class="ot">&lt;-</span> <span class="fu">str_replace_all</span>(frankenstein, <span class="st">&quot;[^A-Za-z]&quot;</span>, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<p>From here, it would be easy enough to count the words in a novel by splitting
its vector on spaces, removing empty elements in the vector, and calling
<code>length()</code> on the vector. The end result is what we call a <strong>bag of words</strong>.</p>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb516-1" aria-hidden="true" tabindex="-1"></a>frankenstein <span class="ot">&lt;-</span> <span class="fu">str_split</span>(frankenstein, <span class="st">&quot; &quot;</span>)</span>
<span id="cb516-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb516-2" aria-hidden="true" tabindex="-1"></a>frankenstein <span class="ot">&lt;-</span> <span class="fu">lapply</span>(frankenstein, <span class="cf">function</span>(x) x[x <span class="sc">!=</span> <span class="st">&quot;&quot;</span>])</span>
<span id="cb516-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb516-3" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(frankenstein[[<span class="dv">1</span>]])</span></code></pre></div>
<pre><code>## [1] 76015</code></pre>
<p>And here are the first nine words (or “tokens”):</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb518-1" aria-hidden="true" tabindex="-1"></a>frankenstein[[<span class="dv">1</span>]][<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>]</span></code></pre></div>
<pre><code>## [1] &quot;FRANKENSTEIN&quot; &quot;OR&quot;           &quot;THE&quot;          &quot;MODERN&quot;       &quot;PROMETHEUS&quot;  
## [6] &quot;BY&quot;           &quot;MARY&quot;         &quot;W&quot;            &quot;SHELLEY&quot;</code></pre>
</div>
<div id="text-normalization" class="section level3" number="20.4.2">
<h3><span class="header-section-number">20.4.2</span> Text Normalization</h3>
<p>While easy, producing our bag of words this way is a bit clunky. And further,
this process can’t handle contractions (“I’m,” “don’t,” “that’s”) or
differences in capitalization.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb520-1" aria-hidden="true" tabindex="-1"></a>frankenstein[[<span class="dv">1</span>]][<span class="dv">188</span><span class="sc">:</span><span class="dv">191</span>]</span></code></pre></div>
<pre><code>## [1] &quot;Midsummer&quot; &quot;Night&quot;     &quot;s&quot;         &quot;Dream&quot;</code></pre>
<p>Should be:</p>
<pre><code>Midsummer Night&#39;s Dream</code></pre>
<p>And</p>
<pre><code>&quot;FRANKENSTEIN&quot;, &quot;Frankenstein&quot;</code></pre>
<p>Should be:</p>
<pre><code>&quot;Frankenstein&quot;</code></pre>
<p>Or, even better:</p>
<pre><code>frankenstein</code></pre>
<p>Typically, when we work with text data we want all of our words to be in the
same case because this makes it easier to do things like counting operations.
Remember that, to a computer, “Word” and “word” are two separate words, and if
we want to count them together, we need to pick one version or the other. Making
all words lowercase (even proper nouns) is the standard. Doing this is part of
what’s called text <strong>normalization</strong>. (Other forms of normalization might
entail handling orthographic differences between British and American English,
like “color” and “colour.”)</p>
<p>As for contractions, we have some decisions to make. On the one hand, it’s
important to retain as much information as we can about the original text, so
keeping “don’t” or “what’s” (which would be “don t” and “what s” in our current
method) is important. One way corpus linguists handle these words is to
<strong>lemmatize</strong> them. Lemmatizing involves removing inflectional endings to return
words to their base form:</p>
<ul>
<li>car, cars, car’s, cars’ =&gt; car</li>
<li>don’t =&gt; do</li>
</ul>
<p>This is a helpful step if what we’re primarily interested in is doing a high-
level analysis of semantics. On the other hand, though, many words that feature
contractions are high-frequency function words, which don’t have much meaning
beyond the immediate context of a sentence or two. Words like “that’s” or
“won’t” appear in huge numbers in text data, but they don’t carry much
information in and of themselves—it may in fact be the case that we could get
rid of them entirely…</p>
</div>
<div id="stop-words" class="section level3" number="20.4.3">
<h3><span class="header-section-number">20.4.3</span> Stop Words</h3>
<p>…and indeed this is the case! When structuring text data to study it at scale,
it’s common to remove, or <strong>stop out</strong>, words that don’t have much meaning. This
makes it much easier to identify significant (i.e. unique) features in a text,
without having to swim through all the noise of “the” or “that,” which would
almost always show up as the highest-occurring words in an analysis. But what
words should we remove? Ultimately, this depends on your text data. We can
usually assume that function words will be on our list of <strong>stop words</strong>, but it
may be that you’ll have to add or subtract others depending on your data and,
of course, your research question.</p>
<p>The <code>tm</code> package has a good starting list. Let’s look at the first 100 words.</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb526-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">stopwords</span>(<span class="st">&quot;SMART&quot;</span>), <span class="dv">100</span>)</span></code></pre></div>
<pre><code>##   [1] &quot;a&quot;            &quot;a&#39;s&quot;          &quot;able&quot;         &quot;about&quot;        &quot;above&quot;       
##   [6] &quot;according&quot;    &quot;accordingly&quot;  &quot;across&quot;       &quot;actually&quot;     &quot;after&quot;       
##  [11] &quot;afterwards&quot;   &quot;again&quot;        &quot;against&quot;      &quot;ain&#39;t&quot;        &quot;all&quot;         
##  [16] &quot;allow&quot;        &quot;allows&quot;       &quot;almost&quot;       &quot;alone&quot;        &quot;along&quot;       
##  [21] &quot;already&quot;      &quot;also&quot;         &quot;although&quot;     &quot;always&quot;       &quot;am&quot;          
##  [26] &quot;among&quot;        &quot;amongst&quot;      &quot;an&quot;           &quot;and&quot;          &quot;another&quot;     
##  [31] &quot;any&quot;          &quot;anybody&quot;      &quot;anyhow&quot;       &quot;anyone&quot;       &quot;anything&quot;    
##  [36] &quot;anyway&quot;       &quot;anyways&quot;      &quot;anywhere&quot;     &quot;apart&quot;        &quot;appear&quot;      
##  [41] &quot;appreciate&quot;   &quot;appropriate&quot;  &quot;are&quot;          &quot;aren&#39;t&quot;       &quot;around&quot;      
##  [46] &quot;as&quot;           &quot;aside&quot;        &quot;ask&quot;          &quot;asking&quot;       &quot;associated&quot;  
##  [51] &quot;at&quot;           &quot;available&quot;    &quot;away&quot;         &quot;awfully&quot;      &quot;b&quot;           
##  [56] &quot;be&quot;           &quot;became&quot;       &quot;because&quot;      &quot;become&quot;       &quot;becomes&quot;     
##  [61] &quot;becoming&quot;     &quot;been&quot;         &quot;before&quot;       &quot;beforehand&quot;   &quot;behind&quot;      
##  [66] &quot;being&quot;        &quot;believe&quot;      &quot;below&quot;        &quot;beside&quot;       &quot;besides&quot;     
##  [71] &quot;best&quot;         &quot;better&quot;       &quot;between&quot;      &quot;beyond&quot;       &quot;both&quot;        
##  [76] &quot;brief&quot;        &quot;but&quot;          &quot;by&quot;           &quot;c&quot;            &quot;c&#39;mon&quot;       
##  [81] &quot;c&#39;s&quot;          &quot;came&quot;         &quot;can&quot;          &quot;can&#39;t&quot;        &quot;cannot&quot;      
##  [86] &quot;cant&quot;         &quot;cause&quot;        &quot;causes&quot;       &quot;certain&quot;      &quot;certainly&quot;   
##  [91] &quot;changes&quot;      &quot;clearly&quot;      &quot;co&quot;           &quot;com&quot;          &quot;come&quot;        
##  [96] &quot;comes&quot;        &quot;concerning&quot;   &quot;consequently&quot; &quot;consider&quot;     &quot;considering&quot;</code></pre>
<p>That looks pretty comprehensive so far, though the only way we’ll know whether
it’s a good match for our corpus is to process our corpus with it. At first
glance, the extra random letters in this list seem like they could be a big
help, on the off chance there’s some noise from OCR. If you look at the first
novel in the corpus, for example, there are a bunch of stray <em>p</em>’s, which is
likely from a pattern for marking pages (“p. 7”):</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb528-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">str_sub</span>(corpus[[<span class="dv">1</span>]]<span class="sc">$</span>content, <span class="dv">1</span>, <span class="dv">1000</span>))</span></code></pre></div>
<pre><code>## VATHEK;  AN ARABIAN TALE,    BY  WILLIAM BECKFORD, ESQ.    p. 7VATHEK.  Vathek, ninth Caliph [7a] of the race of the Abassides, was the son of Motassem, and the grandson of Haroun Al Raschid.  From an early accession to the throne, and the talents he possessed to adorn it, his subjects were induced to expect that his reign would be long and happy.  His figure was pleasing and majestic; but when he was angry, one of his eyes became so terrible [7b] that no person could bear to behold it; and the wretch upon whom it was fixed instantly fell backward, and sometimes expired.  For fear, however, of depopulating his dominions, and making his palace desolate, he but rarely gave way to his anger.  Being much addicted to women, and the pleasures of the table, he sought by his affability to procure agreeable companions; and he succeeded the better, p. 8as his generosity was unbounded and his indulgences unrestrained; for he was by no means scrupulous: nor did he think, with the Caliph Omar Ben A</code></pre>
<p>Our stop word list would take care of this. With it, we could return to our
original collection of novels, split them on spaces as before, and filter out
everything that’s stored in our <code>stop_list</code> variable. Before we did the
filtering, though, we’d need to transform the novels into lowercase (which can
be done with <code>R</code>’s <code>tolower()</code> function).</p>
</div>
<div id="tokenizers" class="section level3" number="20.4.4">
<h3><span class="header-section-number">20.4.4</span> Tokenizers</h3>
<p>This whole process is ultimately straightforward so far, but it would be nice to
collapse all its steps. Luckily, there are packages we can use to streamline our
process. <code>tokenizers</code> has functions that split a text vector, turn words into
lowercase forms, and remove stop words, all in a few lines of code. Further, we
can combine these functions with a special <code>tm_map()</code> function in the <code>tm</code>
package, which will globally apply our changes.</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb530-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tokenizers)</span>
<span id="cb530-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb530-2" aria-hidden="true" tabindex="-1"></a>cleaned_corpus <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus, <span class="cf">function</span>(x) <span class="fu">tokenize_words</span>(x,</span>
<span id="cb530-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb530-3" aria-hidden="true" tabindex="-1"></a>                                                            <span class="at">stopwords=</span><span class="fu">stopwords</span>(<span class="st">&quot;SMART&quot;</span>),</span>
<span id="cb530-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb530-4" aria-hidden="true" tabindex="-1"></a>                                                            <span class="at">lowercase=</span><span class="cn">TRUE</span>,</span>
<span id="cb530-5"><a href="data-forensics-and-cleaning-unstructured-data.html#cb530-5" aria-hidden="true" tabindex="-1"></a>                                                            <span class="at">strip_punct=</span><span class="cn">TRUE</span>,</span>
<span id="cb530-6"><a href="data-forensics-and-cleaning-unstructured-data.html#cb530-6" aria-hidden="true" tabindex="-1"></a>                                                            <span class="at">strip_numeric=</span><span class="cn">TRUE</span>))</span></code></pre></div>
<p>You may see a “transformation drops documents” warning after this. You can
disregard it. It has to do with the way <code>tm</code> references text changes against
a corpus’s metadata, which we’ve left blank.</p>
<p>We can compare our tokenized output with the text data we had been working with
earlier:</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb531-1" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">untokenized=</span>frankenstein[[<span class="dv">1</span>]][<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>], <span class="at">tokenized=</span>cleaned_corpus[[<span class="dv">6</span>]]<span class="sc">$</span>content[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<pre><code>## $untokenized
## [1] &quot;FRANKENSTEIN&quot; &quot;OR&quot;           &quot;THE&quot;          &quot;MODERN&quot;       &quot;PROMETHEUS&quot;  
## [6] &quot;BY&quot;           &quot;MARY&quot;         &quot;W&quot;            &quot;SHELLEY&quot;     
## 
## $tokenized
## [1] &quot;frankenstein&quot; &quot;modern&quot;       &quot;prometheus&quot;   &quot;mary&quot;         &quot;shelley&quot;</code></pre>
<p>From the title alone we can see how much of a difference tokenizing with stop
words makes. And while we lose a bit of information by doing this, what we can
is a much clearer picture of key words we’d want to further analyze.</p>
</div>
<div id="document-chunking-and-n-grams" class="section level3" number="20.4.5">
<h3><span class="header-section-number">20.4.5</span> Document Chunking and N-grams</h3>
<p>Finally, it’s possible to change the way we separate out our text data. Instead
of tokenizing on words, we could use <code>tokenizers</code> to break apart our texts on
paragraphs (<code>tokenize_paragraphs()</code>), sentences (<code>tokenize_sentences</code>), and
more. There might be valuable information to be learned about the average
sentence length of a novel, for example, so we might chunk it accordingly.</p>
<p>We might also want to see whether a text contains repeated phrases, or if two or
three words often occur in the same sequence. We could investigate this by
adjusting the window around which we tokenize individual words. So far we’ve
used the “unigram,” or a single word, as our basic unit of counting, but we
could break our texts into “bigrams” (two word phrases), “trigrams” (three word
phrases), or, well any sequence of <em>n</em> units. Generally, you’ll see these
sequences referred to as <strong>n-grams</strong>:</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb533-1" aria-hidden="true" tabindex="-1"></a>frankenstein_bigrams <span class="ot">&lt;-</span> <span class="fu">tokenize_ngrams</span>(corpus[[<span class="dv">6</span>]]<span class="sc">$</span>content,</span>
<span id="cb533-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb533-2" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">n=</span><span class="dv">2</span>,</span>
<span id="cb533-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb533-3" aria-hidden="true" tabindex="-1"></a>                                        <span class="at">stopwords=</span><span class="fu">stopwords</span>(<span class="st">&quot;SMART&quot;</span>))</span></code></pre></div>
<p>Here, <code>n=2</code> sets the n-gram window at two:</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb534-1" aria-hidden="true" tabindex="-1"></a>frankenstein_bigrams[[<span class="dv">1</span>]][<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span></code></pre></div>
<pre><code>##  [1] &quot;frankenstein modern&quot;   &quot;modern prometheus&quot;     &quot;prometheus mary&quot;      
##  [4] &quot;mary shelley&quot;          &quot;shelley preface&quot;       &quot;preface event&quot;        
##  [7] &quot;event fiction&quot;         &quot;fiction founded&quot;       &quot;founded supposed&quot;     
## [10] &quot;supposed dr&quot;           &quot;dr darwin&quot;             &quot;darwin physiological&quot; 
## [13] &quot;physiological writers&quot; &quot;writers germany&quot;       &quot;germany impossible&quot;   
## [16] &quot;impossible occurrence&quot; &quot;occurrence supposed&quot;   &quot;supposed remotest&quot;    
## [19] &quot;remotest degree&quot;       &quot;degree faith&quot;</code></pre>
<p>Note though that, for this function, we’d need to do some preprocessing on our
own to remove numeric characters and punctuation; <code>tokenize_ngrams()</code> won’t do
it for us.</p>
</div>
</div>
<div id="counting-terms" class="section level2" number="20.5">
<h2><span class="header-section-number">20.5</span> Counting Terms</h2>
<p>Let’s return to our single word counts. Now that we’ve transformed our novels
into bags of single words, we can start with some analysis. Simply counting the
number of times a word appears in some data can tell us a lot about a text. The
following steps should feel familiar: we did them with OCR.</p>
<p>Let’s look at <em>Wuthering Heights</em>, which is our ninth text:</p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb536-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb536-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb536-2" aria-hidden="true" tabindex="-1"></a>wuthering_heights <span class="ot">&lt;-</span> <span class="fu">table</span>(cleaned_corpus[[<span class="dv">9</span>]]<span class="sc">$</span>content)</span>
<span id="cb536-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb536-3" aria-hidden="true" tabindex="-1"></a>wuthering_heights <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">word=</span><span class="fu">names</span>(wuthering_heights),</span>
<span id="cb536-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb536-4" aria-hidden="true" tabindex="-1"></a>                                <span class="at">count=</span><span class="fu">as.numeric</span>(wuthering_heights))</span>
<span id="cb536-5"><a href="data-forensics-and-cleaning-unstructured-data.html#cb536-5" aria-hidden="true" tabindex="-1"></a>wuthering_heights <span class="ot">&lt;-</span> <span class="fu">arrange</span>(wuthering_heights, <span class="fu">desc</span>(count))</span>
<span id="cb536-6"><a href="data-forensics-and-cleaning-unstructured-data.html#cb536-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(wuthering_heights, <span class="dv">30</span>)</span></code></pre></div>
<pre><code>##          word count
## 1  heathcliff   422
## 2      linton   348
## 3   catherine   339
## 4          mr   312
## 5      master   185
## 6     hareton   169
## 7    answered   156
## 8        till   151
## 9       house   144
## 10       door   133
## 11        mrs   133
## 12     joseph   130
## 13       miss   129
## 14       time   127
## 15       back   121
## 16    thought   118
## 17      cathy   117
## 18       good   117
## 19    replied   117
## 20   earnshaw   116
## 21       eyes   116
## 22      cried   114
## 23      young   107
## 24        day   106
## 25     father   106
## 26      asked   105
## 27       make   105
## 28      edgar   104
## 29      night   104
## 30       made   102</code></pre>
<p>Looks good! The two main characters in this novel are named Heathcliff and
Catherine, so it makes sense that these words would appear a lot. You can see,
however, that we might want to fine tune our stop word list so that it removes
“mr” and “mrs” from the text. Though again, it depends on our research question.
If we’re exploring gender roles in nineteenth-century literature, we’d probably
keep those words in.</p>
<p>In addition to fine tuning stop words, pausing here at these counts would be a
good way to check whether some other form of textual noise is present in your
data, which you haven’t yet caught. There’s nothing like that here, but you
might imagine how consistent OCR noise could make itself known in this view.</p>
<div id="term-frequency" class="section level3" number="20.5.1">
<h3><span class="header-section-number">20.5.1</span> Term Frequency</h3>
<p>After you’ve done your fine tuning, it would be good to get a <strong>term frequency</strong>
number for each word in this data frame. Raw counts are nice, but expressing
those counts in proportion to the total words in a document will tell us more
information about a word’s contribution to the document as a whole. We can get
term frequencies for our words by dividing a word’s count by document length
(which is the sum of all words in the document).</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb538-1" aria-hidden="true" tabindex="-1"></a>wuthering_heights<span class="sc">$</span>term_frequency <span class="ot">&lt;-</span> <span class="fu">sapply</span>(wuthering_heights<span class="sc">$</span>count,</span>
<span id="cb538-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb538-2" aria-hidden="true" tabindex="-1"></a>                                           <span class="cf">function</span>(x) (x<span class="sc">/</span><span class="fu">sum</span>(wuthering_heights<span class="sc">$</span>count)))</span>
<span id="cb538-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb538-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(wuthering_heights, <span class="dv">30</span>)</span></code></pre></div>
<pre><code>##          word count term_frequency
## 1  heathcliff   422    0.009619549
## 2      linton   348    0.007932709
## 3   catherine   339    0.007727552
## 4          mr   312    0.007112084
## 5      master   185    0.004217101
## 6     hareton   169    0.003852379
## 7    answered   156    0.003556042
## 8        till   151    0.003442066
## 9       house   144    0.003282500
## 10       door   133    0.003031754
## 11        mrs   133    0.003031754
## 12     joseph   130    0.002963368
## 13       miss   129    0.002940573
## 14       time   127    0.002894983
## 15       back   121    0.002758212
## 16    thought   118    0.002689827
## 17      cathy   117    0.002667031
## 18       good   117    0.002667031
## 19    replied   117    0.002667031
## 20   earnshaw   116    0.002644236
## 21       eyes   116    0.002644236
## 22      cried   114    0.002598646
## 23      young   107    0.002439080
## 24        day   106    0.002416285
## 25     father   106    0.002416285
## 26      asked   105    0.002393490
## 27       make   105    0.002393490
## 28      edgar   104    0.002370695
## 29      night   104    0.002370695
## 30       made   102    0.002325104</code></pre>
</div>
<div id="plotting-term-frequency" class="section level3" number="20.5.2">
<h3><span class="header-section-number">20.5.2</span> Plotting Term Frequency</h3>
<p>Let’s plot the top 50 words in <em>Wuthering Heights</em>. We’ll call <code>fct_reorder()</code>
in the <code>aes()</code> field of <code>ggplot</code> to sort words in the descending order of their
term frequency.</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb540-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb540-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>wuthering_heights[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ], <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">fct_reorder</span>(word, <span class="sc">-</span>term_frequency), <span class="at">y=</span>term_frequency)) <span class="sc">+</span></span>
<span id="cb540-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb540-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">&quot;identity&quot;</span>) <span class="sc">+</span> </span>
<span id="cb540-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb540-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x=</span><span class="fu">element_text</span>(<span class="at">angle=</span><span class="dv">90</span>, <span class="at">vjust=</span><span class="fl">0.5</span>, <span class="at">hjust=</span><span class="dv">1</span>)) <span class="sc">+</span> </span>
<span id="cb540-5"><a href="data-forensics-and-cleaning-unstructured-data.html#cb540-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Top 50 words in Wuthering Heights&quot;</span>, <span class="at">x=</span><span class="st">&quot;Word&quot;</span>, <span class="at">y=</span><span class="st">&quot;Term Frequency&quot;</span>)</span></code></pre></div>
<p><img src="19_data_forensics-unstructured-data_files/figure-html/unnamed-chunk-27-1.png" width="960" /></p>
<p>This is a good start for creating a high-level view of the novel, but further
tuning might be in order. We’ve already mentioned “mrs” and “mr” as two words
that we could cut out of the text. Another option would be to collapse these
two words together into a <strong>base form</strong> by <strong>stemming</strong> them. Though this would
overweight their base form (which in this case is “mr”) in terms of term
frequency, it would also free up space to see other terms in the document. Other
examples of stemming words would be transforming “fishing,” “fished,” and
“fisher” all into “fish.”</p>
<p>That said, like all preprocessing, lemmatizing words is an
<em>interpretive decision</em>, which comes with its own consequences. Maybe it’s okay
to transform “mr” and “mrs” into “mr” for some analyses, but it’s also the case
that we’d be erasing potentially important gender differences in the text—and
would do so by overweighting the masculine form of the word. Regardless of what
you decide, it’s important to keep track of these decisions as you make them
because they will impact the kinds of claims you make about your data later on.</p>
</div>
<div id="comparing-term-frequencies-across-documents" class="section level3" number="20.5.3">
<h3><span class="header-section-number">20.5.3</span> Comparing Term Frequencies Across Documents</h3>
<p>Term frequency is helpful if we want to start comparing words across two texts.
We can make some comparisons by transforming the above code into a function:</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-1" aria-hidden="true" tabindex="-1"></a>term_table <span class="ot">&lt;-</span> <span class="cf">function</span>(text) {</span>
<span id="cb541-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-2" aria-hidden="true" tabindex="-1"></a>  term_tab <span class="ot">&lt;-</span> <span class="fu">table</span>(text)</span>
<span id="cb541-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-3" aria-hidden="true" tabindex="-1"></a>  term_tab <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">word=</span><span class="fu">names</span>(term_tab), <span class="at">count=</span><span class="fu">as.numeric</span>(term_tab))</span>
<span id="cb541-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-4" aria-hidden="true" tabindex="-1"></a>  term_tab<span class="sc">$</span>term_frequency <span class="ot">&lt;-</span> <span class="fu">sapply</span>(term_tab<span class="sc">$</span>count, <span class="cf">function</span>(x) (x<span class="sc">/</span><span class="fu">sum</span>(term_tab<span class="sc">$</span>count)))</span>
<span id="cb541-5"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-5" aria-hidden="true" tabindex="-1"></a>  term_tab <span class="ot">&lt;-</span> <span class="fu">arrange</span>(term_tab, <span class="fu">desc</span>(count))</span>
<span id="cb541-6"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(term_tab)</span>
<span id="cb541-7"><a href="data-forensics-and-cleaning-unstructured-data.html#cb541-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We already have a term table for <em>Wuthering Heights</em>. Let’s make one for <em>Dracula</em>.</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb542-1" aria-hidden="true" tabindex="-1"></a>dracula <span class="ot">&lt;-</span> <span class="fu">term_table</span>(cleaned_corpus[[<span class="dv">18</span>]]<span class="sc">$</span>content)</span>
<span id="cb542-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb542-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dracula, <span class="dv">30</span>)</span></code></pre></div>
<pre><code>##         word count term_frequency
## 1       time   387    0.007280458
## 2        van   321    0.006038829
## 3    helsing   299    0.005624953
## 4       back   261    0.004910076
## 5       room   231    0.004345699
## 6       good   225    0.004232824
## 7       lucy   225    0.004232824
## 8        man   224    0.004214012
## 9       dear   219    0.004119949
## 10      mina   217    0.004082324
## 11     night   217    0.004082324
## 12      hand   209    0.003931823
## 13      face   205    0.003856573
## 14      door   201    0.003781323
## 15      made   193    0.003630822
## 16      poor   192    0.003612010
## 17     sleep   190    0.003574385
## 18      eyes   186    0.003499135
## 19    looked   185    0.003480322
## 20    friend   183    0.003442697
## 21     great   182    0.003423884
## 22  jonathan   182    0.003423884
## 23        dr   178    0.003348634
## 24    things   174    0.003273384
## 25      make   163    0.003066446
## 26       day   160    0.003010008
## 27 professor   155    0.002915946
## 28     count   153    0.002878320
## 29     found   153    0.002878320
## 30   thought   153    0.002878320</code></pre>
<p>Now we can compare the relative frequency of a word across two novels:</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-1" aria-hidden="true" tabindex="-1"></a>comparison_words <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;dark&quot;</span>, <span class="st">&quot;night&quot;</span>, <span class="st">&quot;ominous&quot;</span>)</span>
<span id="cb544-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> comparison_words) {</span>
<span id="cb544-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-3" aria-hidden="true" tabindex="-1"></a>  wh <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">wh=</span><span class="fu">subset</span>(wuthering_heights, word<span class="sc">==</span>i))</span>
<span id="cb544-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-4" aria-hidden="true" tabindex="-1"></a>  drac <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">drac=</span><span class="fu">subset</span>(dracula, word<span class="sc">==</span>i))</span>
<span id="cb544-5"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(wh)</span>
<span id="cb544-6"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(drac)</span>
<span id="cb544-7"><a href="data-forensics-and-cleaning-unstructured-data.html#cb544-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## $wh
##     word count term_frequency
## 183 dark    32   0.0007294445
## 
## $drac
##    word count term_frequency
## 90 dark    77    0.001448566
## 
## $wh
##     word count term_frequency
## 29 night   104    0.002370695
## 
## $drac
##     word count term_frequency
## 11 night   217    0.004082324
## 
## $wh
##         word count term_frequency
## 7283 ominous     1   2.279514e-05
## 
## $drac
##         word count term_frequency
## 7217 ominous     1   1.881255e-05</code></pre>
<p>Not bad! We might be able to make a few generalizations from this, but to say
anything definitively, we’ll need to scale our method. Doing so wouldn’t be
easy with this setup as it stands now. While it’s true that we could write some
functions to roll through these two data frames and systematically compare the
words in each, it would take a lot of work to do so. Luckily, the <code>tm</code> package
(which we’ve used to make our stop word list) features generalized functions
for just this kind of thing.</p>
</div>
</div>
<div id="text-mining-pipepline" class="section level2" number="20.6">
<h2><span class="header-section-number">20.6</span> Text Mining Pipepline</h2>
<p>Before going further, we should note that <code>tm</code> has its own functions for
preprocessing texts. To send raw files directly through those functions, you’d
call <code>tm_map()</code> in conjunction with these functions. You can think of <code>tm_map()</code>
as a cognate to the <code>apply()</code> family.</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb546-1" aria-hidden="true" tabindex="-1"></a>corpus_2 <span class="ot">&lt;-</span> <span class="fu">Corpus</span>(<span class="fu">VectorSource</span>(files))</span>
<span id="cb546-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb546-2" aria-hidden="true" tabindex="-1"></a>corpus_2 <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_2, removeNumbers)</span>
<span id="cb546-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb546-3" aria-hidden="true" tabindex="-1"></a>corpus_2 <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_2, removeWords, <span class="fu">stopwords</span>(<span class="st">&quot;SMART&quot;</span>))</span>
<span id="cb546-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb546-4" aria-hidden="true" tabindex="-1"></a>corpus_2 <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_2, removePunctuation)</span>
<span id="cb546-5"><a href="data-forensics-and-cleaning-unstructured-data.html#cb546-5" aria-hidden="true" tabindex="-1"></a>corpus_2 <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(corpus_2, stripWhitespace)</span></code></pre></div>
<p>Note the order of operations here: because our stop words list takes into account
punctuated words, like “don’t” or “i’m,” we want to remove stop words <em>before</em>
removing punctuation. If we didn’t do this, <code>removeWords()</code> wouldn’t catch the
un-punctuated “dont” or “im.” This won’t always be the case, since we can use
different stop word lists, which may have a different set of terms, but in this
instance, the order in which we preprocess matters.</p>
<p>Preparing your text files like this would be fine, and indeed sometimes it’s
preferable to sequentially step through each part of the preprocessing workflow.
That said, <code>tokenizers</code> manages the order of operations above on its own and its
preprocessing functions are generally a bit faster to run (in particular,
<code>removeWords()</code> is quite slow in comparison to <code>tokenize_words()</code>).</p>
<p>There is, however, one caveat to using <code>tokenizers</code>. It splits documents up to
do text cleaning, but other functions in <code>tm</code> require non-split documents. If
we use <code>tokenizers</code>, then, we need to do a quick workaround with <code>paste()</code>.</p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb547-1" aria-hidden="true" tabindex="-1"></a>cleaned_corpus <span class="ot">&lt;-</span> <span class="fu">lapply</span>(cleaned_corpus, <span class="cf">function</span>(x) <span class="fu">paste</span>(x, <span class="at">collapse=</span><span class="st">&quot; &quot;</span>))</span></code></pre></div>
<p>And then reformat that output as a corpus object:</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb548-1" aria-hidden="true" tabindex="-1"></a>cleaned_corpus <span class="ot">&lt;-</span> <span class="fu">Corpus</span>(<span class="fu">VectorSource</span>(cleaned_corpus))</span></code></pre></div>
<p>Ultimately, it’s up to you to decide what workflow makes sense. Personally, I
(Tyler) like to do exploratory preprocessing steps with <code>tokenizers</code>, often with
a sample set of all the documents. Then, once I’ve settled on my stop word list
and so forth, I reprocess all my files with the <code>tm</code>-specific functions above.</p>
<p>Regardless of what workflow you choose, preprocessing can take a while, so now
would be a good place to save your data. That way, you can retrieve your corpus
later on.</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(cleaned_corpus, <span class="st">&quot;./data/C19_novels_cleaned.rds&quot;</span>)</span></code></pre></div>
<p>Loading it back in is straightforward:</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb550-1" aria-hidden="true" tabindex="-1"></a>cleaned_corpus <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;./data/C19_novels_cleaned.rds&quot;</span>)</span></code></pre></div>
</div>
<div id="document-term-matrix" class="section level2" number="20.7">
<h2><span class="header-section-number">20.7</span> Document Term Matrix</h2>
<p>The advantage of using a <code>tm</code> corpus is that it makes comparing data easier.
Remember that, in our old workflow, looking at the respective term frequencies
in two documents entailed a fair bit of code. And further, we left off before
generalizing that code to the corpus as a whole. But what if we wanted to look
at a term across multiple documents?</p>
<p>To do so, we need to create what’s called a <strong>document-term matrix</strong>, or DTM. A
DTM describes the frequency of terms across an entire corpus (rather than just
one document). Rows of the matrix correspond to documents, while columns
correspond to the terms. For a given document, we count the number of times that
term appears and enter that number in the column in question. We do this <em>even if</em>
the count is 0; key to the way a DTM works is that it’s a <em>corpus-wide</em>
representation of text data, so it matters if a text does or doesn’t contain a
term.</p>
<p>Here’s a simple example with three documents:</p>
<ul>
<li>Document 1: “I like cats”</li>
<li>Document 2: “I like dogs”</li>
<li>Document 3: “I like both cats and dogs”</li>
</ul>
<p>Transforming these into a document-term matrix would yield:</p>
<table>
<thead>
<tr class="header">
<th align="center">n_doc</th>
<th align="center">I</th>
<th align="center">like</th>
<th align="center">both</th>
<th align="center">cats</th>
<th align="center">and</th>
<th align="center">dogs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Representing texts in this way is incredibly useful because it enables us to
easily discern similarities and differences in our corpus. For example, we can
see that each of the above documents contain the words “I” and “like.” Given
that, if we wanted to know what makes documents unique, we can ignore those two
words and focus on the rest of the values.</p>
<p>Now, imagine doing this for thousands of words! What patterns might emerge?</p>
<p>Let’s try it on our corpus. We can transform a <code>tm</code> corpus object into a DTM
by calling <code>DocumentTermMatrix()</code>. (Note: this is one of the functions in <code>tm</code>
that requires non-split documents, so before you call it make sure you know
how you’ve preprocessed your texts!)</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb551-1" aria-hidden="true" tabindex="-1"></a>dtm <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(cleaned_corpus)</span></code></pre></div>
<p>This object is quite similar to the one that results from <code>Corpus()</code>: it
contains a fair bit of metadata, as well as an all-important “dimnames” field,
which records the documents in the matrix and the entire term vocabulary. We
access all of this information with the same syntax we use for data frames.</p>
<p>Let’s look around a bit and get some high-level info.</p>
</div>
<div id="corpus-analytics" class="section level2" number="20.8">
<h2><span class="header-section-number">20.8</span> Corpus Analytics</h2>
<p>Number of columns in the DTM (i.e. the vocabulary size):</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb552-1" aria-hidden="true" tabindex="-1"></a>dtm<span class="sc">$</span>ncol</span></code></pre></div>
<pre><code>## [1] 34925</code></pre>
<p>Number of rows in the DTM (i.e. the number of documents this matrix represents):</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb554-1" aria-hidden="true" tabindex="-1"></a>dtm<span class="sc">$</span>nrow</span></code></pre></div>
<pre><code>## [1] 18</code></pre>
<p>Right now, the document names are just a numbers in a vector:</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb556-1" aria-hidden="true" tabindex="-1"></a>dtm<span class="sc">$</span>dimnames<span class="sc">$</span>Docs</span></code></pre></div>
<pre><code>##  [1] &quot;1&quot;  &quot;2&quot;  &quot;3&quot;  &quot;4&quot;  &quot;5&quot;  &quot;6&quot;  &quot;7&quot;  &quot;8&quot;  &quot;9&quot;  &quot;10&quot; &quot;11&quot; &quot;12&quot; &quot;13&quot; &quot;14&quot; &quot;15&quot;
## [16] &quot;16&quot; &quot;17&quot; &quot;18&quot;</code></pre>
<p>But they’re ordered according to the sequence in which the corpus was originally
created. This means we can use our metadata from way back when to associate a
document with its title:</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb558-1" aria-hidden="true" tabindex="-1"></a>dtm<span class="sc">$</span>dimnames<span class="sc">$</span>Docs <span class="ot">&lt;-</span> C19_novels<span class="sc">$</span>title</span>
<span id="cb558-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb558-2" aria-hidden="true" tabindex="-1"></a>dtm<span class="sc">$</span>dimnames<span class="sc">$</span>Docs</span></code></pre></div>
<pre><code>##  [1] &quot;Vathek&quot;                        &quot;ASicilianRomance&quot;             
##  [3] &quot;TheMysteriesofUdolpho&quot;         &quot;TheMonk&quot;                      
##  [5] &quot;SenseandSensibility&quot;           &quot;Frankenstein&quot;                 
##  [7] &quot;Ivanhoe&quot;                       &quot;TheNarrativeofArthurGordonPym&quot;
##  [9] &quot;WutheringHeights&quot;              &quot;TheHouseoftheSevenGables&quot;     
## [11] &quot;NorthandSouth&quot;                 &quot;TheWomaninWhite&quot;              
## [13] &quot;GreatExpectations&quot;             &quot;PortraitofaLady&quot;              
## [15] &quot;TreasureIsland&quot;                &quot;JekyllandHyde&quot;                
## [17] &quot;ThePictureofDorianGray&quot;        &quot;Dracula&quot;</code></pre>
<p>With this information associated, we can use <code>inspect()</code> to get a high-level
view of the corpus.</p>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb560-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb560-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(dtm)</span></code></pre></div>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 18, terms: 34925)&gt;&gt;
## Non-/sparse entries: 145233/483417
## Sparsity           : 77%
## Maximal term length: 19
## Weighting          : term frequency (tf)
## Sample             :
##                           Terms
## Docs                       back day eyes good great long made man thought time
##   Dracula                   261 160  186  225   182  147  193 224     153  387
##   GreatExpectations         244 216  180  256   198  173  300 307     238  373
##   Ivanhoe                    77 138  100  298   111  154  151 235      46  182
##   NorthandSouth             184 257  197  316   179  211  234 270     332  423
##   PortraitofaLady           210 241  226  520   421  187  381 317     302  339
##   TheHouseoftheSevenGables   79 113   72  100   144  153  144 211      60  113
##   TheMonk                    81 106  184   80    66  108  167  95      72  162
##   TheMysteriesofUdolpho     117 167  225  186   164  359  316 213     341  367
##   TheWomaninWhite           417 351  233  235   112  188  244 443     183  706
##   WutheringHeights          121 106  116  117    63   97  102  88     118  127</code></pre>
<p>Of special note here is <strong>sparsity</strong>. Sparsity measures the amount of 0s in the
data. This happens when a document does not contain a term that appears
elsewhere in the corpus. In our case, of the 628,650 entries in this matrix,
80% of them are 0. Such is the way of working with DTMs: they’re big, expansive
data structures that have a lot of empty space.</p>
<p>We can zoom in and filter on term counts with <code>findFreqTerms()</code>. Here are terms
that appear more than 1,000 times in the corpus:</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb562-1" aria-hidden="true" tabindex="-1"></a><span class="fu">findFreqTerms</span>(dtm, <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>##  [1] &quot;answered&quot; &quot;appeared&quot; &quot;asked&quot;    &quot;back&quot;     &quot;day&quot;      &quot;dear&quot;    
##  [7] &quot;death&quot;    &quot;door&quot;     &quot;eyes&quot;     &quot;face&quot;     &quot;father&quot;   &quot;felt&quot;    
## [13] &quot;found&quot;    &quot;friend&quot;   &quot;gave&quot;     &quot;give&quot;     &quot;good&quot;     &quot;great&quot;   
## [19] &quot;half&quot;     &quot;hand&quot;     &quot;hands&quot;    &quot;head&quot;     &quot;hear&quot;     &quot;heard&quot;   
## [25] &quot;heart&quot;    &quot;hope&quot;     &quot;kind&quot;     &quot;knew&quot;     &quot;lady&quot;     &quot;leave&quot;   
## [31] &quot;left&quot;     &quot;life&quot;     &quot;light&quot;    &quot;long&quot;     &quot;looked&quot;   &quot;love&quot;    
## [37] &quot;made&quot;     &quot;make&quot;     &quot;man&quot;      &quot;men&quot;      &quot;mind&quot;     &quot;moment&quot;  
## [43] &quot;morning&quot;  &quot;mother&quot;   &quot;night&quot;    &quot;part&quot;     &quot;passed&quot;   &quot;people&quot;  
## [49] &quot;person&quot;   &quot;place&quot;    &quot;poor&quot;     &quot;present&quot;  &quot;put&quot;      &quot;replied&quot; 
## [55] &quot;returned&quot; &quot;round&quot;    &quot;side&quot;     &quot;speak&quot;    &quot;stood&quot;    &quot;thing&quot;   
## [61] &quot;thou&quot;     &quot;thought&quot;  &quot;till&quot;     &quot;time&quot;     &quot;told&quot;     &quot;turned&quot;  
## [67] &quot;voice&quot;    &quot;woman&quot;    &quot;words&quot;    &quot;world&quot;    &quot;young&quot;    &quot;count&quot;   
## [73] &quot;house&quot;    &quot;madame&quot;   &quot;room&quot;     &quot;sir&quot;      &quot;emily&quot;    &quot;margaret&quot;
## [79] &quot;miss&quot;     &quot;mrs&quot;      &quot;isabel&quot;</code></pre>
<p>Using <code>findAssocs()</code>, we can also track which words rise and fall in usage
alongside a given word. (The number in the third argument position of this
function is a cutoff for the strength of a correlation.)</p>
<p>Here’s “boat”:</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">findAssocs</span>(dtm, <span class="st">&quot;boat&quot;</span>, .<span class="dv">85</span>)</span></code></pre></div>
<pre><code>## $boat
##   thumping scoundrels     midday  direction 
##       0.94       0.88       0.87       0.85</code></pre>
<p>Here’s “writing” (there are a lot of terms, so we’ll limit to 15):</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb566-1" aria-hidden="true" tabindex="-1"></a>writing <span class="ot">&lt;-</span> <span class="fu">findAssocs</span>(dtm, <span class="st">&quot;writing&quot;</span>, .<span class="dv">85</span>)</span>
<span id="cb566-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb566-2" aria-hidden="true" tabindex="-1"></a>writing[[<span class="dv">1</span>]][<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>]</span></code></pre></div>
<pre><code>##      letter        copy    disposal   inquiries    bedrooms   hindrance 
##        0.99        0.97        0.97        0.97        0.97        0.97 
##    messages certificate    distrust     plainly    drawings   anonymous 
##        0.97        0.97        0.96        0.96        0.96        0.96 
##    ladyship  plantation    lodgings 
##        0.96        0.96        0.96</code></pre>
<div id="corpus-term-counts" class="section level3" number="20.8.1">
<h3><span class="header-section-number">20.8.1</span> Corpus Term Counts</h3>
<p>From here, it would be useful to get a full count of all the terms in the corpus.
We can transform the DTM into a matrix and then a data frame.</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb568-1" aria-hidden="true" tabindex="-1"></a>term_counts <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(dtm)</span>
<span id="cb568-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb568-2" aria-hidden="true" tabindex="-1"></a>term_counts <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">sort</span>(<span class="fu">colSums</span>(term_counts), <span class="at">decreasing=</span><span class="cn">TRUE</span>))</span>
<span id="cb568-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb568-3" aria-hidden="true" tabindex="-1"></a>term_counts <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">newColName=</span><span class="fu">rownames</span>(term_counts), term_counts)</span>
<span id="cb568-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb568-4" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(term_counts) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;term&quot;</span>, <span class="st">&quot;count&quot;</span>)</span></code></pre></div>
<p>As before, let’s plot the top 50 terms in these counts, but this time, they will
cover the entire corpus:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb569-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>term_counts[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ], <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">fct_reorder</span>(term, <span class="sc">-</span>count), <span class="at">y=</span>count)) <span class="sc">+</span></span>
<span id="cb569-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb569-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">&quot;identity&quot;</span>) <span class="sc">+</span> </span>
<span id="cb569-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb569-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x=</span><span class="fu">element_text</span>(<span class="at">angle=</span><span class="dv">90</span>, <span class="at">vjust=</span><span class="fl">0.5</span>, <span class="at">hjust=</span><span class="dv">1</span>)) <span class="sc">+</span> </span>
<span id="cb569-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb569-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Top 50 words in 18 Nineteenth-Century Novels&quot;</span>, <span class="at">x=</span><span class="st">&quot;Word&quot;</span>, <span class="at">y=</span><span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<p><img src="19_data_forensics-unstructured-data_files/figure-html/unnamed-chunk-46-1.png" width="960" /></p>
<p>This looks good, though the words here are all pretty common. In fact, many of
them are simply the most common words in the English language. “Time” is the
64th-most frequent word in English; “make” is the 50th. As it stands, then,
this graph doesn’t tell us very much about the <em>specificity</em> of our particular
collection of texts; if we ran the same process on English novels from the
twentieth century, we’d probably produce very similar output.</p>
</div>
<div id="tfidf-scores" class="section level3" number="20.8.2">
<h3><span class="header-section-number">20.8.2</span> tf–idf Scores</h3>
<p>Given this, if we want to know what makes our corpus special, we need a measure
of uniqueness for the terms it contains. One of the most common ways to do this
is to get what’s called a <strong>tf–idf</strong> score (short for “term frequency—inverse
document frequency”) for each term in our corpus. tf–idf is a weighting method.
It increases proportionally to the number of times a word appears in a
document but is importantly offset by the number of documents in the corpus that
contain this term. This offset adjusts for common words across a corpus, pushing
their scores down while boosting the scores of rarer terms in the corpus.</p>
<p>Inverse document frequency can be expressed as:</p>
<p><span class="math display">\[\begin{align*}
idf_i = log(\frac{n}{df_i})
\end{align*}\]</span></p>
<p>Where <span class="math inline">\(idf_i\)</span> is the idf score for term <span class="math inline">\(i\)</span>, <span class="math inline">\(df_i\)</span> is the number of documents
that contain <span class="math inline">\(i\)</span>, and <span class="math inline">\(n\)</span> is the total number of documents.</p>
<p>A tf-idf score can be calculated by the following:</p>
<p><span class="math display">\[\begin{align*}
w_i,_j = tf_i,_j \times idf_i
\end{align*}\]</span></p>
<p>Where <span class="math inline">\(w_i,_j\)</span> is the tf–idf score of term <span class="math inline">\(i\)</span> in document <span class="math inline">\(j\)</span>, <span class="math inline">\(tf_i,_j\)</span> is
the term frequency for <span class="math inline">\(i\)</span> in <span class="math inline">\(j\)</span>, and <span class="math inline">\(idf_i\)</span> is the inverse document score.</p>
<p>While it’s good to know the underlying equations here, you won’t be tested on
the math specifically. And as it happens, <code>tm</code> has a way to perform the above
math for each term in a corpus. We can implement tf–idf scores when making a
document-term matrix:</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb570-1" aria-hidden="true" tabindex="-1"></a>dtm_tfidf <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(cleaned_corpus, <span class="at">control=</span><span class="fu">list</span>(<span class="at">weighting=</span>weightTfIdf))</span>
<span id="cb570-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb570-2" aria-hidden="true" tabindex="-1"></a>dtm_tfidf<span class="sc">$</span>dimnames<span class="sc">$</span>Docs <span class="ot">&lt;-</span> C19_novels<span class="sc">$</span>title</span></code></pre></div>
<p>To see what difference it makes, let’s plot the top terms in our corpus using
their tf–idf scores.</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb571-1" aria-hidden="true" tabindex="-1"></a>tfidf_counts <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(dtm_tfidf)</span>
<span id="cb571-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb571-2" aria-hidden="true" tabindex="-1"></a>tfidf_counts <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">sort</span>(<span class="fu">colSums</span>(tfidf_counts), <span class="at">decreasing=</span><span class="cn">TRUE</span>))</span>
<span id="cb571-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb571-3" aria-hidden="true" tabindex="-1"></a>tfidf_counts <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">newColName=</span><span class="fu">rownames</span>(tfidf_counts), tfidf_counts)</span>
<span id="cb571-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb571-4" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(tfidf_counts) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;term&quot;</span>, <span class="st">&quot;tfidf&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb572-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>tfidf_counts[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ], <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">fct_reorder</span>(term, <span class="sc">-</span>tfidf), <span class="at">y=</span>tfidf)) <span class="sc">+</span></span>
<span id="cb572-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb572-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">&quot;identity&quot;</span>) <span class="sc">+</span> </span>
<span id="cb572-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb572-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x=</span><span class="fu">element_text</span>(<span class="at">angle=</span><span class="dv">90</span>, <span class="at">vjust=</span><span class="fl">0.5</span>, <span class="at">hjust=</span><span class="dv">1</span>)) <span class="sc">+</span> </span>
<span id="cb572-4"><a href="data-forensics-and-cleaning-unstructured-data.html#cb572-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Words with the 50-highest tf--idf scores in 18 Nineteenth-Century Novels&quot;</span>, <span class="at">x=</span><span class="st">&quot;Word&quot;</span>, <span class="at">y=</span><span class="st">&quot;TF-IDF&quot;</span>)</span></code></pre></div>
<p><img src="19_data_forensics-unstructured-data_files/figure-html/unnamed-chunk-49-1.png" width="960" /></p>
<p>Lots of names! That makes sense: heavily weighted terms in these novels are
going to be terms that are unique to each text. Main characters’ names are used
a lot in novels, and the main character names in these novels are all unique.</p>
<p>To see in more concrete way how tf–idf scores might make a difference in the
way we analyze our corpus, we’ll do two last things. First, we’ll look again at
term correlations, using the same words from above with <code>findAssoscs()</code>, but
this time we’ll use tf–idf scores.</p>
<p>Here’s “boat”:</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb573-1" aria-hidden="true" tabindex="-1"></a><span class="fu">findAssocs</span>(dtm_tfidf, <span class="st">&quot;boat&quot;</span>, .<span class="dv">85</span>)</span></code></pre></div>
<pre><code>## $boat
##    thumping       shore      bucket      cables         doo       geese 
##        0.95        0.93        0.92        0.92        0.92        0.92 
##     pickled         sea      rudder     gunwale  scoundrels       boats 
##        0.92        0.91        0.91        0.91        0.91        0.90 
##        keel      sailed        crew    baffling     biscuit    bowsprit 
##        0.90        0.89        0.89        0.89        0.89        0.89 
##     hauling     muskets      ripped      splash      anchor         oar 
##        0.89        0.89        0.89        0.89        0.88        0.88 
##    rattling       sandy        cook      patted     shipped       beach 
##        0.88        0.88        0.88        0.88        0.88        0.87 
##     pistols      seamen     tobacco         lee    bulwarks      hauled 
##        0.87        0.87        0.87        0.87        0.87        0.87 
##     inkling      musket  navigation        rags    steering      island 
##        0.87        0.87        0.87        0.87        0.87        0.86 
##      bottle     tumbled       avast       belay       bilge   broadside 
##        0.86        0.86        0.86        0.86        0.86        0.86 
##    cruising   cutlasses    diagonal   furtively     headway     jupiter 
##        0.86        0.86        0.86        0.86        0.86        0.86 
##    mainland      marlin      midday     monthly   mutineers outnumbered 
##        0.86        0.86        0.86        0.86        0.86        0.86 
##     plumped     riggers    schooner   schooners   seaworthy    swamping 
##        0.86        0.86        0.86        0.86        0.86        0.86 
##      tide&#39;s      tiller     tonnage       towed       yawed        sail 
##        0.86        0.86        0.86        0.86        0.86        0.85 
##        ship         tap     loading       sails         aft      berths 
##        0.85        0.85        0.85        0.85        0.85        0.85 
##      pinned 
##        0.85</code></pre>
<p>Here’s “writing”:</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="fu">findAssocs</span>(dtm_tfidf, <span class="st">&quot;writing&quot;</span>, .<span class="dv">85</span>)</span></code></pre></div>
<pre><code>## $writing
##     hindrance      messages      disposal     inquiries      bedrooms 
##          0.92          0.91          0.90          0.90          0.89 
##      ladyship          copy      lodgings        london    unforeseen 
##          0.88          0.87          0.87          0.87          0.87 
##      drawings    plantation  explanations   certificate         dears 
##          0.86          0.86          0.86          0.86          0.86 
## neighbourhood    allowances 
##          0.85          0.85</code></pre>
<p>The semantics of these results have changed. For “boats,” we get much more
terms related to sefaring. Most probably this is because only a few novels talk
about boats so these terms correlate highly with one another. For “writing,”
we’ve interestingly lost a lot of the words associated with writing in a strict
sense (“copy,” “message”) but we’ve gained instead a list of terms that seem to
situate us in <em>where</em> writing takes place in these novels, or what characters
write <em>about</em>. So far though this is speculation; we’d have to look into this
further to see whether the hypothesis holds.</p>
<p>Finally, we can disaggregate our giant term count graph from above to focus
more closely on the uniqueness of individual novels in our corpus. First, we’ll
make a data frame from our tf–idf DTM. We’ll transpose the DTM so the
documents are our variables (columns) and the corpus vocabulary terms are our
observations (or rows). Don’t forget the <code>t</code>!</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb577-1" aria-hidden="true" tabindex="-1"></a>tfidf_df <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(dtm_tfidf)</span>
<span id="cb577-2"><a href="data-forensics-and-cleaning-unstructured-data.html#cb577-2" aria-hidden="true" tabindex="-1"></a>tfidf_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">t</span>(tfidf_df))</span>
<span id="cb577-3"><a href="data-forensics-and-cleaning-unstructured-data.html#cb577-3" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(tfidf_df) <span class="ot">&lt;-</span> C19_novels<span class="sc">$</span>title</span></code></pre></div>
</div>
<div id="unique-terms-in-a-document" class="section level3" number="20.8.3">
<h3><span class="header-section-number">20.8.3</span> Unique Terms in a Document</h3>
<p>With this data frame made, we can order our rows by the highest value for a given
column. In other words, we can find out not only the top terms for a novel, but
the top most <em>unique</em> terms in that novel.</p>
<p>Here’s <em>Dracula</em>:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(tfidf_df[<span class="fu">order</span>(tfidf_df<span class="sc">$</span>Dracula, <span class="at">decreasing=</span><span class="cn">TRUE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>],])</span></code></pre></div>
<pre><code>##  [1] &quot;helsing&quot;      &quot;mina&quot;         &quot;lucy&quot;         &quot;jonathan&quot;     &quot;van&quot;         
##  [6] &quot;harker&quot;       &quot;godalming&quot;    &quot;quincey&quot;      &quot;seward&quot;       &quot;professor&quot;   
## [11] &quot;morris&quot;       &quot;lucy&#39;s&quot;       &quot;harker&#39;s&quot;     &quot;diary&quot;        &quot;seward&#39;s&quot;    
## [16] &quot;arthur&quot;       &quot;renfield&quot;     &quot;westenra&quot;     &quot;whilst&quot;       &quot;undead&quot;      
## [21] &quot;tonight&quot;      &quot;whitby&quot;       &quot;dracula&quot;      &quot;varna&quot;        &quot;carfax&quot;      
## [26] &quot;journal&quot;      &quot;helsing&#39;s&quot;    &quot;count&quot;        &quot;count&#39;s&quot;      &quot;hawkins&quot;     
## [31] &quot;madam&quot;        &quot;galatz&quot;       &quot;jonathan&#39;s&quot;   &quot;mina&#39;s&quot;       &quot;pier&quot;        
## [36] &quot;wolves&quot;       &quot;tomorrow&quot;     &quot;czarina&quot;      &quot;telegram&quot;     &quot;boxes&quot;       
## [41] &quot;today&quot;        &quot;holmwood&quot;     &quot;hypnotic&quot;     &quot;garlic&quot;       &quot;vampire&quot;     
## [46] &quot;phonograph&quot;   &quot;transylvania&quot; &quot;cliff&quot;        &quot;piccadilly&quot;   &quot;slovaks&quot;</code></pre>
<p>Note here that some contractions have slipped through. Lemmatizing would take
care of this, though we could also go back to the corpus object and add in
another step with <code>tm_map()</code> and then make another DTM:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb580-1" aria-hidden="true" tabindex="-1"></a>cleaned_corpus <span class="ot">&lt;-</span> <span class="fu">tm_map</span>(cleaned_corpus, <span class="cf">function</span>(x) <span class="fu">str_remove_all</span>(x, <span class="st">&quot;</span><span class="sc">\\</span><span class="st">&#39;s&quot;</span>, <span class="st">&quot; &quot;</span>))</span></code></pre></div>
<p>We won’t bother to do this whole process now, but it’s a good example of how
iterative the preprocessing workflow is.</p>
<p>Here’s <em>Frankenstein</em>:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(tfidf_df[<span class="fu">order</span>(tfidf_df<span class="sc">$</span>Frankenstein, <span class="at">decreasing=</span><span class="cn">TRUE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>],])</span></code></pre></div>
<pre><code>##  [1] &quot;clerval&quot;      &quot;justine&quot;      &quot;elizabeth&quot;    &quot;felix&quot;        &quot;geneva&quot;      
##  [6] &quot;frankenstein&quot; &quot;safie&quot;        &quot;cottagers&quot;    &quot;dæmon&quot;        &quot;ingolstadt&quot;  
## [11] &quot;kirwin&quot;       &quot;agatha&quot;       &quot;victor&quot;       &quot;ernest&quot;       &quot;mont&quot;        
## [16] &quot;krempe&quot;       &quot;lacey&quot;        &quot;waldman&quot;      &quot;agrippa&quot;      &quot;walton&quot;      
## [21] &quot;mountains&quot;    &quot;creator&quot;      &quot;cottage&quot;      &quot;sledge&quot;       &quot;hovel&quot;       
## [26] &quot;switzerland&quot;  &quot;ice&quot;          &quot;beaufort&quot;     &quot;cornelius&quot;    &quot;william&quot;     
## [31] &quot;protectors&quot;   &quot;moritz&quot;       &quot;henry&quot;        &quot;labours&quot;      &quot;chamounix&quot;   
## [36] &quot;glacier&quot;      &quot;jura&quot;         &quot;blanc&quot;        &quot;endeavoured&quot;  &quot;lake&quot;        
## [41] &quot;leghorn&quot;      &quot;monster&quot;      &quot;rhine&quot;        &quot;magistrate&quot;   &quot;belrive&quot;     
## [46] &quot;lavenza&quot;      &quot;salêve&quot;       &quot;saville&quot;      &quot;strasburgh&quot;   &quot;werter&quot;</code></pre>
<p>And here’s <em>Sense and Sensibility</em>:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="data-forensics-and-cleaning-unstructured-data.html#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(tfidf_df[<span class="fu">order</span>(tfidf_df<span class="sc">$</span>SenseandSensibility, <span class="at">decreasing=</span><span class="cn">TRUE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>],])</span></code></pre></div>
<pre><code>##  [1] &quot;elinor&quot;       &quot;marianne&quot;     &quot;dashwood&quot;     &quot;jennings&quot;     &quot;willoughby&quot;  
##  [6] &quot;lucy&quot;         &quot;brandon&quot;      &quot;barton&quot;       &quot;ferrars&quot;      &quot;colonel&quot;     
## [11] &quot;mrs&quot;          &quot;marianne&#39;s&quot;   &quot;edward&quot;       &quot;middleton&quot;    &quot;elinor&#39;s&quot;    
## [16] &quot;norland&quot;      &quot;palmer&quot;       &quot;steele&quot;       &quot;dashwoods&quot;    &quot;jennings&#39;s&quot;  
## [21] &quot;willoughby&#39;s&quot; &quot;edward&#39;s&quot;     &quot;delaford&quot;     &quot;steeles&quot;      &quot;cleveland&quot;   
## [26] &quot;mama&quot;         &quot;dashwood&#39;s&quot;   &quot;lucy&#39;s&quot;       &quot;brandon&#39;s&quot;    &quot;fanny&quot;       
## [31] &quot;allenham&quot;     &quot;middletons&quot;   &quot;devonshire&quot;   &quot;combe&quot;        &quot;ferrars&#39;s&quot;   
## [36] &quot;sister&quot;       &quot;morton&quot;       &quot;miss&quot;         &quot;margaret&quot;     &quot;park&quot;        
## [41] &quot;charlotte&quot;    &quot;exeter&quot;       &quot;magna&quot;        &quot;berkeley&quot;     &quot;harley&quot;      
## [46] &quot;john&quot;         &quot;middleton&#39;s&quot;  &quot;parsonage&quot;    &quot;beaux&quot;        &quot;behaviour&quot;</code></pre>
<p>Names still rank high, but we can see in these results other words that indeed
seem to be particular to each novel. With this data, we now have a sense of
what makes each document unique in its relationship with all other documents in
a corpus</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-forensics-and-cleaning-structured-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-forensics-and-cleaning-geospatial-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ucdavisdatalab/adventures_in_data_science/edit/master/19_data_forensics-unstructured-data.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ucdavisdatalab/adventures_in_data_science/blob/master/19_data_forensics-unstructured-data.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
